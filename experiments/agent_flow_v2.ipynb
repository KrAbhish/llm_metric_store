{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/k.abhishek/anaconda3/envs/agentgpt/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `AzureOpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import AzureOpenAIEmbeddings`.\n",
      "  warn_deprecated(\n",
      "/Users/k.abhishek/anaconda3/envs/agentgpt/lib/python3.11/site-packages/langchain_community/embeddings/azure_openai.py:113: UserWarning: As of openai>=1.0.0, Azure endpoints should be specified via the `azure_endpoint` param not `openai_api_base` (or alias `base_url`). Updating `openai_api_base` from https://polarisopenai.openai.azure.com/ to https://polarisopenai.openai.azure.com//openai.\n",
      "  warnings.warn(\n",
      "/Users/k.abhishek/anaconda3/envs/agentgpt/lib/python3.11/site-packages/langchain_community/embeddings/azure_openai.py:120: UserWarning: As of openai>=1.0.0, if `deployment` (or alias `azure_deployment`) is specified then `openai_api_base` (or alias `base_url`) should not be. Instead use `deployment` (or alias `azure_deployment`) and `azure_endpoint`.\n",
      "  warnings.warn(\n",
      "/Users/k.abhishek/anaconda3/envs/agentgpt/lib/python3.11/site-packages/langchain_community/embeddings/azure_openai.py:128: UserWarning: As of openai>=1.0.0, if `openai_api_base` (or alias `base_url`) is specified it is expected to be of the form https://example-resource.azure.openai.com/openai/deployments/example-deployment. Updating https://polarisopenai.openai.azure.com/ to https://polarisopenai.openai.azure.com//openai.\n",
      "  warnings.warn(\n",
      "/Users/k.abhishek/anaconda3/envs/agentgpt/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `AzureChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import AzureChatOpenAI`.\n",
      "  warn_deprecated(\n",
      "/Users/k.abhishek/anaconda3/envs/agentgpt/lib/python3.11/site-packages/langchain_community/chat_models/azure_openai.py:167: UserWarning: As of openai>=1.0.0, Azure endpoints should be specified via the `azure_endpoint` param not `openai_api_base` (or alias `base_url`). Updating `openai_api_base` from https://polariseastus2.openai.azure.com/ to https://polariseastus2.openai.azure.com/openai.\n",
      "  warnings.warn(\n",
      "/Users/k.abhishek/anaconda3/envs/agentgpt/lib/python3.11/site-packages/langchain_community/chat_models/azure_openai.py:174: UserWarning: As of openai>=1.0.0, if `deployment_name` (or alias `azure_deployment`) is specified then `openai_api_base` (or alias `base_url`) should not be. Instead use `deployment_name` (or alias `azure_deployment`) and `azure_endpoint`.\n",
      "  warnings.warn(\n",
      "/Users/k.abhishek/anaconda3/envs/agentgpt/lib/python3.11/site-packages/langchain_community/chat_models/azure_openai.py:182: UserWarning: As of openai>=1.0.0, if `openai_api_base` (or alias `base_url`) is specified it is expected to be of the form https://example-resource.azure.openai.com/openai/deployments/example-deployment. Updating https://polariseastus2.openai.azure.com/ to https://polariseastus2.openai.azure.com/openai.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#initialize\n",
    "#     model\n",
    "#     environment variables\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.utils.llamaindex_retriever import LlamaIndexRetriever\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.azure_openai import AzureOpenAIEmbeddings\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "\n",
    "def load_env_variables(file_path):\n",
    "    load_dotenv(file_path)\n",
    "    print(\"Environment variables loaded successfully!\")\n",
    "\n",
    "env_file_path = \"../.env\"\n",
    "load_env_variables = load_env_variables(env_file_path)\n",
    "max_tokens = 3500\n",
    "temperature = 0.1\n",
    "\n",
    "# embeddings = AzureOpenAIEmbeddings(azure_deployment=azure_deployment, openai_api_version=openai_api_version)\n",
    "embeddings =  AzureOpenAIEmbeddings(\n",
    "        deployment=os.getenv(\"EMB_DEPLOYMENT\"),\n",
    "        openai_api_version=os.getenv(\"EMB_OPENAI_API_VERSION\"),\n",
    "        model=os.getenv(\"EMB_MODEL\"),\n",
    "        openai_api_key=os.getenv(\"EMB_OPENAI_API_KEY\"),\n",
    "        openai_api_base=os.getenv(\"EMB_OPENAI_ENDPOINT\"),\n",
    "        openai_api_type=os.getenv(\"EMB_API_TYPE\"),\n",
    "    )\n",
    "\n",
    "llm_gpt = AzureChatOpenAI(deployment_name=os.getenv('AZURE_OPENAI_DEPLOYMENT_NAME'), openai_api_version=os.getenv(\"OPENAI_API_VERSION\"),\n",
    "                        openai_api_base=os.getenv(\"OPENAI_API_BASE\"), \n",
    "                        openai_api_type= os.getenv(\"OPENAI_API_TYPE\"),\n",
    "                        openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "                        max_tokens=max_tokens,\n",
    "                        temperature=temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define utils\n",
    "from src.utils.cube_semantic_custom import CubeSemanticLoader\n",
    "def fetch_cube_metadata(*args, **kwargs):\n",
    "    try:\n",
    "        # # Load document from Cube meta api\n",
    "        loader = CubeSemanticLoader(os.getenv(\"CUBE_API_URL\"), os.getenv(\"CUBE_TOKEN\"), False)\n",
    "        documents = loader.load()\n",
    "        # to_json()\n",
    "        return documents\n",
    "    except Exception as e:\n",
    "        # Handle exceptions gracefully and return an error response\n",
    "        print(\"Error in fetching metadata from cube: \" + str(e))\n",
    "        return 0\n",
    "\n",
    "def create_vector_store(documents, local_vector_store_path, *args, **kwargs):\n",
    "    print(\"Loaded documents: \" + str(documents))\n",
    "    vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "    vectorstore.save_local(local_vector_store_path)\n",
    "    print(\"Vector store created and saved successfully!\")\n",
    "\n",
    "def load_vector_store(vector_store_path, embeddings, *args, **kwargs):\n",
    "    # Load the vector store from the local file system\n",
    "    vectorstore = FAISS.load_local(vector_store_path, embeddings, allow_dangerous_deserialization=True)\n",
    "    print(\"Vector store loaded successfully!\")\n",
    "    \n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "#load existing vector store\n",
    "vector_store_path = \"/Users/k.abhishek/Documents/experiments/metric_store/metric_store_gen_ai/data/vector_store/cube_meta_faiss_index\"\n",
    "vectorstore = load_vector_store(vector_store_path, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tools "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from crewai import Agent, Task, Crew\n",
    "from langchain.tools import tool\n",
    "from src.utils.llamaindex_retriever import LlamaIndexRetriever\n",
    "from typing import Optional, Type\n",
    "from langchain.callbacks.manager import (\n",
    "    AsyncCallbackManagerForToolRun,\n",
    "    CallbackManagerForToolRun,\n",
    ")\n",
    "# Import things that are needed generically\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "# from langchain.tools import BaseTool, StructuredTool, tool\n",
    "from crewai_tools import BaseTool\n",
    "\n",
    "\n",
    "def get_similar_documents_faiss(query, max_number_documents=3):\n",
    "  vectorstore = FAISS.load_local(vector_store_path, embeddings, allow_dangerous_deserialization=True)\n",
    "  docs = vectorstore.similarity_search_with_relevance_scores(query, max_number_documents)\n",
    "  relevant_documents = []\n",
    "  for doc in docs:\n",
    "      doc = doc[0]\n",
    "      meta = {'text':doc.page_content, 'table_metadata': doc.metadata}\n",
    "      relevant_documents.append(meta)\n",
    "  return relevant_documents\n",
    "\n",
    "def get_similar_documents(query, max_number_documents=3):\n",
    "    return get_similar_documents_faiss(query, max_number_documents)\n",
    "\n",
    "\n",
    "class QueryInput(BaseModel):\n",
    "    query: str = Field(description=\"should be enquiry query\")\n",
    "\n",
    "class TerminationHandler(CallbackManagerForToolRun):\n",
    "    pass\n",
    "\n",
    "class RephraseInputQuery(BaseTool):\n",
    "    name:str = \"rephrase_input_query\"\n",
    "    description :str = \"Useful to rephrase the query to capture the intent of the user regarding metric information\"\n",
    "    args_schema: Type[BaseModel] = QueryInput\n",
    "\n",
    "    def _run(\n",
    "        self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool.\"\"\"\n",
    "        metric_description = self.rephrase_input_query(query)\n",
    "        return metric_description\n",
    "\n",
    "    async def _arun(\n",
    "        self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"custom_search does not support async\")\n",
    "    \n",
    "    \n",
    "    def rephrase_input_query(self, query, *args, **kwargs):\n",
    "        agent = Agent(\n",
    "                role='Intent Capturer',\n",
    "                goal=\n",
    "                'Rephrasing the query to capture the intent of the user regarding metric information',\n",
    "                backstory=\n",
    "                \"You are an expert to understand the user's intent and rephrase the query to capture the intent of the user accurately.\",\n",
    "                llm = llm_gpt,\n",
    "                allow_delegation=False)\n",
    "        task = Task(\n",
    "                agent=agent,\n",
    "                description=\n",
    "                f'Rephrase the query to capture the intent of the user regarding metric information. The query is {query}. Donot add any noise to the response',\n",
    "                expected_output=\"some string\",\n",
    "        \n",
    "            )\n",
    "        extracted_metrics = task.execute()\n",
    "\n",
    "        return extracted_metrics\n",
    "    \n",
    "\n",
    "    \n",
    "class MetricDiscovery(BaseTool):\n",
    "    name :str = \"metric_discovery\"\n",
    "    description:str = \"\"\"Useful for general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\"\"\n",
    "    args_schema: Type[BaseModel] = QueryInput\n",
    "\n",
    "    def _run(\n",
    "        self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool.\"\"\"\n",
    "        metric_description = self.metric_discovery(query)\n",
    "        return metric_description\n",
    "\n",
    "    async def _arun(\n",
    "        self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"custom_search does not support async\")\n",
    "    \n",
    "    \n",
    "    def metric_discovery(self, query, *args, **kwargs):\n",
    "        \"\"\"Useful for general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\"\"\n",
    "        relevant_documents = get_similar_documents(query)\n",
    "        agent = Agent(\n",
    "                role='Data Analyst Assistant',\n",
    "                goal=\n",
    "                'Empower users to understand and utilize data effectively. This includes helping them discover relevant metrics, interpreting their meaning',\n",
    "                backstory=\n",
    "                \"The primary purpose is to bridge the gap between raw data and user comprehension, fostering a data-driven culture within the organization.\",\n",
    "                llm = llm_gpt,\n",
    "                allow_delegation=False)  \n",
    "        \n",
    "        task = Task(\n",
    "                agent=agent,\n",
    "                description=\n",
    "                \"\"\" You are responding to  question {metric_description} with answer from the Metadata provided to you as {relevant_documents}}.\n",
    "                    Strictly answer the question with the information present in metadata only.\n",
    "                    Respond with \"Sorry, the query is out of scope.\" if the answer is not present in metadata and terminate further reasoning and prcoess.\n",
    "                    \"\"\",\n",
    "                expected_output=\"some string\",\n",
    "        \n",
    "            )\n",
    "        output = task.execute()\n",
    "\n",
    "        return output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def callback_function(output: TaskOutput):\n",
    "    # Do something after the task is completed\n",
    "    # Example: Send an email to the manager\n",
    "    print(f\"\"\"\n",
    "        Task completed!\n",
    "        Task: {output.description}\n",
    "        Output: {output.raw_output}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def check_termination(task_output):\n",
    "#     agent = Agent(\n",
    "#                 role='Determine query completion',\n",
    "#                 goal=\n",
    "#                 'Given task output, determine termination of crew workflow',\n",
    "#                 backstory=\n",
    "#                 \"Given user query request from user determine if no more new task is needed to be executed\",\n",
    "#                 llm = llm_gpt,\n",
    "#                 allow_delegation=False)\n",
    "#     task = Task(\n",
    "#                 agent=agent,\n",
    "#                 description=\n",
    "#                 f'Given task output, if the query is completed and the task result determines that the query is out of scope then terminate the workflow or else the required query is satisfied. Following is the task result {task_output}',\n",
    "#                 expected_output=\"some string\",\n",
    "        \n",
    "#             )\n",
    "#     termination_status = task.execute()\n",
    "#     return termination_status\n",
    "class MetricDiscoveryTasks():\n",
    "  def metric_isolation(self, agent, query):\n",
    "    return Task(description=(f\"\"\"\n",
    "        Rephrase the query to capture the intent of the user regarding metric information. The query is {query}. Donot add any noise to the response.\n",
    "        {self.__tip_section()}\"\"\"),\n",
    "      agent=agent,\n",
    "      expected_output=\"Reformatted query to capture the intent of the user regarding metric information.\",\n",
    "      # callback=callback_function,\n",
    "    )\n",
    "  \n",
    "  def metric_discovery(self, agent):\n",
    "    return Task(description=(f\"\"\"\n",
    "        Answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\n",
    "        {self.__tip_section()}\"\"\"),\n",
    "      agent=agent,\n",
    "      expected_output=\"If relevant metric exists in metadata, provide the answer. Else, respond with 'Sorry, the query is out of scope.' and terminate process.\",\n",
    "      # callback=callback_function,\n",
    "    )\n",
    "  def __tip_section(self):\n",
    "    return \"If you do your BEST WORK, I'll give you a $10,000 commission!\"\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricDiscoveryAgent():\n",
    "  def user_intent_capture(self):\n",
    "    return Agent(\n",
    "      role='Intent Capturer',\n",
    "      goal=\n",
    "      'Rephrasing the query to capture the intent of the user regarding metric information',\n",
    "      backstory=\n",
    "      \"You are an expert to understand the user's intent and rephrase the query to capture the intent of the user accurately.\",\n",
    "      verbose=True,\n",
    "      tools=[\n",
    "        RephraseInputQuery()\n",
    "      ],\n",
    "      llm = llm_gpt,\n",
    "    )\n",
    "  def discover_metric_info(self):\n",
    "    return Agent(\n",
    "     role='Data Analyst Assistant',\n",
    "      goal=\n",
    "      'Empower users to understand and utilize data effectively. This includes helping them discover relevant metrics, interpreting their meaning',\n",
    "      backstory=\n",
    "      \"The primary purpose is to bridge the gap between raw data and user comprehension, fostering a data-driven culture within the organization.\",\n",
    "      llm = llm_gpt,\n",
    "      verbose=True,\n",
    "      tools=[\n",
    "        MetricDiscovery()\n",
    "      ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def after_task_callback(output):\n",
    "  # Perform actions after the task, \n",
    "  # for example, logging or updating agent state\n",
    "  \n",
    "  print(f\"Agent completed task with result: {output}\")\n",
    "\n",
    "# Assigning the function to task_callback\n",
    "task_callback = after_task_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_callback():\n",
    "        # Accessing local variables\n",
    "        print(\"Local variables:\", locals())\n",
    "        \n",
    "        # Accessing global variables\n",
    "        print(\"Global variables:\", globals())    \n",
    "        \n",
    "        # Accessing built-in variables\n",
    "        print(\"Built-in variables:\", dir(__builtins__))\n",
    "        after_task_callback(\"output\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "class Expert(ABC):\n",
    "    name: str = \"\"\n",
    "    description: str = \"\"\n",
    "    public_description: str = \"\"\n",
    "    arg_description: str = \"The argument to the function.\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def call(\n",
    "        self,\n",
    "        goal: str,\n",
    "        task: str,\n",
    "        input_str: str,\n",
    "    ) -> str:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai.process import Process\n",
    "from typing import Any\n",
    "class MetricDiscoveryInputCrew(Expert):\n",
    "  name = \"MetricDiscovery\"\n",
    "  description = (\n",
    "       \"Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\n",
    "    )\n",
    "  public_description = \"Metric discovery crew\"\n",
    "  arg_description = \"Query related to metrics.\"\n",
    "\n",
    "  def __init__(self, query):\n",
    "    self.query = query\n",
    "    self.crew_process = self.crew_process()\n",
    "    # self.llm = llm_gpt\n",
    "  def crew_process(self):\n",
    "    agents = MetricDiscoveryAgent()\n",
    "    tasks = MetricDiscoveryTasks()\n",
    "    # print(agents)\n",
    "    # print(tasks)\n",
    "    user_intent_capture_agent = agents.user_intent_capture()\n",
    "    discover_metric_info_agent = agents.discover_metric_info()\n",
    "    # print(metric_isolator_agent)\n",
    "    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\n",
    "    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, self.query)\n",
    "    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\n",
    "    \n",
    "    # print(\"Metric_isolator_task\", metric_isolator_task)\n",
    "    crew = Crew(\n",
    "      agents=[\n",
    "        user_intent_capture_agent,\n",
    "        discover_metric_info_agent,\n",
    "      ],\n",
    "      tasks=[\n",
    "        metric_isolator_task,\n",
    "        metric_discover_task\n",
    "      ],\n",
    "      verbose=False,\n",
    "      process=Process.sequential,\n",
    "      step_callback=test_callback()\n",
    "    )\n",
    "    return crew\n",
    "\n",
    "  def run(self):\n",
    "    result = self.crew_process.kickoff()\n",
    "    return result\n",
    "  \n",
    "  def call(\n",
    "        self, goal: str, task: str, input_str: str, *args: Any, **kwargs: Any\n",
    "    ) -> str:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-03 19:27:24,054 - 140704419426240 - __init__.py-__init__:518 - WARNING: Overriding of current TracerProvider is not allowed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local variables: {}\n",
      "Global variables: {'__name__': '__main__', '__doc__': 'Automatically created module for IPython interactive environment', '__package__': None, '__loader__': None, '__spec__': None, '__builtin__': <module 'builtins' (built-in)>, '__builtins__': <module 'builtins' (built-in)>, '_ih': ['', '#initialize\\n#     model\\n#     environment variables\\n\\nimport sys\\nsys.path.append(\\'..\\')\\nfrom src.utils.llamaindex_retriever import LlamaIndexRetriever\\nfrom langchain.vectorstores import FAISS\\nfrom langchain.embeddings.azure_openai import AzureOpenAIEmbeddings\\nfrom langchain.embeddings.openai import OpenAIEmbeddings\\nfrom dotenv import load_dotenv\\nimport os\\nfrom langchain.chat_models import AzureChatOpenAI\\n\\ndef load_env_variables(file_path):\\n    load_dotenv(file_path)\\n    print(\"Environment variables loaded successfully!\")\\n\\nenv_file_path = \"../.env\"\\nload_env_variables = load_env_variables(env_file_path)\\nmax_tokens = 3500\\ntemperature = 0.1\\n\\n# embeddings = AzureOpenAIEmbeddings(azure_deployment=azure_deployment, openai_api_version=openai_api_version)\\nembeddings =  AzureOpenAIEmbeddings(\\n        deployment=os.getenv(\"EMB_DEPLOYMENT\"),\\n        openai_api_version=os.getenv(\"EMB_OPENAI_API_VERSION\"),\\n        model=os.getenv(\"EMB_MODEL\"),\\n        openai_api_key=os.getenv(\"EMB_OPENAI_API_KEY\"),\\n        openai_api_base=os.getenv(\"EMB_OPENAI_ENDPOINT\"),\\n        openai_api_type=os.getenv(\"EMB_API_TYPE\"),\\n    )\\n\\nllm_gpt = AzureChatOpenAI(deployment_name=os.getenv(\\'AZURE_OPENAI_DEPLOYMENT_NAME\\'), openai_api_version=os.getenv(\"OPENAI_API_VERSION\"),\\n                        openai_api_base=os.getenv(\"OPENAI_API_BASE\"), \\n                        openai_api_type= os.getenv(\"OPENAI_API_TYPE\"),\\n                        openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\\n                        max_tokens=max_tokens,\\n                        temperature=temperature)', '#define utils\\nfrom src.utils.cube_semantic_custom import CubeSemanticLoader\\ndef fetch_cube_metadata(*args, **kwargs):\\n    try:\\n        # # Load document from Cube meta api\\n        loader = CubeSemanticLoader(os.getenv(\"CUBE_API_URL\"), os.getenv(\"CUBE_TOKEN\"), False)\\n        documents = loader.load()\\n        # to_json()\\n        return documents\\n    except Exception as e:\\n        # Handle exceptions gracefully and return an error response\\n        print(\"Error in fetching metadata from cube: \" + str(e))\\n        return 0\\n\\ndef create_vector_store(documents, local_vector_store_path, *args, **kwargs):\\n    print(\"Loaded documents: \" + str(documents))\\n    vectorstore = FAISS.from_documents(documents, embeddings)\\n    vectorstore.save_local(local_vector_store_path)\\n    print(\"Vector store created and saved successfully!\")\\n\\ndef load_vector_store(vector_store_path, embeddings, *args, **kwargs):\\n    # Load the vector store from the local file system\\n    vectorstore = FAISS.load_local(vector_store_path, embeddings, allow_dangerous_deserialization=True)\\n    print(\"Vector store loaded successfully!\")\\n    \\n    return vectorstore', '#load existing vector store\\nvector_store_path = \"/Users/k.abhishek/Documents/experiments/metric_store/metric_store_gen_ai/data/vector_store/cube_meta_faiss_index\"\\nvectorstore = load_vector_store(vector_store_path, embeddings)', 'import json\\nfrom crewai import Agent, Task, Crew\\nfrom langchain.tools import tool\\nfrom src.utils.llamaindex_retriever import LlamaIndexRetriever\\nfrom typing import Optional, Type\\nfrom langchain.callbacks.manager import (\\n    AsyncCallbackManagerForToolRun,\\n    CallbackManagerForToolRun,\\n)\\n# Import things that are needed generically\\nfrom langchain.pydantic_v1 import BaseModel, Field\\n# from langchain.tools import BaseTool, StructuredTool, tool\\nfrom crewai_tools import BaseTool\\n\\n\\ndef get_similar_documents_faiss(query, max_number_documents=3):\\n  vectorstore = FAISS.load_local(vector_store_path, embeddings, allow_dangerous_deserialization=True)\\n  docs = vectorstore.similarity_search_with_relevance_scores(query, max_number_documents)\\n  relevant_documents = []\\n  for doc in docs:\\n      doc = doc[0]\\n      meta = {\\'text\\':doc.page_content, \\'table_metadata\\': doc.metadata}\\n      relevant_documents.append(meta)\\n  return relevant_documents\\n\\ndef get_similar_documents(query, max_number_documents=3):\\n    return get_similar_documents_faiss(query, max_number_documents)\\n\\n\\nclass QueryInput(BaseModel):\\n    query: str = Field(description=\"should be enquiry query\")\\n\\n\\nclass RephraseInputQuery(BaseTool):\\n    name:str = \"rephrase_input_query\"\\n    description :str = \"Useful to rephrase the query to capture the intent of the user regarding metric information\"\\n    args_schema: Type[BaseModel] = QueryInput\\n\\n    def _run(\\n        self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None\\n    ) -> str:\\n        \"\"\"Use the tool.\"\"\"\\n        metric_description = self.rephrase_input_query(query)\\n        return metric_description\\n\\n    async def _arun(\\n        self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None\\n    ) -> str:\\n        \"\"\"Use the tool asynchronously.\"\"\"\\n        raise NotImplementedError(\"custom_search does not support async\")\\n    \\n    \\n    def rephrase_input_query(self, query, *args, **kwargs):\\n        agent = Agent(\\n                role=\\'Intent Capturer\\',\\n                goal=\\n                \\'Rephrasing the query to capture the intent of the user regarding metric information\\',\\n                backstory=\\n                \"You are an expert to understand the user\\'s intent and rephrase the query to capture the intent of the user accurately.\",\\n                llm = llm_gpt,\\n                allow_delegation=False)\\n        task = Task(\\n                agent=agent,\\n                description=\\n                f\\'Rephrase the query to capture the intent of the user regarding metric information. The query is {query}. Donot add any noise to the response\\',\\n                expected_output=\"some string\",\\n        \\n            )\\n        extracted_metrics = task.execute()\\n\\n        return extracted_metrics\\n    \\n\\n    \\nclass MetricDiscovery(BaseTool):\\n    name :str = \"metric_discovery\"\\n    description:str = \"\"\"Useful for general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\"\"\\n    args_schema: Type[BaseModel] = QueryInput\\n\\n    def _run(\\n        self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None\\n    ) -> str:\\n        \"\"\"Use the tool.\"\"\"\\n        metric_description = self.metric_discovery(query)\\n        return metric_description\\n\\n    async def _arun(\\n        self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None\\n    ) -> str:\\n        \"\"\"Use the tool asynchronously.\"\"\"\\n        raise NotImplementedError(\"custom_search does not support async\")\\n    \\n    \\n    def metric_discovery(self, query, *args, **kwargs):\\n        \"\"\"Useful for general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\"\"\\n        relevant_documents = get_similar_documents(query)\\n        agent = Agent(\\n                role=\\'Data Analyst Assistant\\',\\n                goal=\\n                \\'Empower users to understand and utilize data effectively. This includes helping them discover relevant metrics, interpreting their meaning\\',\\n                backstory=\\n                \"The primary purpose is to bridge the gap between raw data and user comprehension, fostering a data-driven culture within the organization.\",\\n                llm = llm_gpt,\\n                allow_delegation=False)  \\n        \\n        task = Task(\\n                agent=agent,\\n                description=\\n                \"\"\" You are responding to  question {metric_description} with answer from the Metadata provided to you as {relevant_documents}}.\\n                    Strictly answer the question with the information present in metadata only.\\n                    Respond with \"Sorry, the query is out of scope.\" if the answer is not present in metadata and terminate further reasoning and prcoess.\\n                    \"\"\",\\n                expected_output=\"some string\",\\n        \\n            )\\n        output = task.execute()\\n\\n        return output', '# def check_termination(task_output):\\n#     agent = Agent(\\n#                 role=\\'Determine query completion\\',\\n#                 goal=\\n#                 \\'Given task output, determine termination of crew workflow\\',\\n#                 backstory=\\n#                 \"Given user query request from user determine if no more new task is needed to be executed\",\\n#                 llm = llm_gpt,\\n#                 allow_delegation=False)\\n#     task = Task(\\n#                 agent=agent,\\n#                 description=\\n#                 f\\'Given task output, if the query is completed and the task result determines that the query is out of scope then terminate the workflow or else the required query is satisfied. Following is the task result {task_output}\\',\\n#                 expected_output=\"some string\",\\n        \\n#             )\\n#     termination_status = task.execute()\\n#     return termination_status\\nclass MetricDiscoveryTasks():\\n  def metric_isolation(self, agent, query):\\n    return Task(description=(f\"\"\"\\n        Rephrase the query to capture the intent of the user regarding metric information. The query is {query}. Donot add any noise to the response.\\n        {self.__tip_section()}\"\"\"),\\n      agent=agent,\\n      expected_output=\"Reformatted query to capture the intent of the user regarding metric information.\",\\n    )\\n  \\n  def metric_discovery(self, agent):\\n    return Task(description=(f\"\"\"\\n        Answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\\n        {self.__tip_section()}\"\"\"),\\n      agent=agent,\\n      expected_output=\"If relevant metric exists in metadata, provide the answer. Else, respond with \\'Sorry, the query is out of scope.\\' and terminate process.\",\\n    )\\n  def __tip_section(self):\\n    return \"If you do your BEST WORK, I\\'ll give you a $10,000 commission!\"\\n  \\n  ', 'class MetricDiscoveryAgent():\\n  def user_intent_capture(self):\\n    return Agent(\\n      role=\\'Intent Capturer\\',\\n      goal=\\n      \\'Rephrasing the query to capture the intent of the user regarding metric information\\',\\n      backstory=\\n      \"You are an expert to understand the user\\'s intent and rephrase the query to capture the intent of the user accurately.\",\\n      verbose=True,\\n      tools=[\\n        RephraseInputQuery()\\n      ],\\n      llm = llm_gpt,\\n    )\\n  def discover_metric_info(self):\\n    return Agent(\\n     role=\\'Data Analyst Assistant\\',\\n      goal=\\n      \\'Empower users to understand and utilize data effectively. This includes helping them discover relevant metrics, interpreting their meaning\\',\\n      backstory=\\n      \"The primary purpose is to bridge the gap between raw data and user comprehension, fostering a data-driven culture within the organization.\",\\n      llm = llm_gpt,\\n      verbose=True,\\n      tools=[\\n        MetricDiscovery()\\n      ],\\n    )', 'def after_task_callback(output):\\n  # Perform actions after the task, \\n  # for example, logging or updating agent state\\n  \\n  print(f\"Agent completed task with result: {output}\")\\n\\n# Assigning the function to task_callback\\ntask_callback = after_task_callback', 'def test_callback():\\n        # Accessing local variables\\n        print(\"Local variables:\", locals())\\n        \\n        # Accessing global variables\\n        print(\"Global variables:\", globals())    \\n        \\n        # Accessing built-in variables\\n        print(\"Built-in variables:\", dir(__builtins__))\\n        after_task_callback(\"output\")\\n  ', 'from crewai.process import Process\\nclass MetricDiscoveryInputCrew:\\n  def __init__(self, query):\\n    self.query = query\\n    # self.llm = llm_gpt\\n\\n  def run(self):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, self.query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n\\n    result = crew.kickoff()\\n    return result', 'query = \"What is the most popular feature used by our paid subscribers\"\\n# formatted_query = input(\\n#     dedent(\"\"\"\\n#       {What is the most popular feature used by our paid subscribers}\\n#     \"\"\"))\\n# print(formatted_query)\\ncrew = MetricDiscoveryInputCrew(query)\\nresult = crew.run()', 'dir(result)', '# def check_termination(task_output):\\n#     agent = Agent(\\n#                 role=\\'Determine query completion\\',\\n#                 goal=\\n#                 \\'Given task output, determine termination of crew workflow\\',\\n#                 backstory=\\n#                 \"Given user query request from user determine if no more new task is needed to be executed\",\\n#                 llm = llm_gpt,\\n#                 allow_delegation=False)\\n#     task = Task(\\n#                 agent=agent,\\n#                 description=\\n#                 f\\'Given task output, if the query is completed and the task result determines that the query is out of scope then terminate the workflow or else the required query is satisfied. Following is the task result {task_output}\\',\\n#                 expected_output=\"some string\",\\n        \\n#             )\\n#     termination_status = task.execute()\\n#     return termination_status\\nclass MetricDiscoveryTasks():\\n  def metric_isolation(self, agent, query):\\n    return Task(description=(f\"\"\"\\n        Rephrase the query to capture the intent of the user regarding metric information. The query is {query}. Donot add any noise to the response.\\n        {self.__tip_section()}\"\"\"),\\n      agent=agent,\\n      expected_output=\"Reformatted query to capture the intent of the user regarding metric information.\",\\n      callback=callback_function,\\n    )\\n  \\n  def metric_discovery(self, agent):\\n    return Task(description=(f\"\"\"\\n        Answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\\n        {self.__tip_section()}\"\"\"),\\n      agent=agent,\\n      expected_output=\"If relevant metric exists in metadata, provide the answer. Else, respond with \\'Sorry, the query is out of scope.\\' and terminate process.\",\\n      callback=callback_function,\\n    )\\n  def __tip_section(self):\\n    return \"If you do your BEST WORK, I\\'ll give you a $10,000 commission!\"\\n  \\n  ', 'def callback_function(output: TaskOutput):\\n    # Do something after the task is completed\\n    # Example: Send an email to the manager\\n    print(f\"\"\"\\n        Task completed!\\n        Task: {output.description}\\n        Output: {output.raw_output}\\n    \"\"\")', '# def check_termination(task_output):\\n#     agent = Agent(\\n#                 role=\\'Determine query completion\\',\\n#                 goal=\\n#                 \\'Given task output, determine termination of crew workflow\\',\\n#                 backstory=\\n#                 \"Given user query request from user determine if no more new task is needed to be executed\",\\n#                 llm = llm_gpt,\\n#                 allow_delegation=False)\\n#     task = Task(\\n#                 agent=agent,\\n#                 description=\\n#                 f\\'Given task output, if the query is completed and the task result determines that the query is out of scope then terminate the workflow or else the required query is satisfied. Following is the task result {task_output}\\',\\n#                 expected_output=\"some string\",\\n        \\n#             )\\n#     termination_status = task.execute()\\n#     return termination_status\\nclass MetricDiscoveryTasks():\\n  def metric_isolation(self, agent, query):\\n    return Task(description=(f\"\"\"\\n        Rephrase the query to capture the intent of the user regarding metric information. The query is {query}. Donot add any noise to the response.\\n        {self.__tip_section()}\"\"\"),\\n      agent=agent,\\n      expected_output=\"Reformatted query to capture the intent of the user regarding metric information.\",\\n      callback=callback_function,\\n    )\\n  \\n  def metric_discovery(self, agent):\\n    return Task(description=(f\"\"\"\\n        Answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\\n        {self.__tip_section()}\"\"\"),\\n      agent=agent,\\n      expected_output=\"If relevant metric exists in metadata, provide the answer. Else, respond with \\'Sorry, the query is out of scope.\\' and terminate process.\",\\n      callback=callback_function,\\n    )\\n  def __tip_section(self):\\n    return \"If you do your BEST WORK, I\\'ll give you a $10,000 commission!\"\\n  \\n  ', 'class MetricDiscoveryAgent():\\n  def user_intent_capture(self):\\n    return Agent(\\n      role=\\'Intent Capturer\\',\\n      goal=\\n      \\'Rephrasing the query to capture the intent of the user regarding metric information\\',\\n      backstory=\\n      \"You are an expert to understand the user\\'s intent and rephrase the query to capture the intent of the user accurately.\",\\n      verbose=True,\\n      tools=[\\n        RephraseInputQuery()\\n      ],\\n      llm = llm_gpt,\\n    )\\n  def discover_metric_info(self):\\n    return Agent(\\n     role=\\'Data Analyst Assistant\\',\\n      goal=\\n      \\'Empower users to understand and utilize data effectively. This includes helping them discover relevant metrics, interpreting their meaning\\',\\n      backstory=\\n      \"The primary purpose is to bridge the gap between raw data and user comprehension, fostering a data-driven culture within the organization.\",\\n      llm = llm_gpt,\\n      verbose=True,\\n      tools=[\\n        MetricDiscovery()\\n      ],\\n    )', 'def after_task_callback(output):\\n  # Perform actions after the task, \\n  # for example, logging or updating agent state\\n  \\n  print(f\"Agent completed task with result: {output}\")\\n\\n# Assigning the function to task_callback\\ntask_callback = after_task_callback', 'def test_callback():\\n        # Accessing local variables\\n        print(\"Local variables:\", locals())\\n        \\n        # Accessing global variables\\n        print(\"Global variables:\", globals())    \\n        \\n        # Accessing built-in variables\\n        print(\"Built-in variables:\", dir(__builtins__))\\n        after_task_callback(\"output\")\\n  ', 'from crewai.process import Process\\nclass MetricDiscoveryInputCrew:\\n  def __init__(self, query):\\n    self.query = query\\n    # self.llm = llm_gpt\\n\\n  def run(self):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, self.query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n\\n    result = crew.kickoff()\\n    return result', 'query = \"What is the most popular feature used by our paid subscribers\"\\n# formatted_query = input(\\n#     dedent(\"\"\"\\n#       {What is the most popular feature used by our paid subscribers}\\n#     \"\"\"))\\n# print(formatted_query)\\ncrew = MetricDiscoveryInputCrew(query)\\nresult = crew.run()', '# def check_termination(task_output):\\n#     agent = Agent(\\n#                 role=\\'Determine query completion\\',\\n#                 goal=\\n#                 \\'Given task output, determine termination of crew workflow\\',\\n#                 backstory=\\n#                 \"Given user query request from user determine if no more new task is needed to be executed\",\\n#                 llm = llm_gpt,\\n#                 allow_delegation=False)\\n#     task = Task(\\n#                 agent=agent,\\n#                 description=\\n#                 f\\'Given task output, if the query is completed and the task result determines that the query is out of scope then terminate the workflow or else the required query is satisfied. Following is the task result {task_output}\\',\\n#                 expected_output=\"some string\",\\n        \\n#             )\\n#     termination_status = task.execute()\\n#     return termination_status\\nclass MetricDiscoveryTasks():\\n  def metric_isolation(self, agent, query):\\n    return Task(description=(f\"\"\"\\n        Rephrase the query to capture the intent of the user regarding metric information. The query is {query}. Donot add any noise to the response.\\n        {self.__tip_section()}\"\"\"),\\n      agent=agent,\\n      expected_output=\"Reformatted query to capture the intent of the user regarding metric information.\",\\n      # callback=callback_function,\\n    )\\n  \\n  def metric_discovery(self, agent):\\n    return Task(description=(f\"\"\"\\n        Answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\\n        {self.__tip_section()}\"\"\"),\\n      agent=agent,\\n      expected_output=\"If relevant metric exists in metadata, provide the answer. Else, respond with \\'Sorry, the query is out of scope.\\' and terminate process.\",\\n      # callback=callback_function,\\n    )\\n  def __tip_section(self):\\n    return \"If you do your BEST WORK, I\\'ll give you a $10,000 commission!\"\\n  \\n  ', 'class MetricDiscoveryAgent():\\n  def user_intent_capture(self):\\n    return Agent(\\n      role=\\'Intent Capturer\\',\\n      goal=\\n      \\'Rephrasing the query to capture the intent of the user regarding metric information\\',\\n      backstory=\\n      \"You are an expert to understand the user\\'s intent and rephrase the query to capture the intent of the user accurately.\",\\n      verbose=True,\\n      tools=[\\n        RephraseInputQuery()\\n      ],\\n      llm = llm_gpt,\\n    )\\n  def discover_metric_info(self):\\n    return Agent(\\n     role=\\'Data Analyst Assistant\\',\\n      goal=\\n      \\'Empower users to understand and utilize data effectively. This includes helping them discover relevant metrics, interpreting their meaning\\',\\n      backstory=\\n      \"The primary purpose is to bridge the gap between raw data and user comprehension, fostering a data-driven culture within the organization.\",\\n      llm = llm_gpt,\\n      verbose=True,\\n      tools=[\\n        MetricDiscovery()\\n      ],\\n    )', 'def after_task_callback(output):\\n  # Perform actions after the task, \\n  # for example, logging or updating agent state\\n  \\n  print(f\"Agent completed task with result: {output}\")\\n\\n# Assigning the function to task_callback\\ntask_callback = after_task_callback', 'def test_callback():\\n        # Accessing local variables\\n        print(\"Local variables:\", locals())\\n        \\n        # Accessing global variables\\n        print(\"Global variables:\", globals())    \\n        \\n        # Accessing built-in variables\\n        print(\"Built-in variables:\", dir(__builtins__))\\n        after_task_callback(\"output\")\\n  ', 'from crewai.process import Process\\nclass MetricDiscoveryInputCrew:\\n  def __init__(self, query):\\n    self.query = query\\n    # self.llm = llm_gpt\\n\\n  def run(self):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, self.query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n\\n    result = crew.kickoff()\\n    return result', 'query = \"What is the most popular feature used by our paid subscribers\"\\n# formatted_query = input(\\n#     dedent(\"\"\"\\n#       {What is the most popular feature used by our paid subscribers}\\n#     \"\"\"))\\n# print(formatted_query)\\ncrew = MetricDiscoveryInputCrew(query)', 'dir(crew)', 'from crewai.process import Process\\nfrom typing import Any\\nclass MetricDiscoveryInputCrew(Expert):\\n  description = (\\n       \"Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\\n    )\\n  public_description = \"Metric discovery crew\"\\n  arg_description = \"Query for metrics to be processed by the crew.\"\\n\\n  def __init__(self, query):\\n    self.query = query\\n    self.crew_process = self.crew_process()\\n    # self.llm = llm_gpt\\n  def crew_process(self):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, self.query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n    self.crew_process = crew\\n\\n  def run(self):\\n    result = self.crew_process.kickoff()\\n    return result\\n  \\n  def call(\\n        self, goal: str, task: str, input_str: str, *args: Any, **kwargs: Any\\n    ) -> str:\\n    pass', 'from abc import ABC, abstractmethod\\nclass Expert(ABC):\\n    description: str = \"\"\\n    public_description: str = \"\"\\n    arg_description: str = \"The argument to the function.\"\\n\\n    @abstractmethod\\n    def call(\\n        self,\\n        goal: str,\\n        task: str,\\n        input_str: str,\\n    ) -> str:\\n        pass', 'from crewai.process import Process\\nfrom typing import Any\\nclass MetricDiscoveryInputCrew(Expert):\\n  description = (\\n       \"Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\\n    )\\n  public_description = \"Metric discovery crew\"\\n  arg_description = \"Query for metrics to be processed by the crew.\"\\n\\n  def __init__(self, query):\\n    self.query = query\\n    self.crew_process = self.crew_process()\\n    # self.llm = llm_gpt\\n  def crew_process(self):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, self.query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n    self.crew_process = crew\\n\\n  def run(self):\\n    result = self.crew_process.kickoff()\\n    return result\\n  \\n  def call(\\n        self, goal: str, task: str, input_str: str, *args: Any, **kwargs: Any\\n    ) -> str:\\n    pass', '#Available experts\\nfrom typing import Any, Dict, List, Optional, Union\\nfrom typing import Type, TypedDict\\n\\nclass ExpertDescription(TypedDict):\\n    \"\"\"Representation of a callable expert\"\"\"\\n    name: str\\n    \"\"\"The name of the expert.\"\"\"\\n    description: str\\n    \"\"\"A description of the expert.\"\"\"\\n    parameters: dict[str, object]\\n    \"\"\"The parameters of the expert.\"\"\"\\n\\ndef get_expert_function(expert: Type[Expert]) -> ExpertDescription:\\n    \"\"\"A function that will return the tool\\'s function specification\"\"\"\\n    name = get_expert_name(tool)\\n\\n    return {\\n        \"name\": name,\\n        \"description\": expert.description,\\n        \"parameters\": {\\n            \"type\": \"object\",\\n            \"properties\": {\\n                \"reasoning\": {\\n                    \"type\": \"string\",\\n                    \"description\": (\\n                        f\"Reasoning is how the task will be accomplished with the current expert. \"\\n                        \"Detail your overall plan along with any concerns you have.\"\\n                        \"Ensure this reasoning value is in the user defined langauge \"\\n                    ),\\n                },\\n                \"arg\": {\\n                    \"type\": \"string\",\\n                    \"description\": expert.arg_description,\\n                },\\n            },\\n            \"required\": [\"reasoning\", \"arg\"],\\n        },\\n    }\\n\\ndef get_expert_name(expert: Type[Expert]) -> str:\\n    return format_expert_name(expert.__name__)\\n\\ndef format_expert_name(expert_name: str) -> str:\\n    return expert_name.lower()\\n\\ndef get_available_experts() -> List[Type[Expert]]:\\n    return [\\n        MetricDiscoveryInputCrew\\n    ]', \"available_experts = get_available_experts()\\nexperts = list(map(get_expert_function, available_experts))\\nexpert_descriptions = {expert['name'] : expert['description'] for expert in experts}\", 'expert_descriptions', 'experts', 'from abc import ABC, abstractmethod\\nclass Expert(ABC):\\n    name: str = \"\"\\n    description: str = \"\"\\n    public_description: str = \"\"\\n    arg_description: str = \"The argument to the function.\"\\n\\n    @abstractmethod\\n    def call(\\n        self,\\n        goal: str,\\n        task: str,\\n        input_str: str,\\n    ) -> str:\\n        pass', 'from crewai.process import Process\\nfrom typing import Any\\nclass MetricDiscoveryInputCrew(Expert):\\n  name = \"MetricDiscovery\"\\n  description = (\\n       \"Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\\n    )\\n  public_description = \"Metric discovery crew\"\\n  arg_description = \"Query related to metrics.\"\\n\\n  def __init__(self, query):\\n    self.query = query\\n    self.crew_process = self.crew_process()\\n    # self.llm = llm_gpt\\n  def crew_process(self):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    # print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, self.query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n    self.crew_process = crew\\n\\n  def run(self):\\n    result = self.crew_process.kickoff()\\n    return result\\n  \\n  def call(\\n        self, goal: str, task: str, input_str: str, *args: Any, **kwargs: Any\\n    ) -> str:\\n    pass', 'query = \"What is the most popular feature used by our paid subscribers\"\\n# formatted_query = input(\\n#     dedent(\"\"\"\\n#       {What is the most popular feature used by our paid subscribers}\\n#     \"\"\"))\\n# print(formatted_query)\\ncrew = MetricDiscoveryInputCrew(query)\\nresult = crew.run()'], '_oh': {11: ['__add__', '__class__', '__contains__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getnewargs__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mod__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__rmod__', '__rmul__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'capitalize', 'casefold', 'center', 'count', 'encode', 'endswith', 'expandtabs', 'find', 'format', 'format_map', 'index', 'isalnum', 'isalpha', 'isascii', 'isdecimal', 'isdigit', 'isidentifier', 'islower', 'isnumeric', 'isprintable', 'isspace', 'istitle', 'isupper', 'join', 'ljust', 'lower', 'lstrip', 'maketrans', 'partition', 'removeprefix', 'removesuffix', 'replace', 'rfind', 'rindex', 'rjust', 'rpartition', 'rsplit', 'rstrip', 'split', 'splitlines', 'startswith', 'strip', 'swapcase', 'title', 'translate', 'upper', 'zfill'], 26: ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'query', 'run'], 32: {'tool': 'Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.'}, 33: [{'name': 'tool', 'description': 'Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.', 'parameters': {'type': 'object', 'properties': {'reasoning': {'type': 'string', 'description': 'Reasoning is how the task will be accomplished with the current expert. Detail your overall plan along with any concerns you have.Ensure this reasoning value is in the user defined langauge '}, 'arg': {'type': 'string', 'description': 'Query for metrics to be processed by the crew.'}}, 'required': ['reasoning', 'arg']}}]}, '_dh': [PosixPath('/Users/k.abhishek/Documents/experiments/metric_store/metric_store_gen_ai/experiments')], 'In': ['', '#initialize\\n#     model\\n#     environment variables\\n\\nimport sys\\nsys.path.append(\\'..\\')\\nfrom src.utils.llamaindex_retriever import LlamaIndexRetriever\\nfrom langchain.vectorstores import FAISS\\nfrom langchain.embeddings.azure_openai import AzureOpenAIEmbeddings\\nfrom langchain.embeddings.openai import OpenAIEmbeddings\\nfrom dotenv import load_dotenv\\nimport os\\nfrom langchain.chat_models import AzureChatOpenAI\\n\\ndef load_env_variables(file_path):\\n    load_dotenv(file_path)\\n    print(\"Environment variables loaded successfully!\")\\n\\nenv_file_path = \"../.env\"\\nload_env_variables = load_env_variables(env_file_path)\\nmax_tokens = 3500\\ntemperature = 0.1\\n\\n# embeddings = AzureOpenAIEmbeddings(azure_deployment=azure_deployment, openai_api_version=openai_api_version)\\nembeddings =  AzureOpenAIEmbeddings(\\n        deployment=os.getenv(\"EMB_DEPLOYMENT\"),\\n        openai_api_version=os.getenv(\"EMB_OPENAI_API_VERSION\"),\\n        model=os.getenv(\"EMB_MODEL\"),\\n        openai_api_key=os.getenv(\"EMB_OPENAI_API_KEY\"),\\n        openai_api_base=os.getenv(\"EMB_OPENAI_ENDPOINT\"),\\n        openai_api_type=os.getenv(\"EMB_API_TYPE\"),\\n    )\\n\\nllm_gpt = AzureChatOpenAI(deployment_name=os.getenv(\\'AZURE_OPENAI_DEPLOYMENT_NAME\\'), openai_api_version=os.getenv(\"OPENAI_API_VERSION\"),\\n                        openai_api_base=os.getenv(\"OPENAI_API_BASE\"), \\n                        openai_api_type= os.getenv(\"OPENAI_API_TYPE\"),\\n                        openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\\n                        max_tokens=max_tokens,\\n                        temperature=temperature)', '#define utils\\nfrom src.utils.cube_semantic_custom import CubeSemanticLoader\\ndef fetch_cube_metadata(*args, **kwargs):\\n    try:\\n        # # Load document from Cube meta api\\n        loader = CubeSemanticLoader(os.getenv(\"CUBE_API_URL\"), os.getenv(\"CUBE_TOKEN\"), False)\\n        documents = loader.load()\\n        # to_json()\\n        return documents\\n    except Exception as e:\\n        # Handle exceptions gracefully and return an error response\\n        print(\"Error in fetching metadata from cube: \" + str(e))\\n        return 0\\n\\ndef create_vector_store(documents, local_vector_store_path, *args, **kwargs):\\n    print(\"Loaded documents: \" + str(documents))\\n    vectorstore = FAISS.from_documents(documents, embeddings)\\n    vectorstore.save_local(local_vector_store_path)\\n    print(\"Vector store created and saved successfully!\")\\n\\ndef load_vector_store(vector_store_path, embeddings, *args, **kwargs):\\n    # Load the vector store from the local file system\\n    vectorstore = FAISS.load_local(vector_store_path, embeddings, allow_dangerous_deserialization=True)\\n    print(\"Vector store loaded successfully!\")\\n    \\n    return vectorstore', '#load existing vector store\\nvector_store_path = \"/Users/k.abhishek/Documents/experiments/metric_store/metric_store_gen_ai/data/vector_store/cube_meta_faiss_index\"\\nvectorstore = load_vector_store(vector_store_path, embeddings)', 'import json\\nfrom crewai import Agent, Task, Crew\\nfrom langchain.tools import tool\\nfrom src.utils.llamaindex_retriever import LlamaIndexRetriever\\nfrom typing import Optional, Type\\nfrom langchain.callbacks.manager import (\\n    AsyncCallbackManagerForToolRun,\\n    CallbackManagerForToolRun,\\n)\\n# Import things that are needed generically\\nfrom langchain.pydantic_v1 import BaseModel, Field\\n# from langchain.tools import BaseTool, StructuredTool, tool\\nfrom crewai_tools import BaseTool\\n\\n\\ndef get_similar_documents_faiss(query, max_number_documents=3):\\n  vectorstore = FAISS.load_local(vector_store_path, embeddings, allow_dangerous_deserialization=True)\\n  docs = vectorstore.similarity_search_with_relevance_scores(query, max_number_documents)\\n  relevant_documents = []\\n  for doc in docs:\\n      doc = doc[0]\\n      meta = {\\'text\\':doc.page_content, \\'table_metadata\\': doc.metadata}\\n      relevant_documents.append(meta)\\n  return relevant_documents\\n\\ndef get_similar_documents(query, max_number_documents=3):\\n    return get_similar_documents_faiss(query, max_number_documents)\\n\\n\\nclass QueryInput(BaseModel):\\n    query: str = Field(description=\"should be enquiry query\")\\n\\n\\nclass RephraseInputQuery(BaseTool):\\n    name:str = \"rephrase_input_query\"\\n    description :str = \"Useful to rephrase the query to capture the intent of the user regarding metric information\"\\n    args_schema: Type[BaseModel] = QueryInput\\n\\n    def _run(\\n        self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None\\n    ) -> str:\\n        \"\"\"Use the tool.\"\"\"\\n        metric_description = self.rephrase_input_query(query)\\n        return metric_description\\n\\n    async def _arun(\\n        self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None\\n    ) -> str:\\n        \"\"\"Use the tool asynchronously.\"\"\"\\n        raise NotImplementedError(\"custom_search does not support async\")\\n    \\n    \\n    def rephrase_input_query(self, query, *args, **kwargs):\\n        agent = Agent(\\n                role=\\'Intent Capturer\\',\\n                goal=\\n                \\'Rephrasing the query to capture the intent of the user regarding metric information\\',\\n                backstory=\\n                \"You are an expert to understand the user\\'s intent and rephrase the query to capture the intent of the user accurately.\",\\n                llm = llm_gpt,\\n                allow_delegation=False)\\n        task = Task(\\n                agent=agent,\\n                description=\\n                f\\'Rephrase the query to capture the intent of the user regarding metric information. The query is {query}. Donot add any noise to the response\\',\\n                expected_output=\"some string\",\\n        \\n            )\\n        extracted_metrics = task.execute()\\n\\n        return extracted_metrics\\n    \\n\\n    \\nclass MetricDiscovery(BaseTool):\\n    name :str = \"metric_discovery\"\\n    description:str = \"\"\"Useful for general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\"\"\\n    args_schema: Type[BaseModel] = QueryInput\\n\\n    def _run(\\n        self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None\\n    ) -> str:\\n        \"\"\"Use the tool.\"\"\"\\n        metric_description = self.metric_discovery(query)\\n        return metric_description\\n\\n    async def _arun(\\n        self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None\\n    ) -> str:\\n        \"\"\"Use the tool asynchronously.\"\"\"\\n        raise NotImplementedError(\"custom_search does not support async\")\\n    \\n    \\n    def metric_discovery(self, query, *args, **kwargs):\\n        \"\"\"Useful for general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\"\"\\n        relevant_documents = get_similar_documents(query)\\n        agent = Agent(\\n                role=\\'Data Analyst Assistant\\',\\n                goal=\\n                \\'Empower users to understand and utilize data effectively. This includes helping them discover relevant metrics, interpreting their meaning\\',\\n                backstory=\\n                \"The primary purpose is to bridge the gap between raw data and user comprehension, fostering a data-driven culture within the organization.\",\\n                llm = llm_gpt,\\n                allow_delegation=False)  \\n        \\n        task = Task(\\n                agent=agent,\\n                description=\\n                \"\"\" You are responding to  question {metric_description} with answer from the Metadata provided to you as {relevant_documents}}.\\n                    Strictly answer the question with the information present in metadata only.\\n                    Respond with \"Sorry, the query is out of scope.\" if the answer is not present in metadata and terminate further reasoning and prcoess.\\n                    \"\"\",\\n                expected_output=\"some string\",\\n        \\n            )\\n        output = task.execute()\\n\\n        return output', '# def check_termination(task_output):\\n#     agent = Agent(\\n#                 role=\\'Determine query completion\\',\\n#                 goal=\\n#                 \\'Given task output, determine termination of crew workflow\\',\\n#                 backstory=\\n#                 \"Given user query request from user determine if no more new task is needed to be executed\",\\n#                 llm = llm_gpt,\\n#                 allow_delegation=False)\\n#     task = Task(\\n#                 agent=agent,\\n#                 description=\\n#                 f\\'Given task output, if the query is completed and the task result determines that the query is out of scope then terminate the workflow or else the required query is satisfied. Following is the task result {task_output}\\',\\n#                 expected_output=\"some string\",\\n        \\n#             )\\n#     termination_status = task.execute()\\n#     return termination_status\\nclass MetricDiscoveryTasks():\\n  def metric_isolation(self, agent, query):\\n    return Task(description=(f\"\"\"\\n        Rephrase the query to capture the intent of the user regarding metric information. The query is {query}. Donot add any noise to the response.\\n        {self.__tip_section()}\"\"\"),\\n      agent=agent,\\n      expected_output=\"Reformatted query to capture the intent of the user regarding metric information.\",\\n    )\\n  \\n  def metric_discovery(self, agent):\\n    return Task(description=(f\"\"\"\\n        Answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\\n        {self.__tip_section()}\"\"\"),\\n      agent=agent,\\n      expected_output=\"If relevant metric exists in metadata, provide the answer. Else, respond with \\'Sorry, the query is out of scope.\\' and terminate process.\",\\n    )\\n  def __tip_section(self):\\n    return \"If you do your BEST WORK, I\\'ll give you a $10,000 commission!\"\\n  \\n  ', 'class MetricDiscoveryAgent():\\n  def user_intent_capture(self):\\n    return Agent(\\n      role=\\'Intent Capturer\\',\\n      goal=\\n      \\'Rephrasing the query to capture the intent of the user regarding metric information\\',\\n      backstory=\\n      \"You are an expert to understand the user\\'s intent and rephrase the query to capture the intent of the user accurately.\",\\n      verbose=True,\\n      tools=[\\n        RephraseInputQuery()\\n      ],\\n      llm = llm_gpt,\\n    )\\n  def discover_metric_info(self):\\n    return Agent(\\n     role=\\'Data Analyst Assistant\\',\\n      goal=\\n      \\'Empower users to understand and utilize data effectively. This includes helping them discover relevant metrics, interpreting their meaning\\',\\n      backstory=\\n      \"The primary purpose is to bridge the gap between raw data and user comprehension, fostering a data-driven culture within the organization.\",\\n      llm = llm_gpt,\\n      verbose=True,\\n      tools=[\\n        MetricDiscovery()\\n      ],\\n    )', 'def after_task_callback(output):\\n  # Perform actions after the task, \\n  # for example, logging or updating agent state\\n  \\n  print(f\"Agent completed task with result: {output}\")\\n\\n# Assigning the function to task_callback\\ntask_callback = after_task_callback', 'def test_callback():\\n        # Accessing local variables\\n        print(\"Local variables:\", locals())\\n        \\n        # Accessing global variables\\n        print(\"Global variables:\", globals())    \\n        \\n        # Accessing built-in variables\\n        print(\"Built-in variables:\", dir(__builtins__))\\n        after_task_callback(\"output\")\\n  ', 'from crewai.process import Process\\nclass MetricDiscoveryInputCrew:\\n  def __init__(self, query):\\n    self.query = query\\n    # self.llm = llm_gpt\\n\\n  def run(self):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, self.query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n\\n    result = crew.kickoff()\\n    return result', 'query = \"What is the most popular feature used by our paid subscribers\"\\n# formatted_query = input(\\n#     dedent(\"\"\"\\n#       {What is the most popular feature used by our paid subscribers}\\n#     \"\"\"))\\n# print(formatted_query)\\ncrew = MetricDiscoveryInputCrew(query)\\nresult = crew.run()', 'dir(result)', '# def check_termination(task_output):\\n#     agent = Agent(\\n#                 role=\\'Determine query completion\\',\\n#                 goal=\\n#                 \\'Given task output, determine termination of crew workflow\\',\\n#                 backstory=\\n#                 \"Given user query request from user determine if no more new task is needed to be executed\",\\n#                 llm = llm_gpt,\\n#                 allow_delegation=False)\\n#     task = Task(\\n#                 agent=agent,\\n#                 description=\\n#                 f\\'Given task output, if the query is completed and the task result determines that the query is out of scope then terminate the workflow or else the required query is satisfied. Following is the task result {task_output}\\',\\n#                 expected_output=\"some string\",\\n        \\n#             )\\n#     termination_status = task.execute()\\n#     return termination_status\\nclass MetricDiscoveryTasks():\\n  def metric_isolation(self, agent, query):\\n    return Task(description=(f\"\"\"\\n        Rephrase the query to capture the intent of the user regarding metric information. The query is {query}. Donot add any noise to the response.\\n        {self.__tip_section()}\"\"\"),\\n      agent=agent,\\n      expected_output=\"Reformatted query to capture the intent of the user regarding metric information.\",\\n      callback=callback_function,\\n    )\\n  \\n  def metric_discovery(self, agent):\\n    return Task(description=(f\"\"\"\\n        Answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\\n        {self.__tip_section()}\"\"\"),\\n      agent=agent,\\n      expected_output=\"If relevant metric exists in metadata, provide the answer. Else, respond with \\'Sorry, the query is out of scope.\\' and terminate process.\",\\n      callback=callback_function,\\n    )\\n  def __tip_section(self):\\n    return \"If you do your BEST WORK, I\\'ll give you a $10,000 commission!\"\\n  \\n  ', 'def callback_function(output: TaskOutput):\\n    # Do something after the task is completed\\n    # Example: Send an email to the manager\\n    print(f\"\"\"\\n        Task completed!\\n        Task: {output.description}\\n        Output: {output.raw_output}\\n    \"\"\")', '# def check_termination(task_output):\\n#     agent = Agent(\\n#                 role=\\'Determine query completion\\',\\n#                 goal=\\n#                 \\'Given task output, determine termination of crew workflow\\',\\n#                 backstory=\\n#                 \"Given user query request from user determine if no more new task is needed to be executed\",\\n#                 llm = llm_gpt,\\n#                 allow_delegation=False)\\n#     task = Task(\\n#                 agent=agent,\\n#                 description=\\n#                 f\\'Given task output, if the query is completed and the task result determines that the query is out of scope then terminate the workflow or else the required query is satisfied. Following is the task result {task_output}\\',\\n#                 expected_output=\"some string\",\\n        \\n#             )\\n#     termination_status = task.execute()\\n#     return termination_status\\nclass MetricDiscoveryTasks():\\n  def metric_isolation(self, agent, query):\\n    return Task(description=(f\"\"\"\\n        Rephrase the query to capture the intent of the user regarding metric information. The query is {query}. Donot add any noise to the response.\\n        {self.__tip_section()}\"\"\"),\\n      agent=agent,\\n      expected_output=\"Reformatted query to capture the intent of the user regarding metric information.\",\\n      callback=callback_function,\\n    )\\n  \\n  def metric_discovery(self, agent):\\n    return Task(description=(f\"\"\"\\n        Answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\\n        {self.__tip_section()}\"\"\"),\\n      agent=agent,\\n      expected_output=\"If relevant metric exists in metadata, provide the answer. Else, respond with \\'Sorry, the query is out of scope.\\' and terminate process.\",\\n      callback=callback_function,\\n    )\\n  def __tip_section(self):\\n    return \"If you do your BEST WORK, I\\'ll give you a $10,000 commission!\"\\n  \\n  ', 'class MetricDiscoveryAgent():\\n  def user_intent_capture(self):\\n    return Agent(\\n      role=\\'Intent Capturer\\',\\n      goal=\\n      \\'Rephrasing the query to capture the intent of the user regarding metric information\\',\\n      backstory=\\n      \"You are an expert to understand the user\\'s intent and rephrase the query to capture the intent of the user accurately.\",\\n      verbose=True,\\n      tools=[\\n        RephraseInputQuery()\\n      ],\\n      llm = llm_gpt,\\n    )\\n  def discover_metric_info(self):\\n    return Agent(\\n     role=\\'Data Analyst Assistant\\',\\n      goal=\\n      \\'Empower users to understand and utilize data effectively. This includes helping them discover relevant metrics, interpreting their meaning\\',\\n      backstory=\\n      \"The primary purpose is to bridge the gap between raw data and user comprehension, fostering a data-driven culture within the organization.\",\\n      llm = llm_gpt,\\n      verbose=True,\\n      tools=[\\n        MetricDiscovery()\\n      ],\\n    )', 'def after_task_callback(output):\\n  # Perform actions after the task, \\n  # for example, logging or updating agent state\\n  \\n  print(f\"Agent completed task with result: {output}\")\\n\\n# Assigning the function to task_callback\\ntask_callback = after_task_callback', 'def test_callback():\\n        # Accessing local variables\\n        print(\"Local variables:\", locals())\\n        \\n        # Accessing global variables\\n        print(\"Global variables:\", globals())    \\n        \\n        # Accessing built-in variables\\n        print(\"Built-in variables:\", dir(__builtins__))\\n        after_task_callback(\"output\")\\n  ', 'from crewai.process import Process\\nclass MetricDiscoveryInputCrew:\\n  def __init__(self, query):\\n    self.query = query\\n    # self.llm = llm_gpt\\n\\n  def run(self):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, self.query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n\\n    result = crew.kickoff()\\n    return result', 'query = \"What is the most popular feature used by our paid subscribers\"\\n# formatted_query = input(\\n#     dedent(\"\"\"\\n#       {What is the most popular feature used by our paid subscribers}\\n#     \"\"\"))\\n# print(formatted_query)\\ncrew = MetricDiscoveryInputCrew(query)\\nresult = crew.run()', '# def check_termination(task_output):\\n#     agent = Agent(\\n#                 role=\\'Determine query completion\\',\\n#                 goal=\\n#                 \\'Given task output, determine termination of crew workflow\\',\\n#                 backstory=\\n#                 \"Given user query request from user determine if no more new task is needed to be executed\",\\n#                 llm = llm_gpt,\\n#                 allow_delegation=False)\\n#     task = Task(\\n#                 agent=agent,\\n#                 description=\\n#                 f\\'Given task output, if the query is completed and the task result determines that the query is out of scope then terminate the workflow or else the required query is satisfied. Following is the task result {task_output}\\',\\n#                 expected_output=\"some string\",\\n        \\n#             )\\n#     termination_status = task.execute()\\n#     return termination_status\\nclass MetricDiscoveryTasks():\\n  def metric_isolation(self, agent, query):\\n    return Task(description=(f\"\"\"\\n        Rephrase the query to capture the intent of the user regarding metric information. The query is {query}. Donot add any noise to the response.\\n        {self.__tip_section()}\"\"\"),\\n      agent=agent,\\n      expected_output=\"Reformatted query to capture the intent of the user regarding metric information.\",\\n      # callback=callback_function,\\n    )\\n  \\n  def metric_discovery(self, agent):\\n    return Task(description=(f\"\"\"\\n        Answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\\n        {self.__tip_section()}\"\"\"),\\n      agent=agent,\\n      expected_output=\"If relevant metric exists in metadata, provide the answer. Else, respond with \\'Sorry, the query is out of scope.\\' and terminate process.\",\\n      # callback=callback_function,\\n    )\\n  def __tip_section(self):\\n    return \"If you do your BEST WORK, I\\'ll give you a $10,000 commission!\"\\n  \\n  ', 'class MetricDiscoveryAgent():\\n  def user_intent_capture(self):\\n    return Agent(\\n      role=\\'Intent Capturer\\',\\n      goal=\\n      \\'Rephrasing the query to capture the intent of the user regarding metric information\\',\\n      backstory=\\n      \"You are an expert to understand the user\\'s intent and rephrase the query to capture the intent of the user accurately.\",\\n      verbose=True,\\n      tools=[\\n        RephraseInputQuery()\\n      ],\\n      llm = llm_gpt,\\n    )\\n  def discover_metric_info(self):\\n    return Agent(\\n     role=\\'Data Analyst Assistant\\',\\n      goal=\\n      \\'Empower users to understand and utilize data effectively. This includes helping them discover relevant metrics, interpreting their meaning\\',\\n      backstory=\\n      \"The primary purpose is to bridge the gap between raw data and user comprehension, fostering a data-driven culture within the organization.\",\\n      llm = llm_gpt,\\n      verbose=True,\\n      tools=[\\n        MetricDiscovery()\\n      ],\\n    )', 'def after_task_callback(output):\\n  # Perform actions after the task, \\n  # for example, logging or updating agent state\\n  \\n  print(f\"Agent completed task with result: {output}\")\\n\\n# Assigning the function to task_callback\\ntask_callback = after_task_callback', 'def test_callback():\\n        # Accessing local variables\\n        print(\"Local variables:\", locals())\\n        \\n        # Accessing global variables\\n        print(\"Global variables:\", globals())    \\n        \\n        # Accessing built-in variables\\n        print(\"Built-in variables:\", dir(__builtins__))\\n        after_task_callback(\"output\")\\n  ', 'from crewai.process import Process\\nclass MetricDiscoveryInputCrew:\\n  def __init__(self, query):\\n    self.query = query\\n    # self.llm = llm_gpt\\n\\n  def run(self):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, self.query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n\\n    result = crew.kickoff()\\n    return result', 'query = \"What is the most popular feature used by our paid subscribers\"\\n# formatted_query = input(\\n#     dedent(\"\"\"\\n#       {What is the most popular feature used by our paid subscribers}\\n#     \"\"\"))\\n# print(formatted_query)\\ncrew = MetricDiscoveryInputCrew(query)', 'dir(crew)', 'from crewai.process import Process\\nfrom typing import Any\\nclass MetricDiscoveryInputCrew(Expert):\\n  description = (\\n       \"Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\\n    )\\n  public_description = \"Metric discovery crew\"\\n  arg_description = \"Query for metrics to be processed by the crew.\"\\n\\n  def __init__(self, query):\\n    self.query = query\\n    self.crew_process = self.crew_process()\\n    # self.llm = llm_gpt\\n  def crew_process(self):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, self.query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n    self.crew_process = crew\\n\\n  def run(self):\\n    result = self.crew_process.kickoff()\\n    return result\\n  \\n  def call(\\n        self, goal: str, task: str, input_str: str, *args: Any, **kwargs: Any\\n    ) -> str:\\n    pass', 'from abc import ABC, abstractmethod\\nclass Expert(ABC):\\n    description: str = \"\"\\n    public_description: str = \"\"\\n    arg_description: str = \"The argument to the function.\"\\n\\n    @abstractmethod\\n    def call(\\n        self,\\n        goal: str,\\n        task: str,\\n        input_str: str,\\n    ) -> str:\\n        pass', 'from crewai.process import Process\\nfrom typing import Any\\nclass MetricDiscoveryInputCrew(Expert):\\n  description = (\\n       \"Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\\n    )\\n  public_description = \"Metric discovery crew\"\\n  arg_description = \"Query for metrics to be processed by the crew.\"\\n\\n  def __init__(self, query):\\n    self.query = query\\n    self.crew_process = self.crew_process()\\n    # self.llm = llm_gpt\\n  def crew_process(self):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, self.query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n    self.crew_process = crew\\n\\n  def run(self):\\n    result = self.crew_process.kickoff()\\n    return result\\n  \\n  def call(\\n        self, goal: str, task: str, input_str: str, *args: Any, **kwargs: Any\\n    ) -> str:\\n    pass', '#Available experts\\nfrom typing import Any, Dict, List, Optional, Union\\nfrom typing import Type, TypedDict\\n\\nclass ExpertDescription(TypedDict):\\n    \"\"\"Representation of a callable expert\"\"\"\\n    name: str\\n    \"\"\"The name of the expert.\"\"\"\\n    description: str\\n    \"\"\"A description of the expert.\"\"\"\\n    parameters: dict[str, object]\\n    \"\"\"The parameters of the expert.\"\"\"\\n\\ndef get_expert_function(expert: Type[Expert]) -> ExpertDescription:\\n    \"\"\"A function that will return the tool\\'s function specification\"\"\"\\n    name = get_expert_name(tool)\\n\\n    return {\\n        \"name\": name,\\n        \"description\": expert.description,\\n        \"parameters\": {\\n            \"type\": \"object\",\\n            \"properties\": {\\n                \"reasoning\": {\\n                    \"type\": \"string\",\\n                    \"description\": (\\n                        f\"Reasoning is how the task will be accomplished with the current expert. \"\\n                        \"Detail your overall plan along with any concerns you have.\"\\n                        \"Ensure this reasoning value is in the user defined langauge \"\\n                    ),\\n                },\\n                \"arg\": {\\n                    \"type\": \"string\",\\n                    \"description\": expert.arg_description,\\n                },\\n            },\\n            \"required\": [\"reasoning\", \"arg\"],\\n        },\\n    }\\n\\ndef get_expert_name(expert: Type[Expert]) -> str:\\n    return format_expert_name(expert.__name__)\\n\\ndef format_expert_name(expert_name: str) -> str:\\n    return expert_name.lower()\\n\\ndef get_available_experts() -> List[Type[Expert]]:\\n    return [\\n        MetricDiscoveryInputCrew\\n    ]', \"available_experts = get_available_experts()\\nexperts = list(map(get_expert_function, available_experts))\\nexpert_descriptions = {expert['name'] : expert['description'] for expert in experts}\", 'expert_descriptions', 'experts', 'from abc import ABC, abstractmethod\\nclass Expert(ABC):\\n    name: str = \"\"\\n    description: str = \"\"\\n    public_description: str = \"\"\\n    arg_description: str = \"The argument to the function.\"\\n\\n    @abstractmethod\\n    def call(\\n        self,\\n        goal: str,\\n        task: str,\\n        input_str: str,\\n    ) -> str:\\n        pass', 'from crewai.process import Process\\nfrom typing import Any\\nclass MetricDiscoveryInputCrew(Expert):\\n  name = \"MetricDiscovery\"\\n  description = (\\n       \"Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\\n    )\\n  public_description = \"Metric discovery crew\"\\n  arg_description = \"Query related to metrics.\"\\n\\n  def __init__(self, query):\\n    self.query = query\\n    self.crew_process = self.crew_process()\\n    # self.llm = llm_gpt\\n  def crew_process(self):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    # print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, self.query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n    self.crew_process = crew\\n\\n  def run(self):\\n    result = self.crew_process.kickoff()\\n    return result\\n  \\n  def call(\\n        self, goal: str, task: str, input_str: str, *args: Any, **kwargs: Any\\n    ) -> str:\\n    pass', 'query = \"What is the most popular feature used by our paid subscribers\"\\n# formatted_query = input(\\n#     dedent(\"\"\"\\n#       {What is the most popular feature used by our paid subscribers}\\n#     \"\"\"))\\n# print(formatted_query)\\ncrew = MetricDiscoveryInputCrew(query)\\nresult = crew.run()'], 'Out': {11: ['__add__', '__class__', '__contains__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getnewargs__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mod__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__rmod__', '__rmul__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'capitalize', 'casefold', 'center', 'count', 'encode', 'endswith', 'expandtabs', 'find', 'format', 'format_map', 'index', 'isalnum', 'isalpha', 'isascii', 'isdecimal', 'isdigit', 'isidentifier', 'islower', 'isnumeric', 'isprintable', 'isspace', 'istitle', 'isupper', 'join', 'ljust', 'lower', 'lstrip', 'maketrans', 'partition', 'removeprefix', 'removesuffix', 'replace', 'rfind', 'rindex', 'rjust', 'rpartition', 'rsplit', 'rstrip', 'split', 'splitlines', 'startswith', 'strip', 'swapcase', 'title', 'translate', 'upper', 'zfill'], 26: ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'query', 'run'], 32: {'tool': 'Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.'}, 33: [{'name': 'tool', 'description': 'Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.', 'parameters': {'type': 'object', 'properties': {'reasoning': {'type': 'string', 'description': 'Reasoning is how the task will be accomplished with the current expert. Detail your overall plan along with any concerns you have.Ensure this reasoning value is in the user defined langauge '}, 'arg': {'type': 'string', 'description': 'Query for metrics to be processed by the crew.'}}, 'required': ['reasoning', 'arg']}}]}, 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x10ce4e4d0>>, 'exit': <IPython.core.autocall.ZMQExitAutocall object at 0x10ce62b10>, 'quit': <IPython.core.autocall.ZMQExitAutocall object at 0x10ce62b10>, 'open': <function open at 0x10bb7d440>, '_': [{'name': 'tool', 'description': 'Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.', 'parameters': {'type': 'object', 'properties': {'reasoning': {'type': 'string', 'description': 'Reasoning is how the task will be accomplished with the current expert. Detail your overall plan along with any concerns you have.Ensure this reasoning value is in the user defined langauge '}, 'arg': {'type': 'string', 'description': 'Query for metrics to be processed by the crew.'}}, 'required': ['reasoning', 'arg']}}], '__': {'tool': 'Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.'}, '___': ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'query', 'run'], '__vsc_ipynb_file__': '/Users/k.abhishek/Documents/experiments/metric_store/metric_store_gen_ai/experiments/agent_flow_v2.ipynb', '_i': 'from crewai.process import Process\\nfrom typing import Any\\nclass MetricDiscoveryInputCrew(Expert):\\n  name = \"MetricDiscovery\"\\n  description = (\\n       \"Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\\n    )\\n  public_description = \"Metric discovery crew\"\\n  arg_description = \"Query related to metrics.\"\\n\\n  def __init__(self, query):\\n    self.query = query\\n    self.crew_process = self.crew_process()\\n    # self.llm = llm_gpt\\n  def crew_process(self):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    # print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, self.query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n    self.crew_process = crew\\n\\n  def run(self):\\n    result = self.crew_process.kickoff()\\n    return result\\n  \\n  def call(\\n        self, goal: str, task: str, input_str: str, *args: Any, **kwargs: Any\\n    ) -> str:\\n    pass', '_ii': 'from abc import ABC, abstractmethod\\nclass Expert(ABC):\\n    name: str = \"\"\\n    description: str = \"\"\\n    public_description: str = \"\"\\n    arg_description: str = \"The argument to the function.\"\\n\\n    @abstractmethod\\n    def call(\\n        self,\\n        goal: str,\\n        task: str,\\n        input_str: str,\\n    ) -> str:\\n        pass', '_iii': 'experts', '_i1': '#initialize\\n#     model\\n#     environment variables\\n\\nimport sys\\nsys.path.append(\\'..\\')\\nfrom src.utils.llamaindex_retriever import LlamaIndexRetriever\\nfrom langchain.vectorstores import FAISS\\nfrom langchain.embeddings.azure_openai import AzureOpenAIEmbeddings\\nfrom langchain.embeddings.openai import OpenAIEmbeddings\\nfrom dotenv import load_dotenv\\nimport os\\nfrom langchain.chat_models import AzureChatOpenAI\\n\\ndef load_env_variables(file_path):\\n    load_dotenv(file_path)\\n    print(\"Environment variables loaded successfully!\")\\n\\nenv_file_path = \"../.env\"\\nload_env_variables = load_env_variables(env_file_path)\\nmax_tokens = 3500\\ntemperature = 0.1\\n\\n# embeddings = AzureOpenAIEmbeddings(azure_deployment=azure_deployment, openai_api_version=openai_api_version)\\nembeddings =  AzureOpenAIEmbeddings(\\n        deployment=os.getenv(\"EMB_DEPLOYMENT\"),\\n        openai_api_version=os.getenv(\"EMB_OPENAI_API_VERSION\"),\\n        model=os.getenv(\"EMB_MODEL\"),\\n        openai_api_key=os.getenv(\"EMB_OPENAI_API_KEY\"),\\n        openai_api_base=os.getenv(\"EMB_OPENAI_ENDPOINT\"),\\n        openai_api_type=os.getenv(\"EMB_API_TYPE\"),\\n    )\\n\\nllm_gpt = AzureChatOpenAI(deployment_name=os.getenv(\\'AZURE_OPENAI_DEPLOYMENT_NAME\\'), openai_api_version=os.getenv(\"OPENAI_API_VERSION\"),\\n                        openai_api_base=os.getenv(\"OPENAI_API_BASE\"), \\n                        openai_api_type= os.getenv(\"OPENAI_API_TYPE\"),\\n                        openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\\n                        max_tokens=max_tokens,\\n                        temperature=temperature)', 'sys': <module 'sys' (built-in)>, 'LlamaIndexRetriever': <class 'src.utils.llamaindex_retriever.LlamaIndexRetriever'>, 'FAISS': <class 'langchain_community.vectorstores.faiss.FAISS'>, 'AzureOpenAIEmbeddings': <class 'langchain_community.embeddings.azure_openai.AzureOpenAIEmbeddings'>, 'OpenAIEmbeddings': <class 'langchain_community.embeddings.openai.OpenAIEmbeddings'>, 'load_dotenv': <function load_dotenv at 0x1381bd300>, 'os': <module 'os' (frozen)>, 'AzureChatOpenAI': <class 'langchain_community.chat_models.azure_openai.AzureChatOpenAI'>, 'load_env_variables': None, 'env_file_path': '../.env', 'max_tokens': 3500, 'temperature': 0.1, 'embeddings': AzureOpenAIEmbeddings(client=<openai.resources.embeddings.Embeddings object at 0x138292ed0>, async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x138292bd0>, model='text-embedding-ada-002', deployment=None, openai_api_version='2023-03-15-preview', openai_api_base='https://polarisopenai.openai.azure.com//openai/deployments/text-embedding-ada-002', openai_api_type='azure', openai_proxy='', embedding_ctx_length=8191, openai_api_key='35431d6cd1874798b9ebbd6bdfbb0720', openai_organization=None, allowed_special=set(), disallowed_special='all', chunk_size=16, max_retries=2, request_timeout=None, headers=None, tiktoken_enabled=True, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, retry_min_seconds=4, retry_max_seconds=20, http_client=None, azure_endpoint=None, azure_ad_token=None, azure_ad_token_provider=None, validate_base_url=True), 'llm_gpt': AzureChatOpenAI(callbacks=[<crewai.utilities.token_counter_callback.TokenCalcHandler object at 0x13c4e4dd0>], client=<openai.resources.chat.completions.Completions object at 0x137639150>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x13836b850>, temperature=0.1, openai_api_key='43b8528ab70d48359744cd0165a1167e', openai_api_base='https://polariseastus2.openai.azure.com/openai/deployments/gpt4-turbo', openai_proxy='', max_tokens=3500, openai_api_version='2023-07-01-preview', openai_api_type='azure'), '_i2': '#define utils\\nfrom src.utils.cube_semantic_custom import CubeSemanticLoader\\ndef fetch_cube_metadata(*args, **kwargs):\\n    try:\\n        # # Load document from Cube meta api\\n        loader = CubeSemanticLoader(os.getenv(\"CUBE_API_URL\"), os.getenv(\"CUBE_TOKEN\"), False)\\n        documents = loader.load()\\n        # to_json()\\n        return documents\\n    except Exception as e:\\n        # Handle exceptions gracefully and return an error response\\n        print(\"Error in fetching metadata from cube: \" + str(e))\\n        return 0\\n\\ndef create_vector_store(documents, local_vector_store_path, *args, **kwargs):\\n    print(\"Loaded documents: \" + str(documents))\\n    vectorstore = FAISS.from_documents(documents, embeddings)\\n    vectorstore.save_local(local_vector_store_path)\\n    print(\"Vector store created and saved successfully!\")\\n\\ndef load_vector_store(vector_store_path, embeddings, *args, **kwargs):\\n    # Load the vector store from the local file system\\n    vectorstore = FAISS.load_local(vector_store_path, embeddings, allow_dangerous_deserialization=True)\\n    print(\"Vector store loaded successfully!\")\\n    \\n    return vectorstore', 'CubeSemanticLoader': <class 'src.utils.cube_semantic_custom.CubeSemanticLoader'>, 'fetch_cube_metadata': <function fetch_cube_metadata at 0x10cefc0e0>, 'create_vector_store': <function create_vector_store at 0x138378180>, 'load_vector_store': <function load_vector_store at 0x138378360>, '_i3': '#load existing vector store\\nvector_store_path = \"/Users/k.abhishek/Documents/experiments/metric_store/metric_store_gen_ai/data/vector_store/cube_meta_faiss_index\"\\nvectorstore = load_vector_store(vector_store_path, embeddings)', 'vector_store_path': '/Users/k.abhishek/Documents/experiments/metric_store/metric_store_gen_ai/data/vector_store/cube_meta_faiss_index', 'vectorstore': <langchain_community.vectorstores.faiss.FAISS object at 0x10ceb61d0>, '_i4': 'import json\\nfrom crewai import Agent, Task, Crew\\nfrom langchain.tools import tool\\nfrom src.utils.llamaindex_retriever import LlamaIndexRetriever\\nfrom typing import Optional, Type\\nfrom langchain.callbacks.manager import (\\n    AsyncCallbackManagerForToolRun,\\n    CallbackManagerForToolRun,\\n)\\n# Import things that are needed generically\\nfrom langchain.pydantic_v1 import BaseModel, Field\\n# from langchain.tools import BaseTool, StructuredTool, tool\\nfrom crewai_tools import BaseTool\\n\\n\\ndef get_similar_documents_faiss(query, max_number_documents=3):\\n  vectorstore = FAISS.load_local(vector_store_path, embeddings, allow_dangerous_deserialization=True)\\n  docs = vectorstore.similarity_search_with_relevance_scores(query, max_number_documents)\\n  relevant_documents = []\\n  for doc in docs:\\n      doc = doc[0]\\n      meta = {\\'text\\':doc.page_content, \\'table_metadata\\': doc.metadata}\\n      relevant_documents.append(meta)\\n  return relevant_documents\\n\\ndef get_similar_documents(query, max_number_documents=3):\\n    return get_similar_documents_faiss(query, max_number_documents)\\n\\n\\nclass QueryInput(BaseModel):\\n    query: str = Field(description=\"should be enquiry query\")\\n\\n\\nclass RephraseInputQuery(BaseTool):\\n    name:str = \"rephrase_input_query\"\\n    description :str = \"Useful to rephrase the query to capture the intent of the user regarding metric information\"\\n    args_schema: Type[BaseModel] = QueryInput\\n\\n    def _run(\\n        self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None\\n    ) -> str:\\n        \"\"\"Use the tool.\"\"\"\\n        metric_description = self.rephrase_input_query(query)\\n        return metric_description\\n\\n    async def _arun(\\n        self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None\\n    ) -> str:\\n        \"\"\"Use the tool asynchronously.\"\"\"\\n        raise NotImplementedError(\"custom_search does not support async\")\\n    \\n    \\n    def rephrase_input_query(self, query, *args, **kwargs):\\n        agent = Agent(\\n                role=\\'Intent Capturer\\',\\n                goal=\\n                \\'Rephrasing the query to capture the intent of the user regarding metric information\\',\\n                backstory=\\n                \"You are an expert to understand the user\\'s intent and rephrase the query to capture the intent of the user accurately.\",\\n                llm = llm_gpt,\\n                allow_delegation=False)\\n        task = Task(\\n                agent=agent,\\n                description=\\n                f\\'Rephrase the query to capture the intent of the user regarding metric information. The query is {query}. Donot add any noise to the response\\',\\n                expected_output=\"some string\",\\n        \\n            )\\n        extracted_metrics = task.execute()\\n\\n        return extracted_metrics\\n    \\n\\n    \\nclass MetricDiscovery(BaseTool):\\n    name :str = \"metric_discovery\"\\n    description:str = \"\"\"Useful for general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\"\"\\n    args_schema: Type[BaseModel] = QueryInput\\n\\n    def _run(\\n        self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None\\n    ) -> str:\\n        \"\"\"Use the tool.\"\"\"\\n        metric_description = self.metric_discovery(query)\\n        return metric_description\\n\\n    async def _arun(\\n        self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None\\n    ) -> str:\\n        \"\"\"Use the tool asynchronously.\"\"\"\\n        raise NotImplementedError(\"custom_search does not support async\")\\n    \\n    \\n    def metric_discovery(self, query, *args, **kwargs):\\n        \"\"\"Useful for general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\"\"\\n        relevant_documents = get_similar_documents(query)\\n        agent = Agent(\\n                role=\\'Data Analyst Assistant\\',\\n                goal=\\n                \\'Empower users to understand and utilize data effectively. This includes helping them discover relevant metrics, interpreting their meaning\\',\\n                backstory=\\n                \"The primary purpose is to bridge the gap between raw data and user comprehension, fostering a data-driven culture within the organization.\",\\n                llm = llm_gpt,\\n                allow_delegation=False)  \\n        \\n        task = Task(\\n                agent=agent,\\n                description=\\n                \"\"\" You are responding to  question {metric_description} with answer from the Metadata provided to you as {relevant_documents}}.\\n                    Strictly answer the question with the information present in metadata only.\\n                    Respond with \"Sorry, the query is out of scope.\" if the answer is not present in metadata and terminate further reasoning and prcoess.\\n                    \"\"\",\\n                expected_output=\"some string\",\\n        \\n            )\\n        output = task.execute()\\n\\n        return output', 'json': <module 'json' from '/Users/k.abhishek/anaconda3/envs/agentgpt/lib/python3.11/json/__init__.py'>, 'Agent': <class 'crewai.agent.Agent'>, 'Task': <class 'crewai.task.Task'>, 'Crew': <class 'crewai.crew.Crew'>, 'tool': <function tool at 0x13884c040>, 'Optional': typing.Optional, 'Type': typing.Type, 'AsyncCallbackManagerForToolRun': <class 'langchain_core.callbacks.manager.AsyncCallbackManagerForToolRun'>, 'CallbackManagerForToolRun': <class 'langchain_core.callbacks.manager.CallbackManagerForToolRun'>, 'BaseModel': <class 'pydantic.v1.main.BaseModel'>, 'Field': <function Field at 0x10cf7ef20>, 'BaseTool': <class 'crewai_tools.tools.base_tool.BaseTool'>, 'get_similar_documents_faiss': <function get_similar_documents_faiss at 0x138353d80>, 'get_similar_documents': <function get_similar_documents at 0x13864b7e0>, 'QueryInput': <class '__main__.QueryInput'>, 'RephraseInputQuery': <class '__main__.RephraseInputQuery'>, 'MetricDiscovery': <class '__main__.MetricDiscovery'>, '_i5': '# def check_termination(task_output):\\n#     agent = Agent(\\n#                 role=\\'Determine query completion\\',\\n#                 goal=\\n#                 \\'Given task output, determine termination of crew workflow\\',\\n#                 backstory=\\n#                 \"Given user query request from user determine if no more new task is needed to be executed\",\\n#                 llm = llm_gpt,\\n#                 allow_delegation=False)\\n#     task = Task(\\n#                 agent=agent,\\n#                 description=\\n#                 f\\'Given task output, if the query is completed and the task result determines that the query is out of scope then terminate the workflow or else the required query is satisfied. Following is the task result {task_output}\\',\\n#                 expected_output=\"some string\",\\n        \\n#             )\\n#     termination_status = task.execute()\\n#     return termination_status\\nclass MetricDiscoveryTasks():\\n  def metric_isolation(self, agent, query):\\n    return Task(description=(f\"\"\"\\n        Rephrase the query to capture the intent of the user regarding metric information. The query is {query}. Donot add any noise to the response.\\n        {self.__tip_section()}\"\"\"),\\n      agent=agent,\\n      expected_output=\"Reformatted query to capture the intent of the user regarding metric information.\",\\n    )\\n  \\n  def metric_discovery(self, agent):\\n    return Task(description=(f\"\"\"\\n        Answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\\n        {self.__tip_section()}\"\"\"),\\n      agent=agent,\\n      expected_output=\"If relevant metric exists in metadata, provide the answer. Else, respond with \\'Sorry, the query is out of scope.\\' and terminate process.\",\\n    )\\n  def __tip_section(self):\\n    return \"If you do your BEST WORK, I\\'ll give you a $10,000 commission!\"\\n  \\n  ', 'MetricDiscoveryTasks': <class '__main__.MetricDiscoveryTasks'>, '_i6': 'class MetricDiscoveryAgent():\\n  def user_intent_capture(self):\\n    return Agent(\\n      role=\\'Intent Capturer\\',\\n      goal=\\n      \\'Rephrasing the query to capture the intent of the user regarding metric information\\',\\n      backstory=\\n      \"You are an expert to understand the user\\'s intent and rephrase the query to capture the intent of the user accurately.\",\\n      verbose=True,\\n      tools=[\\n        RephraseInputQuery()\\n      ],\\n      llm = llm_gpt,\\n    )\\n  def discover_metric_info(self):\\n    return Agent(\\n     role=\\'Data Analyst Assistant\\',\\n      goal=\\n      \\'Empower users to understand and utilize data effectively. This includes helping them discover relevant metrics, interpreting their meaning\\',\\n      backstory=\\n      \"The primary purpose is to bridge the gap between raw data and user comprehension, fostering a data-driven culture within the organization.\",\\n      llm = llm_gpt,\\n      verbose=True,\\n      tools=[\\n        MetricDiscovery()\\n      ],\\n    )', 'MetricDiscoveryAgent': <class '__main__.MetricDiscoveryAgent'>, '_i7': 'def after_task_callback(output):\\n  # Perform actions after the task, \\n  # for example, logging or updating agent state\\n  \\n  print(f\"Agent completed task with result: {output}\")\\n\\n# Assigning the function to task_callback\\ntask_callback = after_task_callback', 'after_task_callback': <function after_task_callback at 0x13cd14cc0>, 'task_callback': <function after_task_callback at 0x13cd14cc0>, '_i8': 'def test_callback():\\n        # Accessing local variables\\n        print(\"Local variables:\", locals())\\n        \\n        # Accessing global variables\\n        print(\"Global variables:\", globals())    \\n        \\n        # Accessing built-in variables\\n        print(\"Built-in variables:\", dir(__builtins__))\\n        after_task_callback(\"output\")\\n  ', 'test_callback': <function test_callback at 0x13cd142c0>, '_i9': 'from crewai.process import Process\\nclass MetricDiscoveryInputCrew:\\n  def __init__(self, query):\\n    self.query = query\\n    # self.llm = llm_gpt\\n\\n  def run(self):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, self.query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n\\n    result = crew.kickoff()\\n    return result', 'Process': <enum 'Process'>, 'MetricDiscoveryInputCrew': <class '__main__.MetricDiscoveryInputCrew'>, '_i10': 'query = \"What is the most popular feature used by our paid subscribers\"\\n# formatted_query = input(\\n#     dedent(\"\"\"\\n#       {What is the most popular feature used by our paid subscribers}\\n#     \"\"\"))\\n# print(formatted_query)\\ncrew = MetricDiscoveryInputCrew(query)\\nresult = crew.run()', 'query': 'What is the most popular feature used by our paid subscribers', 'crew': <__main__.MetricDiscoveryInputCrew object at 0x13ccc5bd0>, 'result': 'Sorry, the query is out of scope.', '_i11': 'dir(result)', '_11': ['__add__', '__class__', '__contains__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getnewargs__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mod__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__rmod__', '__rmul__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'capitalize', 'casefold', 'center', 'count', 'encode', 'endswith', 'expandtabs', 'find', 'format', 'format_map', 'index', 'isalnum', 'isalpha', 'isascii', 'isdecimal', 'isdigit', 'isidentifier', 'islower', 'isnumeric', 'isprintable', 'isspace', 'istitle', 'isupper', 'join', 'ljust', 'lower', 'lstrip', 'maketrans', 'partition', 'removeprefix', 'removesuffix', 'replace', 'rfind', 'rindex', 'rjust', 'rpartition', 'rsplit', 'rstrip', 'split', 'splitlines', 'startswith', 'strip', 'swapcase', 'title', 'translate', 'upper', 'zfill'], '_i12': '# def check_termination(task_output):\\n#     agent = Agent(\\n#                 role=\\'Determine query completion\\',\\n#                 goal=\\n#                 \\'Given task output, determine termination of crew workflow\\',\\n#                 backstory=\\n#                 \"Given user query request from user determine if no more new task is needed to be executed\",\\n#                 llm = llm_gpt,\\n#                 allow_delegation=False)\\n#     task = Task(\\n#                 agent=agent,\\n#                 description=\\n#                 f\\'Given task output, if the query is completed and the task result determines that the query is out of scope then terminate the workflow or else the required query is satisfied. Following is the task result {task_output}\\',\\n#                 expected_output=\"some string\",\\n        \\n#             )\\n#     termination_status = task.execute()\\n#     return termination_status\\nclass MetricDiscoveryTasks():\\n  def metric_isolation(self, agent, query):\\n    return Task(description=(f\"\"\"\\n        Rephrase the query to capture the intent of the user regarding metric information. The query is {query}. Donot add any noise to the response.\\n        {self.__tip_section()}\"\"\"),\\n      agent=agent,\\n      expected_output=\"Reformatted query to capture the intent of the user regarding metric information.\",\\n      callback=callback_function,\\n    )\\n  \\n  def metric_discovery(self, agent):\\n    return Task(description=(f\"\"\"\\n        Answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\\n        {self.__tip_section()}\"\"\"),\\n      agent=agent,\\n      expected_output=\"If relevant metric exists in metadata, provide the answer. Else, respond with \\'Sorry, the query is out of scope.\\' and terminate process.\",\\n      callback=callback_function,\\n    )\\n  def __tip_section(self):\\n    return \"If you do your BEST WORK, I\\'ll give you a $10,000 commission!\"\\n  \\n  ', '_i13': 'def callback_function(output: TaskOutput):\\n    # Do something after the task is completed\\n    # Example: Send an email to the manager\\n    print(f\"\"\"\\n        Task completed!\\n        Task: {output.description}\\n        Output: {output.raw_output}\\n    \"\"\")', '_i14': '# def check_termination(task_output):\\n#     agent = Agent(\\n#                 role=\\'Determine query completion\\',\\n#                 goal=\\n#                 \\'Given task output, determine termination of crew workflow\\',\\n#                 backstory=\\n#                 \"Given user query request from user determine if no more new task is needed to be executed\",\\n#                 llm = llm_gpt,\\n#                 allow_delegation=False)\\n#     task = Task(\\n#                 agent=agent,\\n#                 description=\\n#                 f\\'Given task output, if the query is completed and the task result determines that the query is out of scope then terminate the workflow or else the required query is satisfied. Following is the task result {task_output}\\',\\n#                 expected_output=\"some string\",\\n        \\n#             )\\n#     termination_status = task.execute()\\n#     return termination_status\\nclass MetricDiscoveryTasks():\\n  def metric_isolation(self, agent, query):\\n    return Task(description=(f\"\"\"\\n        Rephrase the query to capture the intent of the user regarding metric information. The query is {query}. Donot add any noise to the response.\\n        {self.__tip_section()}\"\"\"),\\n      agent=agent,\\n      expected_output=\"Reformatted query to capture the intent of the user regarding metric information.\",\\n      callback=callback_function,\\n    )\\n  \\n  def metric_discovery(self, agent):\\n    return Task(description=(f\"\"\"\\n        Answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\\n        {self.__tip_section()}\"\"\"),\\n      agent=agent,\\n      expected_output=\"If relevant metric exists in metadata, provide the answer. Else, respond with \\'Sorry, the query is out of scope.\\' and terminate process.\",\\n      callback=callback_function,\\n    )\\n  def __tip_section(self):\\n    return \"If you do your BEST WORK, I\\'ll give you a $10,000 commission!\"\\n  \\n  ', '_i15': 'class MetricDiscoveryAgent():\\n  def user_intent_capture(self):\\n    return Agent(\\n      role=\\'Intent Capturer\\',\\n      goal=\\n      \\'Rephrasing the query to capture the intent of the user regarding metric information\\',\\n      backstory=\\n      \"You are an expert to understand the user\\'s intent and rephrase the query to capture the intent of the user accurately.\",\\n      verbose=True,\\n      tools=[\\n        RephraseInputQuery()\\n      ],\\n      llm = llm_gpt,\\n    )\\n  def discover_metric_info(self):\\n    return Agent(\\n     role=\\'Data Analyst Assistant\\',\\n      goal=\\n      \\'Empower users to understand and utilize data effectively. This includes helping them discover relevant metrics, interpreting their meaning\\',\\n      backstory=\\n      \"The primary purpose is to bridge the gap between raw data and user comprehension, fostering a data-driven culture within the organization.\",\\n      llm = llm_gpt,\\n      verbose=True,\\n      tools=[\\n        MetricDiscovery()\\n      ],\\n    )', '_i16': 'def after_task_callback(output):\\n  # Perform actions after the task, \\n  # for example, logging or updating agent state\\n  \\n  print(f\"Agent completed task with result: {output}\")\\n\\n# Assigning the function to task_callback\\ntask_callback = after_task_callback', '_i17': 'def test_callback():\\n        # Accessing local variables\\n        print(\"Local variables:\", locals())\\n        \\n        # Accessing global variables\\n        print(\"Global variables:\", globals())    \\n        \\n        # Accessing built-in variables\\n        print(\"Built-in variables:\", dir(__builtins__))\\n        after_task_callback(\"output\")\\n  ', '_i18': 'from crewai.process import Process\\nclass MetricDiscoveryInputCrew:\\n  def __init__(self, query):\\n    self.query = query\\n    # self.llm = llm_gpt\\n\\n  def run(self):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, self.query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n\\n    result = crew.kickoff()\\n    return result', '_i19': 'query = \"What is the most popular feature used by our paid subscribers\"\\n# formatted_query = input(\\n#     dedent(\"\"\"\\n#       {What is the most popular feature used by our paid subscribers}\\n#     \"\"\"))\\n# print(formatted_query)\\ncrew = MetricDiscoveryInputCrew(query)\\nresult = crew.run()', '_i20': '# def check_termination(task_output):\\n#     agent = Agent(\\n#                 role=\\'Determine query completion\\',\\n#                 goal=\\n#                 \\'Given task output, determine termination of crew workflow\\',\\n#                 backstory=\\n#                 \"Given user query request from user determine if no more new task is needed to be executed\",\\n#                 llm = llm_gpt,\\n#                 allow_delegation=False)\\n#     task = Task(\\n#                 agent=agent,\\n#                 description=\\n#                 f\\'Given task output, if the query is completed and the task result determines that the query is out of scope then terminate the workflow or else the required query is satisfied. Following is the task result {task_output}\\',\\n#                 expected_output=\"some string\",\\n        \\n#             )\\n#     termination_status = task.execute()\\n#     return termination_status\\nclass MetricDiscoveryTasks():\\n  def metric_isolation(self, agent, query):\\n    return Task(description=(f\"\"\"\\n        Rephrase the query to capture the intent of the user regarding metric information. The query is {query}. Donot add any noise to the response.\\n        {self.__tip_section()}\"\"\"),\\n      agent=agent,\\n      expected_output=\"Reformatted query to capture the intent of the user regarding metric information.\",\\n      # callback=callback_function,\\n    )\\n  \\n  def metric_discovery(self, agent):\\n    return Task(description=(f\"\"\"\\n        Answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\\n        {self.__tip_section()}\"\"\"),\\n      agent=agent,\\n      expected_output=\"If relevant metric exists in metadata, provide the answer. Else, respond with \\'Sorry, the query is out of scope.\\' and terminate process.\",\\n      # callback=callback_function,\\n    )\\n  def __tip_section(self):\\n    return \"If you do your BEST WORK, I\\'ll give you a $10,000 commission!\"\\n  \\n  ', '_i21': 'class MetricDiscoveryAgent():\\n  def user_intent_capture(self):\\n    return Agent(\\n      role=\\'Intent Capturer\\',\\n      goal=\\n      \\'Rephrasing the query to capture the intent of the user regarding metric information\\',\\n      backstory=\\n      \"You are an expert to understand the user\\'s intent and rephrase the query to capture the intent of the user accurately.\",\\n      verbose=True,\\n      tools=[\\n        RephraseInputQuery()\\n      ],\\n      llm = llm_gpt,\\n    )\\n  def discover_metric_info(self):\\n    return Agent(\\n     role=\\'Data Analyst Assistant\\',\\n      goal=\\n      \\'Empower users to understand and utilize data effectively. This includes helping them discover relevant metrics, interpreting their meaning\\',\\n      backstory=\\n      \"The primary purpose is to bridge the gap between raw data and user comprehension, fostering a data-driven culture within the organization.\",\\n      llm = llm_gpt,\\n      verbose=True,\\n      tools=[\\n        MetricDiscovery()\\n      ],\\n    )', '_i22': 'def after_task_callback(output):\\n  # Perform actions after the task, \\n  # for example, logging or updating agent state\\n  \\n  print(f\"Agent completed task with result: {output}\")\\n\\n# Assigning the function to task_callback\\ntask_callback = after_task_callback', '_i23': 'def test_callback():\\n        # Accessing local variables\\n        print(\"Local variables:\", locals())\\n        \\n        # Accessing global variables\\n        print(\"Global variables:\", globals())    \\n        \\n        # Accessing built-in variables\\n        print(\"Built-in variables:\", dir(__builtins__))\\n        after_task_callback(\"output\")\\n  ', '_i24': 'from crewai.process import Process\\nclass MetricDiscoveryInputCrew:\\n  def __init__(self, query):\\n    self.query = query\\n    # self.llm = llm_gpt\\n\\n  def run(self):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, self.query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n\\n    result = crew.kickoff()\\n    return result', '_i25': 'query = \"What is the most popular feature used by our paid subscribers\"\\n# formatted_query = input(\\n#     dedent(\"\"\"\\n#       {What is the most popular feature used by our paid subscribers}\\n#     \"\"\"))\\n# print(formatted_query)\\ncrew = MetricDiscoveryInputCrew(query)', '_i26': 'dir(crew)', '_26': ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'query', 'run'], '_i27': 'from crewai.process import Process\\nfrom typing import Any\\nclass MetricDiscoveryInputCrew(Expert):\\n  description = (\\n       \"Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\\n    )\\n  public_description = \"Metric discovery crew\"\\n  arg_description = \"Query for metrics to be processed by the crew.\"\\n\\n  def __init__(self, query):\\n    self.query = query\\n    self.crew_process = self.crew_process()\\n    # self.llm = llm_gpt\\n  def crew_process(self):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, self.query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n    self.crew_process = crew\\n\\n  def run(self):\\n    result = self.crew_process.kickoff()\\n    return result\\n  \\n  def call(\\n        self, goal: str, task: str, input_str: str, *args: Any, **kwargs: Any\\n    ) -> str:\\n    pass', 'Any': typing.Any, '_i28': 'from abc import ABC, abstractmethod\\nclass Expert(ABC):\\n    description: str = \"\"\\n    public_description: str = \"\"\\n    arg_description: str = \"The argument to the function.\"\\n\\n    @abstractmethod\\n    def call(\\n        self,\\n        goal: str,\\n        task: str,\\n        input_str: str,\\n    ) -> str:\\n        pass', 'ABC': <class 'abc.ABC'>, 'abstractmethod': <function abstractmethod at 0x109fba480>, 'Expert': <class '__main__.Expert'>, '_i29': 'from crewai.process import Process\\nfrom typing import Any\\nclass MetricDiscoveryInputCrew(Expert):\\n  description = (\\n       \"Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\\n    )\\n  public_description = \"Metric discovery crew\"\\n  arg_description = \"Query for metrics to be processed by the crew.\"\\n\\n  def __init__(self, query):\\n    self.query = query\\n    self.crew_process = self.crew_process()\\n    # self.llm = llm_gpt\\n  def crew_process(self):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, self.query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n    self.crew_process = crew\\n\\n  def run(self):\\n    result = self.crew_process.kickoff()\\n    return result\\n  \\n  def call(\\n        self, goal: str, task: str, input_str: str, *args: Any, **kwargs: Any\\n    ) -> str:\\n    pass', '_i30': '#Available experts\\nfrom typing import Any, Dict, List, Optional, Union\\nfrom typing import Type, TypedDict\\n\\nclass ExpertDescription(TypedDict):\\n    \"\"\"Representation of a callable expert\"\"\"\\n    name: str\\n    \"\"\"The name of the expert.\"\"\"\\n    description: str\\n    \"\"\"A description of the expert.\"\"\"\\n    parameters: dict[str, object]\\n    \"\"\"The parameters of the expert.\"\"\"\\n\\ndef get_expert_function(expert: Type[Expert]) -> ExpertDescription:\\n    \"\"\"A function that will return the tool\\'s function specification\"\"\"\\n    name = get_expert_name(tool)\\n\\n    return {\\n        \"name\": name,\\n        \"description\": expert.description,\\n        \"parameters\": {\\n            \"type\": \"object\",\\n            \"properties\": {\\n                \"reasoning\": {\\n                    \"type\": \"string\",\\n                    \"description\": (\\n                        f\"Reasoning is how the task will be accomplished with the current expert. \"\\n                        \"Detail your overall plan along with any concerns you have.\"\\n                        \"Ensure this reasoning value is in the user defined langauge \"\\n                    ),\\n                },\\n                \"arg\": {\\n                    \"type\": \"string\",\\n                    \"description\": expert.arg_description,\\n                },\\n            },\\n            \"required\": [\"reasoning\", \"arg\"],\\n        },\\n    }\\n\\ndef get_expert_name(expert: Type[Expert]) -> str:\\n    return format_expert_name(expert.__name__)\\n\\ndef format_expert_name(expert_name: str) -> str:\\n    return expert_name.lower()\\n\\ndef get_available_experts() -> List[Type[Expert]]:\\n    return [\\n        MetricDiscoveryInputCrew\\n    ]', 'Dict': typing.Dict, 'List': typing.List, 'Union': typing.Union, 'TypedDict': <function TypedDict at 0x10a19cae0>, 'ExpertDescription': <class '__main__.ExpertDescription'>, 'get_expert_function': <function get_expert_function at 0x13d77f2e0>, 'get_expert_name': <function get_expert_name at 0x13d77f240>, 'format_expert_name': <function format_expert_name at 0x13d77f380>, 'get_available_experts': <function get_available_experts at 0x13d77f560>, '_i31': \"available_experts = get_available_experts()\\nexperts = list(map(get_expert_function, available_experts))\\nexpert_descriptions = {expert['name'] : expert['description'] for expert in experts}\", 'available_experts': [<class '__main__.MetricDiscoveryInputCrew'>], 'experts': [{'name': 'tool', 'description': 'Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.', 'parameters': {'type': 'object', 'properties': {'reasoning': {'type': 'string', 'description': 'Reasoning is how the task will be accomplished with the current expert. Detail your overall plan along with any concerns you have.Ensure this reasoning value is in the user defined langauge '}, 'arg': {'type': 'string', 'description': 'Query for metrics to be processed by the crew.'}}, 'required': ['reasoning', 'arg']}}], 'expert_descriptions': {'tool': 'Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.'}, '_i32': 'expert_descriptions', '_32': {'tool': 'Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.'}, '_i33': 'experts', '_33': [{'name': 'tool', 'description': 'Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.', 'parameters': {'type': 'object', 'properties': {'reasoning': {'type': 'string', 'description': 'Reasoning is how the task will be accomplished with the current expert. Detail your overall plan along with any concerns you have.Ensure this reasoning value is in the user defined langauge '}, 'arg': {'type': 'string', 'description': 'Query for metrics to be processed by the crew.'}}, 'required': ['reasoning', 'arg']}}], '_i34': 'from abc import ABC, abstractmethod\\nclass Expert(ABC):\\n    name: str = \"\"\\n    description: str = \"\"\\n    public_description: str = \"\"\\n    arg_description: str = \"The argument to the function.\"\\n\\n    @abstractmethod\\n    def call(\\n        self,\\n        goal: str,\\n        task: str,\\n        input_str: str,\\n    ) -> str:\\n        pass', '_i35': 'from crewai.process import Process\\nfrom typing import Any\\nclass MetricDiscoveryInputCrew(Expert):\\n  name = \"MetricDiscovery\"\\n  description = (\\n       \"Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\\n    )\\n  public_description = \"Metric discovery crew\"\\n  arg_description = \"Query related to metrics.\"\\n\\n  def __init__(self, query):\\n    self.query = query\\n    self.crew_process = self.crew_process()\\n    # self.llm = llm_gpt\\n  def crew_process(self):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    # print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, self.query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n    self.crew_process = crew\\n\\n  def run(self):\\n    result = self.crew_process.kickoff()\\n    return result\\n  \\n  def call(\\n        self, goal: str, task: str, input_str: str, *args: Any, **kwargs: Any\\n    ) -> str:\\n    pass', '_i36': 'query = \"What is the most popular feature used by our paid subscribers\"\\n# formatted_query = input(\\n#     dedent(\"\"\"\\n#       {What is the most popular feature used by our paid subscribers}\\n#     \"\"\"))\\n# print(formatted_query)\\ncrew = MetricDiscoveryInputCrew(query)\\nresult = crew.run()'}\n",
      "Built-in variables: ['ArithmeticError', 'AssertionError', 'AttributeError', 'BaseException', 'BaseExceptionGroup', 'BlockingIOError', 'BrokenPipeError', 'BufferError', 'BytesWarning', 'ChildProcessError', 'ConnectionAbortedError', 'ConnectionError', 'ConnectionRefusedError', 'ConnectionResetError', 'DeprecationWarning', 'EOFError', 'Ellipsis', 'EncodingWarning', 'EnvironmentError', 'Exception', 'ExceptionGroup', 'False', 'FileExistsError', 'FileNotFoundError', 'FloatingPointError', 'FutureWarning', 'GeneratorExit', 'IOError', 'ImportError', 'ImportWarning', 'IndentationError', 'IndexError', 'InterruptedError', 'IsADirectoryError', 'KeyError', 'KeyboardInterrupt', 'LookupError', 'MemoryError', 'ModuleNotFoundError', 'NameError', 'None', 'NotADirectoryError', 'NotImplemented', 'NotImplementedError', 'OSError', 'OverflowError', 'PendingDeprecationWarning', 'PermissionError', 'ProcessLookupError', 'RecursionError', 'ReferenceError', 'ResourceWarning', 'RuntimeError', 'RuntimeWarning', 'StopAsyncIteration', 'StopIteration', 'SyntaxError', 'SyntaxWarning', 'SystemError', 'SystemExit', 'TabError', 'TimeoutError', 'True', 'TypeError', 'UnboundLocalError', 'UnicodeDecodeError', 'UnicodeEncodeError', 'UnicodeError', 'UnicodeTranslateError', 'UnicodeWarning', 'UserWarning', 'ValueError', 'Warning', 'ZeroDivisionError', '__IPYTHON__', '__build_class__', '__debug__', '__doc__', '__import__', '__loader__', '__name__', '__package__', '__pybind11_internals_v4_clang_libcpp_cxxabi1002__', '__spec__', 'abs', 'aiter', 'all', 'anext', 'any', 'ascii', 'bin', 'bool', 'breakpoint', 'bytearray', 'bytes', 'callable', 'chr', 'classmethod', 'compile', 'complex', 'copyright', 'credits', 'delattr', 'dict', 'dir', 'display', 'divmod', 'enumerate', 'eval', 'exec', 'execfile', 'filter', 'float', 'format', 'frozenset', 'get_ipython', 'getattr', 'globals', 'hasattr', 'hash', 'help', 'hex', 'id', 'input', 'int', 'isinstance', 'issubclass', 'iter', 'len', 'license', 'list', 'locals', 'map', 'max', 'memoryview', 'min', 'next', 'object', 'oct', 'open', 'ord', 'pow', 'print', 'property', 'range', 'repr', 'reversed', 'round', 'runfile', 'set', 'setattr', 'slice', 'sorted', 'staticmethod', 'str', 'sum', 'super', 'tuple', 'type', 'vars', 'zip']\n",
      "Agent completed task with result: output\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'kickoff'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 8\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# formatted_query = input(\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#     dedent(\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#       {What is the most popular feature used by our paid subscribers}\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#     \"\"\"))\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# print(formatted_query)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m crew \u001b[38;5;241m=\u001b[39m MetricDiscoveryInputCrew(query)\n\u001b[0;32m----> 8\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mcrew\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[35], line 44\u001b[0m, in \u001b[0;36mMetricDiscoveryInputCrew.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 44\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcrew_process\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkickoff\u001b[49m()\n\u001b[1;32m     45\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'kickoff'"
     ]
    }
   ],
   "source": [
    "query = \"What is the most popular feature used by our paid subscribers\"\n",
    "# formatted_query = input(\n",
    "#     dedent(\"\"\"\n",
    "#       {What is the most popular feature used by our paid subscribers}\n",
    "#     \"\"\"))\n",
    "# print(formatted_query)\n",
    "crew = MetricDiscoveryInputCrew(query)\n",
    "result = crew.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "# from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate\n",
    "# Define the prompt template\n",
    "prompt_create_objectives = PromptTemplate(\n",
    "    input_variables=[\"goal\", \"chat_history\"],\n",
    "    template=\"\"\"\n",
    "You are an intelligent assistant that helps users break down their goals into high-level, smaller objectives. The system you are part of serves as an interface between users and a database containing various metrics. You have access to metadata of these metrics, including table columns information.\n",
    "Goal: {goal}\n",
    "{chat_history}\n",
    "Using the provided goal and any relevant chat history, break down the goal into high-level, smaller objectives whose intents are different. Make sure each objective is clear and distinct.\n",
    ") \"\"\")\n",
    "\n",
    "goal =\"Can you show me the average user signup rate for the past month, segmented by device type?\"\n",
    "chat_history = \"\"\n",
    "\n",
    "prompt = prompt_create_objectives.format_prompt(\n",
    "                goal=goal,\n",
    "                chat_history=chat_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"text='\\\\nYou are an intelligent assistant that helps users break down their goals into high-level, smaller objectives. The system you are part of serves as an interface between users and a database containing various metrics. You have access to metadata of these metrics, including table columns information.\\\\nGoal: Can you show me the average user signup rate for the past month, segmented by device type?\\\\n\\\\nUsing the provided goal and any relevant chat history, break down the goal into high-level, smaller objectives whose intents are different. Make sure each objective is clear and distinct.\\\\n) '\""
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = llm_gpt.invoke(str(prompt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"To achieve the goal of showing the average user signup rate for the past month, segmented by device type, we can break down the task into the following high-level, smaller objectives:\\n\\n1. **Data Retrieval Objective**: Access the database to retrieve user signup data for the past month. This involves:\\n   - Identifying the correct database and table(s) that contain user signup information.\\n   - Determining the relevant columns that store signup dates and device types.\\n   - Constructing and executing a query to fetch the data within the date range of the past month.\\n\\n2. **Data Segmentation Objective**: Segment the retrieved data by device type. This requires:\\n   - Grouping the signup data based on the device type column.\\n   - Ensuring that each group represents a unique device type.\\n\\n3. **Calculation Objective**: Calculate the average signup rate for each device type. This involves:\\n   - Counting the number of signups for each device type.\\n   - Calculating the total number of days in the past month to determine the period over which the average will be calculated.\\n   - Dividing the total signups by the number of days to find the average daily signup rate per device type.\\n\\n4. **Data Presentation Objective**: Present the calculated average signup rates in a clear and understandable format. This includes:\\n   - Formatting the results in a table or chart that clearly shows the average signup rates segmented by device type.\\n   - Ensuring the time frame (past month) is clearly indicated in the presentation.\\n   - Providing any additional context or explanations that may help the user understand the data.\\n\\n5. **User Interface Interaction Objective**: Interact with the user to deliver the results and offer further assistance. This involves:\\n   - Displaying the results to the user through the system's interface.\\n   - Asking the user if they need any further breakdowns, comparisons, or additional data.\\n   - Being prepared to refine the query or presentation based on user feedback.\\n\\nEach of these objectives is distinct and requires different actions and intents to be fulfilled. Together, they contribute to achieving the overall goal of providing the average user signup rate for the past month, segmented by device type.\""
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Based on your query regarding CPU utilization, here are the high-level, smaller objectives broken down by intent:\\n\\n**Discover Metrics:**\\n- Identify metrics that can provide insights into CPU utilization, such as average CPU load, peak CPU usage, and CPU idle time.\\n\\n**Fetch Data:**\\n- Retrieve the latest data on average CPU load from the database.\\n- Obtain historical data on peak CPU usage over the last month.\\n- Access information on CPU idle time percentages during off-peak hours.\\n\\n**Interpret Metrics:**\\n- Analyze the trend of CPU utilization over time to understand system performance.\\n- Compare CPU usage during peak and off-peak hours to identify potential bottlenecks.\\n- Evaluate the correlation between CPU idle time and system efficiency.\\n\\n**Understand Metrics:**\\n- Explain the significance of average CPU load as a measure of system performance.\\n- Clarify what peak CPU usage indicates about the system's capacity.\\n- Describe how CPU idle time can reflect on system optimization and potential over-provisioning.\\n\\nIf the query does not fit into these intents, such as requesting to upgrade the CPU or change system configurations, then the response would be an empty list.\" response_metadata={'token_usage': {'completion_tokens': 232, 'prompt_tokens': 194, 'total_tokens': 426}, 'model_name': 'gpt-4', 'system_fingerprint': 'fp_811936bd4f', 'finish_reason': 'stop', 'logprobs': None} id='run-10a1c445-8b2e-4d9e-8cdb-0552e039e2b6-0'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the prompt template\n",
    "prompt_template = PromptTemplate.from_template(\"\"\"\n",
    "You are an intelligent assistant that breaks down user's query {query} into high-level, smaller objectives. The system you are part of serves as an interface between users and a database containing various metrics/KPIs/measures.\n",
    "Each smaller objective should strictly fall into one of the following intent:\n",
    "* **Discover Metrics:** If you'd like to measure something specific, I can identify relevant metrics. For example, are you interested in suggest some metrics based on objective?\n",
    "* **Fetch Data:** If you already know the metric you're interested in, I can retrieve the data from the database.\n",
    "* **Interpret Metrics:** Once you have the data, I can explain what it means in the context of your objective. \n",
    "* **Understand Metrics:** If you're unsure about a metric's definition or purpose, I can provide more information.\n",
    "\n",
    "However, if the query involves something else entirely, like action outside current intents, give empty list.\"\"\")\n",
    "\n",
    "\n",
    "def complete(prompt, user_query):\n",
    "  \"\"\"\n",
    "  Completes the prompt with the user objective.\n",
    "\n",
    "  Args:\n",
    "      prompt: The prompt template.\n",
    "      user_objective: The user's objective.\n",
    "\n",
    "  Returns:\n",
    "      The completed prompt.\n",
    "  \"\"\"\n",
    "  return prompt.format(query=user_query)\n",
    "\n",
    "# Example usage\n",
    "user_objective = \"CPU utilization\"\n",
    "completed_prompt = complete(prompt_template, user_objective)\n",
    "\n",
    "# Use the completed prompt with the AzureChatOpenAI model\n",
    "response = llm_gpt.invoke(completed_prompt)\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Available experts\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "from typing import Type, TypedDict\n",
    "\n",
    "class ExpertDescription(TypedDict):\n",
    "    \"\"\"Representation of a callable expert\"\"\"\n",
    "    name: str\n",
    "    \"\"\"The name of the expert.\"\"\"\n",
    "    description: str\n",
    "    \"\"\"A description of the expert.\"\"\"\n",
    "    parameters: dict[str, object]\n",
    "    \"\"\"The parameters of the expert.\"\"\"\n",
    "\n",
    "def get_expert_function(expert: Type[Expert]) -> ExpertDescription:\n",
    "    \"\"\"A function that will return the tool's function specification\"\"\"\n",
    "    name = get_expert_name(expert)\n",
    "    return {\n",
    "        \"name\": name,\n",
    "        \"description\": expert.description,\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"reasoning\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": (\n",
    "                        f\"Reasoning is how the task will be accomplished with the current expert. \"\n",
    "                        \"Detail your overall plan along with any concerns you have.\"\n",
    "                        \"Ensure this reasoning value is in the user defined langauge \"\n",
    "                    ),\n",
    "                },\n",
    "                \"arg\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": expert.arg_description,\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"reasoning\", \"arg\"],\n",
    "        },\n",
    "    }\n",
    "\n",
    "def get_expert_name(expert: Type[Expert]) -> str:\n",
    "    return format_expert_name(expert.name)\n",
    "\n",
    "def format_expert_name(expert_name: str) -> str:\n",
    "    return expert_name.lower()\n",
    "\n",
    "def get_available_experts() -> List[Type[Expert]]:\n",
    "    return [\n",
    "        MetricDiscoveryInputCrew\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_experts = get_available_experts()\n",
    "experts = list(map(get_expert_function, available_experts))\n",
    "expert_descriptions = {expert['name'] : expert['description'] for expert in experts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metricdiscovery': 'Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'tool',\n",
       "  'description': 'Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'reasoning': {'type': 'string',\n",
       "     'description': 'Reasoning is how the task will be accomplished with the current expert. Detail your overall plan along with any concerns you have.Ensure this reasoning value is in the user defined langauge '},\n",
       "    'arg': {'type': 'string',\n",
       "     'description': 'Query for metrics to be processed by the crew.'}},\n",
       "   'required': ['reasoning', 'arg']}}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
