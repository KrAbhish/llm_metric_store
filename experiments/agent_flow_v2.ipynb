{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/k.abhishek/anaconda3/envs/agentgpt/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `AzureOpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import AzureOpenAIEmbeddings`.\n",
      "  warn_deprecated(\n",
      "/Users/k.abhishek/anaconda3/envs/agentgpt/lib/python3.11/site-packages/langchain_community/embeddings/azure_openai.py:113: UserWarning: As of openai>=1.0.0, Azure endpoints should be specified via the `azure_endpoint` param not `openai_api_base` (or alias `base_url`). Updating `openai_api_base` from https://polarisopenai.openai.azure.com/ to https://polarisopenai.openai.azure.com//openai.\n",
      "  warnings.warn(\n",
      "/Users/k.abhishek/anaconda3/envs/agentgpt/lib/python3.11/site-packages/langchain_community/embeddings/azure_openai.py:120: UserWarning: As of openai>=1.0.0, if `deployment` (or alias `azure_deployment`) is specified then `openai_api_base` (or alias `base_url`) should not be. Instead use `deployment` (or alias `azure_deployment`) and `azure_endpoint`.\n",
      "  warnings.warn(\n",
      "/Users/k.abhishek/anaconda3/envs/agentgpt/lib/python3.11/site-packages/langchain_community/embeddings/azure_openai.py:128: UserWarning: As of openai>=1.0.0, if `openai_api_base` (or alias `base_url`) is specified it is expected to be of the form https://example-resource.azure.openai.com/openai/deployments/example-deployment. Updating https://polarisopenai.openai.azure.com/ to https://polarisopenai.openai.azure.com//openai.\n",
      "  warnings.warn(\n",
      "/Users/k.abhishek/anaconda3/envs/agentgpt/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `AzureChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import AzureChatOpenAI`.\n",
      "  warn_deprecated(\n",
      "/Users/k.abhishek/anaconda3/envs/agentgpt/lib/python3.11/site-packages/langchain_community/chat_models/azure_openai.py:167: UserWarning: As of openai>=1.0.0, Azure endpoints should be specified via the `azure_endpoint` param not `openai_api_base` (or alias `base_url`). Updating `openai_api_base` from https://polariseastus2.openai.azure.com/ to https://polariseastus2.openai.azure.com/openai.\n",
      "  warnings.warn(\n",
      "/Users/k.abhishek/anaconda3/envs/agentgpt/lib/python3.11/site-packages/langchain_community/chat_models/azure_openai.py:174: UserWarning: As of openai>=1.0.0, if `deployment_name` (or alias `azure_deployment`) is specified then `openai_api_base` (or alias `base_url`) should not be. Instead use `deployment_name` (or alias `azure_deployment`) and `azure_endpoint`.\n",
      "  warnings.warn(\n",
      "/Users/k.abhishek/anaconda3/envs/agentgpt/lib/python3.11/site-packages/langchain_community/chat_models/azure_openai.py:182: UserWarning: As of openai>=1.0.0, if `openai_api_base` (or alias `base_url`) is specified it is expected to be of the form https://example-resource.azure.openai.com/openai/deployments/example-deployment. Updating https://polariseastus2.openai.azure.com/ to https://polariseastus2.openai.azure.com/openai.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#initialize\n",
    "#     model\n",
    "#     environment variables\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.utils.llamaindex_retriever import LlamaIndexRetriever\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.azure_openai import AzureOpenAIEmbeddings\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "\n",
    "\n",
    "def load_env_variables(file_path):\n",
    "    load_dotenv(file_path)\n",
    "    print(\"Environment variables loaded successfully!\")\n",
    "\n",
    "env_file_path = \"../.env\"\n",
    "load_env_variables = load_env_variables(env_file_path)\n",
    "max_tokens = 3500\n",
    "temperature = 0.1\n",
    "\n",
    "# embeddings = AzureOpenAIEmbeddings(azure_deployment=azure_deployment, openai_api_version=openai_api_version)\n",
    "embeddings =  AzureOpenAIEmbeddings(\n",
    "        deployment=os.getenv(\"EMB_DEPLOYMENT\"),\n",
    "        openai_api_version=os.getenv(\"EMB_OPENAI_API_VERSION\"),\n",
    "        model=os.getenv(\"EMB_MODEL\"),\n",
    "        openai_api_key=os.getenv(\"EMB_OPENAI_API_KEY\"),\n",
    "        openai_api_base=os.getenv(\"EMB_OPENAI_ENDPOINT\"),\n",
    "        openai_api_type=os.getenv(\"EMB_API_TYPE\"),\n",
    "    )\n",
    "\n",
    "llm_service = AzureChatOpenAI(deployment_name=os.getenv('AZURE_OPENAI_DEPLOYMENT_NAME'), openai_api_version=os.getenv(\"OPENAI_API_VERSION\"),\n",
    "                        openai_api_base=os.getenv(\"OPENAI_API_BASE\"), \n",
    "                        openai_api_type= os.getenv(\"OPENAI_API_TYPE\"),\n",
    "                        openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "                        max_tokens=max_tokens,\n",
    "                        temperature=temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define utils\n",
    "from src.utils.cube_semantic_custom import CubeSemanticLoader\n",
    "def fetch_cube_metadata(*args, **kwargs):\n",
    "    try:\n",
    "        # # Load document from Cube meta api\n",
    "        loader = CubeSemanticLoader(os.getenv(\"CUBE_API_URL\"), os.getenv(\"CUBE_TOKEN\"), False)\n",
    "        documents = loader.load()\n",
    "        # to_json()\n",
    "        return documents\n",
    "    except Exception as e:\n",
    "        # Handle exceptions gracefully and return an error response\n",
    "        print(\"Error in fetching metadata from cube: \" + str(e))\n",
    "        return 0\n",
    "\n",
    "def create_vector_store(documents, local_vector_store_path, *args, **kwargs):\n",
    "    print(\"Loaded documents: \" + str(documents))\n",
    "    vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "    vectorstore.save_local(local_vector_store_path)\n",
    "    print(\"Vector store created and saved successfully!\")\n",
    "\n",
    "def load_vector_store(vector_store_path, embeddings, *args, **kwargs):\n",
    "    # Load the vector store from the local file system\n",
    "    vectorstore = FAISS.load_local(vector_store_path, embeddings, allow_dangerous_deserialization=True)\n",
    "    print(\"Vector store loaded successfully!\")\n",
    "    \n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "#load existing vector store\n",
    "vector_store_path = \"/Users/k.abhishek/Documents/experiments/metric_store/metric_store_gen_ai/data/vector_store/cube_meta_faiss_index\"\n",
    "vectorstore = load_vector_store(vector_store_path, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tools "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from crewai import Agent, Task, Crew\n",
    "from langchain.tools import tool\n",
    "from src.utils.llamaindex_retriever import LlamaIndexRetriever\n",
    "from typing import Optional, Type\n",
    "from langchain.callbacks.manager import (\n",
    "    AsyncCallbackManagerForToolRun,\n",
    "    CallbackManagerForToolRun,\n",
    ")\n",
    "# Import things that are needed generically\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "# from langchain.tools import BaseTool, StructuredTool, tool\n",
    "from crewai_tools import BaseTool\n",
    "\n",
    "\n",
    "def get_similar_documents_faiss(query, max_number_documents=3):\n",
    "  vectorstore = FAISS.load_local(vector_store_path, embeddings, allow_dangerous_deserialization=True)\n",
    "  docs = vectorstore.similarity_search_with_relevance_scores(query, max_number_documents)\n",
    "  relevant_documents = []\n",
    "  for doc in docs:\n",
    "      doc = doc[0]\n",
    "      meta = {'text':doc.page_content, 'table_metadata': doc.metadata}\n",
    "      relevant_documents.append(meta)\n",
    "  return relevant_documents\n",
    "\n",
    "def get_similar_documents(query, max_number_documents=3):\n",
    "    return get_similar_documents_faiss(query, max_number_documents)\n",
    "\n",
    "\n",
    "class QueryInput(BaseModel):\n",
    "    query: str = Field(description=\"should be enquiry query\")\n",
    "\n",
    "class TerminationHandler(CallbackManagerForToolRun):\n",
    "    pass\n",
    "\n",
    "class RephraseInputQuery(BaseTool):\n",
    "    name:str = \"rephrase_input_query\"\n",
    "    description :str = \"Useful to rephrase the query to capture the intent of the user regarding metric information\"\n",
    "    args_schema: Type[BaseModel] = QueryInput\n",
    "\n",
    "    def _run(\n",
    "        self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool.\"\"\"\n",
    "        metric_description = self.rephrase_input_query(query)\n",
    "        return metric_description\n",
    "\n",
    "    async def _arun(\n",
    "        self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"custom_search does not support async\")\n",
    "    \n",
    "    \n",
    "    def rephrase_input_query(self, query, *args, **kwargs):\n",
    "        agent = Agent(\n",
    "                role='Intent Capturer',\n",
    "                goal=\n",
    "                'Rephrasing the query to capture the intent of the user regarding metric information',\n",
    "                backstory=\n",
    "                \"You are an expert to understand the user's intent and rephrase the query to capture the intent of the user accurately.\",\n",
    "                llm = llm_service,\n",
    "                allow_delegation=False)\n",
    "        task = Task(\n",
    "                agent=agent,\n",
    "                description=\n",
    "                f'Rephrase the query to capture the intent of the user regarding metric information. The query is {query}. Donot add any noise to the response',\n",
    "                expected_output=\"some string\",\n",
    "        \n",
    "            )\n",
    "        extracted_metrics = task.execute()\n",
    "\n",
    "        return extracted_metrics\n",
    "    \n",
    "\n",
    "    \n",
    "class MetricDiscovery(BaseTool):\n",
    "    name :str = \"metric_discovery\"\n",
    "    description:str = \"\"\"Useful for general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\"\"\n",
    "    args_schema: Type[BaseModel] = QueryInput\n",
    "\n",
    "    def _run(\n",
    "        self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool.\"\"\"\n",
    "        metric_description = self.metric_discovery(query)\n",
    "        return metric_description\n",
    "\n",
    "    async def _arun(\n",
    "        self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"custom_search does not support async\")\n",
    "    \n",
    "    \n",
    "    def metric_discovery(self, query, *args, **kwargs):\n",
    "        \"\"\"Useful for general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\"\"\n",
    "        relevant_documents = get_similar_documents(query)\n",
    "        agent = Agent(\n",
    "                role='Data Analyst Assistant',\n",
    "                goal=\n",
    "                'Empower users to understand and utilize data effectively. This includes helping them discover relevant metrics, interpreting their meaning',\n",
    "                backstory=\n",
    "                \"The primary purpose is to bridge the gap between raw data and user comprehension, fostering a data-driven culture within the organization.\",\n",
    "                llm = llm_service,\n",
    "                allow_delegation=False)  \n",
    "        \n",
    "        task = Task(\n",
    "                agent=agent,\n",
    "                description=\n",
    "                \"\"\" You are responding to  question {metric_description} with answer from the Metadata provided to you as {relevant_documents}}.\n",
    "                    Strictly answer the question with the information present in metadata only.\n",
    "                    Respond with \"Sorry, the query is out of scope.\" if the answer is not present in metadata and terminate further reasoning and prcoess.\n",
    "                    \"\"\",\n",
    "                expected_output=\"some string\",\n",
    "        \n",
    "            )\n",
    "        output = task.execute()\n",
    "\n",
    "        return output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def callback_function(output: TaskOutput):\n",
    "    # Do something after the task is completed\n",
    "    # Example: Send an email to the manager\n",
    "    print(f\"\"\"\n",
    "        Task completed!\n",
    "        Task: {output.description}\n",
    "        Output: {output.raw_output}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def check_termination(task_output):\n",
    "#     agent = Agent(\n",
    "#                 role='Determine query completion',\n",
    "#                 goal=\n",
    "#                 'Given task output, determine termination of crew workflow',\n",
    "#                 backstory=\n",
    "#                 \"Given user query request from user determine if no more new task is needed to be executed\",\n",
    "#                 llm = llm_service,\n",
    "#                 allow_delegation=False)\n",
    "#     task = Task(\n",
    "#                 agent=agent,\n",
    "#                 description=\n",
    "#                 f'Given task output, if the query is completed and the task result determines that the query is out of scope then terminate the workflow or else the required query is satisfied. Following is the task result {task_output}',\n",
    "#                 expected_output=\"some string\",\n",
    "        \n",
    "#             )\n",
    "#     termination_status = task.execute()\n",
    "#     return termination_status\n",
    "class MetricDiscoveryTasks():\n",
    "  def metric_isolation(self, agent, query):\n",
    "    return Task(description=(f\"\"\"\n",
    "        Rephrase the query to capture the intent of the user regarding metric information. The query is {query}. Donot add any noise to the response.\n",
    "        {self.__tip_section()}\"\"\"),\n",
    "      agent=agent,\n",
    "      expected_output=\"Reformatted query to capture the intent of the user regarding metric information.\",\n",
    "      # callback=callback_function,\n",
    "    )\n",
    "  \n",
    "  def metric_discovery(self, agent):\n",
    "    return Task(description=(f\"\"\"\n",
    "        Answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\n",
    "        {self.__tip_section()}\"\"\"),\n",
    "      agent=agent,\n",
    "      expected_output=\"If relevant metric exists in metadata, provide the answer. Else, respond with 'Sorry, the query is out of scope.' and terminate process.\",\n",
    "      # callback=callback_function,\n",
    "    )\n",
    "  def __tip_section(self):\n",
    "    return \"If you do your BEST WORK, I'll give you a $10,000 commission!\"\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricDiscoveryAgent():\n",
    "  def user_intent_capture(self):\n",
    "    return Agent(\n",
    "      role='Intent Capturer',\n",
    "      goal=\n",
    "      'Rephrasing the query to capture the intent of the user regarding metric information',\n",
    "      backstory=\n",
    "      \"You are an expert to understand the user's intent and rephrase the query to capture the intent of the user accurately.\",\n",
    "      verbose=True,\n",
    "      tools=[\n",
    "        RephraseInputQuery()\n",
    "      ],\n",
    "      llm = llm_service,\n",
    "    )\n",
    "  def discover_metric_info(self):\n",
    "    return Agent(\n",
    "     role='Data Analyst Assistant',\n",
    "      goal=\n",
    "      'Empower users to understand and utilize data effectively. This includes helping them discover relevant metrics, interpreting their meaning',\n",
    "      backstory=\n",
    "      \"The primary purpose is to bridge the gap between raw data and user comprehension, fostering a data-driven culture within the organization.\",\n",
    "      llm = llm_service,\n",
    "      verbose=True,\n",
    "      tools=[\n",
    "        MetricDiscovery()\n",
    "      ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def after_task_callback(output):\n",
    "  # Perform actions after the task, \n",
    "  # for example, logging or updating agent state\n",
    "  \n",
    "  print(f\"Agent completed task with result: {output}\")\n",
    "\n",
    "# Assigning the function to task_callback\n",
    "task_callback = after_task_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_callback():\n",
    "        # Accessing local variables\n",
    "        print(\"Local variables:\", locals())\n",
    "        \n",
    "        # Accessing global variables\n",
    "        print(\"Global variables:\", globals())    \n",
    "        \n",
    "        # Accessing built-in variables\n",
    "        print(\"Built-in variables:\", dir(__builtins__))\n",
    "        after_task_callback(\"output\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "class Expert(ABC):\n",
    "    name: str = \"\"\n",
    "    description: str = \"\"\n",
    "    public_description: str = \"\"\n",
    "    arg_description: str = \"The argument to the function.\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def call(\n",
    "        self,\n",
    "        goal: str,\n",
    "        task: str,\n",
    "        input_str: str,\n",
    "    ) -> str:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai.process import Process\n",
    "from typing import Any\n",
    "class MetricDiscoveryInputCrew(Expert):\n",
    "  name = \"MetricDiscovery\"\n",
    "  description = (\n",
    "       \"Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\n",
    "    )\n",
    "  public_description = \"Metric discovery crew\"\n",
    "  arg_description = \"Query related to metrics.\"\n",
    "\n",
    "  def crew_process(self, query: str):\n",
    "    agents = MetricDiscoveryAgent()\n",
    "    tasks = MetricDiscoveryTasks()\n",
    "    # print(agents)\n",
    "    # print(tasks)\n",
    "    user_intent_capture_agent = agents.user_intent_capture()\n",
    "    discover_metric_info_agent = agents.discover_metric_info()\n",
    "    # print(metric_isolator_agent)\n",
    "    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\n",
    "    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, query)\n",
    "    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\n",
    "    \n",
    "    # print(\"Metric_isolator_task\", metric_isolator_task)\n",
    "    crew = Crew(\n",
    "      agents=[\n",
    "        user_intent_capture_agent,\n",
    "        discover_metric_info_agent,\n",
    "      ],\n",
    "      tasks=[\n",
    "        metric_isolator_task,\n",
    "        metric_discover_task\n",
    "      ],\n",
    "      verbose=False,\n",
    "      process=Process.sequential,\n",
    "      step_callback=test_callback()\n",
    "    )\n",
    "    return crew\n",
    "  \n",
    "\n",
    "  def run(self, query: str):\n",
    "    crew = self.crew_process(query)\n",
    "    result = crew.kickoff()\n",
    "    return result\n",
    "  \n",
    "  def call(\n",
    "        self, goal: str, task: str, input_str: str, *args: Any, **kwargs: Any\n",
    "    ) -> str:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local variables: {}\n",
      "Global variables: {'__name__': '__main__', '__doc__': 'Automatically created module for IPython interactive environment', '__package__': None, '__loader__': None, '__spec__': None, '__builtin__': <module 'builtins' (built-in)>, '__builtins__': <module 'builtins' (built-in)>, '_ih': ['', 'a ={\"a\" : MetricDiscoveryInputCrew()}', 'from crewai.process import Process\\nfrom typing import Any\\nclass MetricDiscoveryInputCrew(Expert):\\n  name = \"MetricDiscovery\"\\n  description = (\\n       \"Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\\n    )\\n  public_description = \"Metric discovery crew\"\\n  arg_description = \"Query related to metrics.\"\\n\\n  def __init__(self, query):\\n    self.query = query\\n    self.crew_process = self.crew_process()\\n    # self.llm = llm_gpt\\n  def crew_process(self):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    # print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, self.query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n    return crew\\n\\n  def run(self):\\n    result = self.crew_process.kickoff()\\n    return result\\n  \\n  def call(\\n        self, goal: str, task: str, input_str: str, *args: Any, **kwargs: Any\\n    ) -> str:\\n    pass', '#initialize\\n#     model\\n#     environment variables\\n\\nimport sys\\nsys.path.append(\\'..\\')\\nfrom src.utils.llamaindex_retriever import LlamaIndexRetriever\\nfrom langchain.vectorstores import FAISS\\nfrom langchain.embeddings.azure_openai import AzureOpenAIEmbeddings\\nfrom langchain.embeddings.openai import OpenAIEmbeddings\\nfrom dotenv import load_dotenv\\nimport os\\nfrom langchain.chat_models import AzureChatOpenAI\\n\\ndef load_env_variables(file_path):\\n    load_dotenv(file_path)\\n    print(\"Environment variables loaded successfully!\")\\n\\nenv_file_path = \"../.env\"\\nload_env_variables = load_env_variables(env_file_path)\\nmax_tokens = 3500\\ntemperature = 0.1\\n\\n# embeddings = AzureOpenAIEmbeddings(azure_deployment=azure_deployment, openai_api_version=openai_api_version)\\nembeddings =  AzureOpenAIEmbeddings(\\n        deployment=os.getenv(\"EMB_DEPLOYMENT\"),\\n        openai_api_version=os.getenv(\"EMB_OPENAI_API_VERSION\"),\\n        model=os.getenv(\"EMB_MODEL\"),\\n        openai_api_key=os.getenv(\"EMB_OPENAI_API_KEY\"),\\n        openai_api_base=os.getenv(\"EMB_OPENAI_ENDPOINT\"),\\n        openai_api_type=os.getenv(\"EMB_API_TYPE\"),\\n    )\\n\\nllm_gpt = AzureChatOpenAI(deployment_name=os.getenv(\\'AZURE_OPENAI_DEPLOYMENT_NAME\\'), openai_api_version=os.getenv(\"OPENAI_API_VERSION\"),\\n                        openai_api_base=os.getenv(\"OPENAI_API_BASE\"), \\n                        openai_api_type= os.getenv(\"OPENAI_API_TYPE\"),\\n                        openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\\n                        max_tokens=max_tokens,\\n                        temperature=temperature)', '#define utils\\nfrom src.utils.cube_semantic_custom import CubeSemanticLoader\\ndef fetch_cube_metadata(*args, **kwargs):\\n    try:\\n        # # Load document from Cube meta api\\n        loader = CubeSemanticLoader(os.getenv(\"CUBE_API_URL\"), os.getenv(\"CUBE_TOKEN\"), False)\\n        documents = loader.load()\\n        # to_json()\\n        return documents\\n    except Exception as e:\\n        # Handle exceptions gracefully and return an error response\\n        print(\"Error in fetching metadata from cube: \" + str(e))\\n        return 0\\n\\ndef create_vector_store(documents, local_vector_store_path, *args, **kwargs):\\n    print(\"Loaded documents: \" + str(documents))\\n    vectorstore = FAISS.from_documents(documents, embeddings)\\n    vectorstore.save_local(local_vector_store_path)\\n    print(\"Vector store created and saved successfully!\")\\n\\ndef load_vector_store(vector_store_path, embeddings, *args, **kwargs):\\n    # Load the vector store from the local file system\\n    vectorstore = FAISS.load_local(vector_store_path, embeddings, allow_dangerous_deserialization=True)\\n    print(\"Vector store loaded successfully!\")\\n    \\n    return vectorstore', '#load existing vector store\\nvector_store_path = \"/Users/k.abhishek/Documents/experiments/metric_store/metric_store_gen_ai/data/vector_store/cube_meta_faiss_index\"\\nvectorstore = load_vector_store(vector_store_path, embeddings)', 'import json\\nfrom crewai import Agent, Task, Crew\\nfrom langchain.tools import tool\\nfrom src.utils.llamaindex_retriever import LlamaIndexRetriever\\nfrom typing import Optional, Type\\nfrom langchain.callbacks.manager import (\\n    AsyncCallbackManagerForToolRun,\\n    CallbackManagerForToolRun,\\n)\\n# Import things that are needed generically\\nfrom langchain.pydantic_v1 import BaseModel, Field\\n# from langchain.tools import BaseTool, StructuredTool, tool\\nfrom crewai_tools import BaseTool\\n\\n\\ndef get_similar_documents_faiss(query, max_number_documents=3):\\n  vectorstore = FAISS.load_local(vector_store_path, embeddings, allow_dangerous_deserialization=True)\\n  docs = vectorstore.similarity_search_with_relevance_scores(query, max_number_documents)\\n  relevant_documents = []\\n  for doc in docs:\\n      doc = doc[0]\\n      meta = {\\'text\\':doc.page_content, \\'table_metadata\\': doc.metadata}\\n      relevant_documents.append(meta)\\n  return relevant_documents\\n\\ndef get_similar_documents(query, max_number_documents=3):\\n    return get_similar_documents_faiss(query, max_number_documents)\\n\\n\\nclass QueryInput(BaseModel):\\n    query: str = Field(description=\"should be enquiry query\")\\n\\nclass TerminationHandler(CallbackManagerForToolRun):\\n    pass\\n\\nclass RephraseInputQuery(BaseTool):\\n    name:str = \"rephrase_input_query\"\\n    description :str = \"Useful to rephrase the query to capture the intent of the user regarding metric information\"\\n    args_schema: Type[BaseModel] = QueryInput\\n\\n    def _run(\\n        self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None\\n    ) -> str:\\n        \"\"\"Use the tool.\"\"\"\\n        metric_description = self.rephrase_input_query(query)\\n        return metric_description\\n\\n    async def _arun(\\n        self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None\\n    ) -> str:\\n        \"\"\"Use the tool asynchronously.\"\"\"\\n        raise NotImplementedError(\"custom_search does not support async\")\\n    \\n    \\n    def rephrase_input_query(self, query, *args, **kwargs):\\n        agent = Agent(\\n                role=\\'Intent Capturer\\',\\n                goal=\\n                \\'Rephrasing the query to capture the intent of the user regarding metric information\\',\\n                backstory=\\n                \"You are an expert to understand the user\\'s intent and rephrase the query to capture the intent of the user accurately.\",\\n                llm = llm_gpt,\\n                allow_delegation=False)\\n        task = Task(\\n                agent=agent,\\n                description=\\n                f\\'Rephrase the query to capture the intent of the user regarding metric information. The query is {query}. Donot add any noise to the response\\',\\n                expected_output=\"some string\",\\n        \\n            )\\n        extracted_metrics = task.execute()\\n\\n        return extracted_metrics\\n    \\n\\n    \\nclass MetricDiscovery(BaseTool):\\n    name :str = \"metric_discovery\"\\n    description:str = \"\"\"Useful for general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\"\"\\n    args_schema: Type[BaseModel] = QueryInput\\n\\n    def _run(\\n        self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None\\n    ) -> str:\\n        \"\"\"Use the tool.\"\"\"\\n        metric_description = self.metric_discovery(query)\\n        return metric_description\\n\\n    async def _arun(\\n        self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None\\n    ) -> str:\\n        \"\"\"Use the tool asynchronously.\"\"\"\\n        raise NotImplementedError(\"custom_search does not support async\")\\n    \\n    \\n    def metric_discovery(self, query, *args, **kwargs):\\n        \"\"\"Useful for general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\"\"\\n        relevant_documents = get_similar_documents(query)\\n        agent = Agent(\\n                role=\\'Data Analyst Assistant\\',\\n                goal=\\n                \\'Empower users to understand and utilize data effectively. This includes helping them discover relevant metrics, interpreting their meaning\\',\\n                backstory=\\n                \"The primary purpose is to bridge the gap between raw data and user comprehension, fostering a data-driven culture within the organization.\",\\n                llm = llm_gpt,\\n                allow_delegation=False)  \\n        \\n        task = Task(\\n                agent=agent,\\n                description=\\n                \"\"\" You are responding to  question {metric_description} with answer from the Metadata provided to you as {relevant_documents}}.\\n                    Strictly answer the question with the information present in metadata only.\\n                    Respond with \"Sorry, the query is out of scope.\" if the answer is not present in metadata and terminate further reasoning and prcoess.\\n                    \"\"\",\\n                expected_output=\"some string\",\\n        \\n            )\\n        output = task.execute()\\n\\n        return output', '# def check_termination(task_output):\\n#     agent = Agent(\\n#                 role=\\'Determine query completion\\',\\n#                 goal=\\n#                 \\'Given task output, determine termination of crew workflow\\',\\n#                 backstory=\\n#                 \"Given user query request from user determine if no more new task is needed to be executed\",\\n#                 llm = llm_gpt,\\n#                 allow_delegation=False)\\n#     task = Task(\\n#                 agent=agent,\\n#                 description=\\n#                 f\\'Given task output, if the query is completed and the task result determines that the query is out of scope then terminate the workflow or else the required query is satisfied. Following is the task result {task_output}\\',\\n#                 expected_output=\"some string\",\\n        \\n#             )\\n#     termination_status = task.execute()\\n#     return termination_status\\nclass MetricDiscoveryTasks():\\n  def metric_isolation(self, agent, query):\\n    return Task(description=(f\"\"\"\\n        Rephrase the query to capture the intent of the user regarding metric information. The query is {query}. Donot add any noise to the response.\\n        {self.__tip_section()}\"\"\"),\\n      agent=agent,\\n      expected_output=\"Reformatted query to capture the intent of the user regarding metric information.\",\\n      # callback=callback_function,\\n    )\\n  \\n  def metric_discovery(self, agent):\\n    return Task(description=(f\"\"\"\\n        Answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\\n        {self.__tip_section()}\"\"\"),\\n      agent=agent,\\n      expected_output=\"If relevant metric exists in metadata, provide the answer. Else, respond with \\'Sorry, the query is out of scope.\\' and terminate process.\",\\n      # callback=callback_function,\\n    )\\n  def __tip_section(self):\\n    return \"If you do your BEST WORK, I\\'ll give you a $10,000 commission!\"\\n  \\n  ', 'class MetricDiscoveryAgent():\\n  def user_intent_capture(self):\\n    return Agent(\\n      role=\\'Intent Capturer\\',\\n      goal=\\n      \\'Rephrasing the query to capture the intent of the user regarding metric information\\',\\n      backstory=\\n      \"You are an expert to understand the user\\'s intent and rephrase the query to capture the intent of the user accurately.\",\\n      verbose=True,\\n      tools=[\\n        RephraseInputQuery()\\n      ],\\n      llm = llm_gpt,\\n    )\\n  def discover_metric_info(self):\\n    return Agent(\\n     role=\\'Data Analyst Assistant\\',\\n      goal=\\n      \\'Empower users to understand and utilize data effectively. This includes helping them discover relevant metrics, interpreting their meaning\\',\\n      backstory=\\n      \"The primary purpose is to bridge the gap between raw data and user comprehension, fostering a data-driven culture within the organization.\",\\n      llm = llm_gpt,\\n      verbose=True,\\n      tools=[\\n        MetricDiscovery()\\n      ],\\n    )', 'def after_task_callback(output):\\n  # Perform actions after the task, \\n  # for example, logging or updating agent state\\n  \\n  print(f\"Agent completed task with result: {output}\")\\n\\n# Assigning the function to task_callback\\ntask_callback = after_task_callback', 'def test_callback():\\n        # Accessing local variables\\n        print(\"Local variables:\", locals())\\n        \\n        # Accessing global variables\\n        print(\"Global variables:\", globals())    \\n        \\n        # Accessing built-in variables\\n        print(\"Built-in variables:\", dir(__builtins__))\\n        after_task_callback(\"output\")\\n  ', 'from abc import ABC, abstractmethod\\nclass Expert(ABC):\\n    name: str = \"\"\\n    description: str = \"\"\\n    public_description: str = \"\"\\n    arg_description: str = \"The argument to the function.\"\\n\\n    @abstractmethod\\n    def call(\\n        self,\\n        goal: str,\\n        task: str,\\n        input_str: str,\\n    ) -> str:\\n        pass', 'from crewai.process import Process\\nfrom typing import Any\\nclass MetricDiscoveryInputCrew(Expert):\\n  name = \"MetricDiscovery\"\\n  description = (\\n       \"Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\\n    )\\n  public_description = \"Metric discovery crew\"\\n  arg_description = \"Query related to metrics.\"\\n\\n  def __init__(self, query):\\n    self.query = query\\n    self.crew_process = self.crew_process()\\n    # self.llm = llm_gpt\\n  def crew_process(self):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    # print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, self.query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n    return crew\\n\\n  def run(self):\\n    result = self.crew_process.kickoff()\\n    return result\\n  \\n  def call(\\n        self, goal: str, task: str, input_str: str, *args: Any, **kwargs: Any\\n    ) -> str:\\n    pass', 'a ={\"a\" : MetricDiscoveryInputCrew()}', 'from crewai.process import Process\\nfrom typing import Any\\nclass MetricDiscoveryInputCrew(Expert):\\n  name = \"MetricDiscovery\"\\n  description = (\\n       \"Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\\n    )\\n  public_description = \"Metric discovery crew\"\\n  arg_description = \"Query related to metrics.\"\\n\\n  def __init__(self):\\n    # self.query = query\\n    self.crew_process = self.crew_process()\\n    # self.llm = llm_gpt\\n  def crew_process(self, query: str):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    # print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n    return crew\\n\\n  def run(self, query: str):\\n    result = self.crew_process.kickoff()\\n    return result\\n  \\n  def call(\\n        self, goal: str, task: str, input_str: str, *args: Any, **kwargs: Any\\n    ) -> str:\\n    pass', 'a ={\"a\" : MetricDiscoveryInputCrew()}', 'from crewai.process import Process\\nfrom typing import Any\\nclass MetricDiscoveryInputCrew(Expert):\\n  name = \"MetricDiscovery\"\\n  description = (\\n       \"Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\\n    )\\n  public_description = \"Metric discovery crew\"\\n  arg_description = \"Query related to metrics.\"\\n\\n  def crew_process(self, query: str):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    # print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n    return crew\\n  \\n\\n  def run(self, query: str):\\n    result = self.crew_process.kickoff(query)\\n    return result\\n  \\n  def call(\\n        self, goal: str, task: str, input_str: str, *args: Any, **kwargs: Any\\n    ) -> str:\\n    pass', 'a ={\"a\" : MetricDiscoveryInputCrew()}', 'objectives = parse_with_handling(task_output_parser, response.content)\\nprint(objectives)', 'intents = {\\n    \"discover_metrics\": \"Identify relevant metrics based on user objectives. (e.g., Suggest metrics to measure customer satisfaction)\",\\n    \"fetch_data\": \"Retrieve data for a specific metric the user has already identified.\",\\n    # \"analyze_trends\": \"Analyze trends within the fetched data to provide deeper insights.\",\\n    \"interpret_metrics\": \"Explain the meaning of the data in the context of the user\\'s objective.\",\\n    \"understand_metrics\": \"Provide information about a metric\\'s definition and purpose.\"\\n}\\nprompt_template = PromptTemplate.from_template(\"\"\"You are an intelligent assistant focused on helping users with metrics and data. Your primary goal is to break down user queries ({query}) into a concise list of high-level objectives.\\n\\n**Intents:**\\n\\n{intents}\\n\\nImportant Notes:\\n* Alignment with Intents: The new objectives should strictly align with the provided intents.\\n* Prioritize Clarity & Efficiency:  Minimize the number of objectives and maintain a high-level overview. \\n* Direct Match: If the query aligns perfectly with one intent (e.g., \"What\\'s the current customer churn rate?\" for Fetch Data), don\\'t alter it.\\n* Outside Scope: If the query falls outside these intents (e.g., \"Book a flight\"), return an empty list.\\n* Focus on User Need: Keep responses clear and concise, avoiding unnecessary information. \\n* Output Format:  Respond with a list containing the breakdown of objectives.\\n\\n**Here\\'s the user query: {query}\\n\\nWhat is the high-level breakdown of objectives for this query?\\n\"\"\")\\n\\n\\n\\n# Format the intent descriptions for the prompt\\nformatted_intents = \"\\\\n\".join([f\"* {intent_name}: {description}\" for intent_name, description in intents.items()])\\nquery = \"What dose the vessel name column represents?\"\\n# Insert formatted intents into the prompt template\\ncompleted_prompt = prompt_template.format(intents=formatted_intents, query=query)\\n# Use the completed prompt with the AzureChatOpenAI model\\nresponse = llm_gpt.invoke(completed_prompt)\\n\\nprint(response)', 'query = \"What is the most popular feature used by our paid subscribers\"\\n# formatted_query = input(\\n#     dedent(\"\"\"\\n#       {What is the most popular feature used by our paid subscribers}\\n#     \"\"\"))\\n# print(formatted_query)\\ncrew = MetricDiscoveryInputCrew()\\nresult = crew.run(query)', 'from crewai.process import Process\\nfrom typing import Any\\nclass MetricDiscoveryInputCrew(Expert):\\n  name = \"MetricDiscovery\"\\n  description = (\\n       \"Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\\n    )\\n  public_description = \"Metric discovery crew\"\\n  arg_description = \"Query related to metrics.\"\\n\\n  def crew_process(self, query: str):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    # print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n    return crew\\n  \\n\\n  def run(self, query: str):\\n    crew = self.crew_process.kickoff(query)\\n    result = crew.kickoff()\\n    return result\\n  \\n  def call(\\n        self, goal: str, task: str, input_str: str, *args: Any, **kwargs: Any\\n    ) -> str:\\n    pass', 'query = \"What is the most popular feature used by our paid subscribers\"\\n# formatted_query = input(\\n#     dedent(\"\"\"\\n#       {What is the most popular feature used by our paid subscribers}\\n#     \"\"\"))\\n# print(formatted_query)\\ncrew = MetricDiscoveryInputCrew()\\nresult = crew.run(query)', 'from crewai.process import Process\\nfrom typing import Any\\nclass MetricDiscoveryInputCrew(Expert):\\n  name = \"MetricDiscovery\"\\n  description = (\\n       \"Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\\n    )\\n  public_description = \"Metric discovery crew\"\\n  arg_description = \"Query related to metrics.\"\\n\\n  def crew_process(self, query: str):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    # print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n    return crew\\n  \\n\\n  def run(self, query: str):\\n    crew = self.crew_process(query)\\n    result = crew.kickoff()\\n    return result\\n  \\n  def call(\\n        self, goal: str, task: str, input_str: str, *args: Any, **kwargs: Any\\n    ) -> str:\\n    pass', 'query = \"What is the most popular feature used by our paid subscribers\"\\n# formatted_query = input(\\n#     dedent(\"\"\"\\n#       {What is the most popular feature used by our paid subscribers}\\n#     \"\"\"))\\n# print(formatted_query)\\ncrew = MetricDiscoveryInputCrew()\\nresult = crew.run(query)'], '_oh': {}, '_dh': [PosixPath('/Users/k.abhishek/Documents/experiments/metric_store/metric_store_gen_ai/experiments')], 'In': ['', 'a ={\"a\" : MetricDiscoveryInputCrew()}', 'from crewai.process import Process\\nfrom typing import Any\\nclass MetricDiscoveryInputCrew(Expert):\\n  name = \"MetricDiscovery\"\\n  description = (\\n       \"Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\\n    )\\n  public_description = \"Metric discovery crew\"\\n  arg_description = \"Query related to metrics.\"\\n\\n  def __init__(self, query):\\n    self.query = query\\n    self.crew_process = self.crew_process()\\n    # self.llm = llm_gpt\\n  def crew_process(self):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    # print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, self.query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n    return crew\\n\\n  def run(self):\\n    result = self.crew_process.kickoff()\\n    return result\\n  \\n  def call(\\n        self, goal: str, task: str, input_str: str, *args: Any, **kwargs: Any\\n    ) -> str:\\n    pass', '#initialize\\n#     model\\n#     environment variables\\n\\nimport sys\\nsys.path.append(\\'..\\')\\nfrom src.utils.llamaindex_retriever import LlamaIndexRetriever\\nfrom langchain.vectorstores import FAISS\\nfrom langchain.embeddings.azure_openai import AzureOpenAIEmbeddings\\nfrom langchain.embeddings.openai import OpenAIEmbeddings\\nfrom dotenv import load_dotenv\\nimport os\\nfrom langchain.chat_models import AzureChatOpenAI\\n\\ndef load_env_variables(file_path):\\n    load_dotenv(file_path)\\n    print(\"Environment variables loaded successfully!\")\\n\\nenv_file_path = \"../.env\"\\nload_env_variables = load_env_variables(env_file_path)\\nmax_tokens = 3500\\ntemperature = 0.1\\n\\n# embeddings = AzureOpenAIEmbeddings(azure_deployment=azure_deployment, openai_api_version=openai_api_version)\\nembeddings =  AzureOpenAIEmbeddings(\\n        deployment=os.getenv(\"EMB_DEPLOYMENT\"),\\n        openai_api_version=os.getenv(\"EMB_OPENAI_API_VERSION\"),\\n        model=os.getenv(\"EMB_MODEL\"),\\n        openai_api_key=os.getenv(\"EMB_OPENAI_API_KEY\"),\\n        openai_api_base=os.getenv(\"EMB_OPENAI_ENDPOINT\"),\\n        openai_api_type=os.getenv(\"EMB_API_TYPE\"),\\n    )\\n\\nllm_gpt = AzureChatOpenAI(deployment_name=os.getenv(\\'AZURE_OPENAI_DEPLOYMENT_NAME\\'), openai_api_version=os.getenv(\"OPENAI_API_VERSION\"),\\n                        openai_api_base=os.getenv(\"OPENAI_API_BASE\"), \\n                        openai_api_type= os.getenv(\"OPENAI_API_TYPE\"),\\n                        openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\\n                        max_tokens=max_tokens,\\n                        temperature=temperature)', '#define utils\\nfrom src.utils.cube_semantic_custom import CubeSemanticLoader\\ndef fetch_cube_metadata(*args, **kwargs):\\n    try:\\n        # # Load document from Cube meta api\\n        loader = CubeSemanticLoader(os.getenv(\"CUBE_API_URL\"), os.getenv(\"CUBE_TOKEN\"), False)\\n        documents = loader.load()\\n        # to_json()\\n        return documents\\n    except Exception as e:\\n        # Handle exceptions gracefully and return an error response\\n        print(\"Error in fetching metadata from cube: \" + str(e))\\n        return 0\\n\\ndef create_vector_store(documents, local_vector_store_path, *args, **kwargs):\\n    print(\"Loaded documents: \" + str(documents))\\n    vectorstore = FAISS.from_documents(documents, embeddings)\\n    vectorstore.save_local(local_vector_store_path)\\n    print(\"Vector store created and saved successfully!\")\\n\\ndef load_vector_store(vector_store_path, embeddings, *args, **kwargs):\\n    # Load the vector store from the local file system\\n    vectorstore = FAISS.load_local(vector_store_path, embeddings, allow_dangerous_deserialization=True)\\n    print(\"Vector store loaded successfully!\")\\n    \\n    return vectorstore', '#load existing vector store\\nvector_store_path = \"/Users/k.abhishek/Documents/experiments/metric_store/metric_store_gen_ai/data/vector_store/cube_meta_faiss_index\"\\nvectorstore = load_vector_store(vector_store_path, embeddings)', 'import json\\nfrom crewai import Agent, Task, Crew\\nfrom langchain.tools import tool\\nfrom src.utils.llamaindex_retriever import LlamaIndexRetriever\\nfrom typing import Optional, Type\\nfrom langchain.callbacks.manager import (\\n    AsyncCallbackManagerForToolRun,\\n    CallbackManagerForToolRun,\\n)\\n# Import things that are needed generically\\nfrom langchain.pydantic_v1 import BaseModel, Field\\n# from langchain.tools import BaseTool, StructuredTool, tool\\nfrom crewai_tools import BaseTool\\n\\n\\ndef get_similar_documents_faiss(query, max_number_documents=3):\\n  vectorstore = FAISS.load_local(vector_store_path, embeddings, allow_dangerous_deserialization=True)\\n  docs = vectorstore.similarity_search_with_relevance_scores(query, max_number_documents)\\n  relevant_documents = []\\n  for doc in docs:\\n      doc = doc[0]\\n      meta = {\\'text\\':doc.page_content, \\'table_metadata\\': doc.metadata}\\n      relevant_documents.append(meta)\\n  return relevant_documents\\n\\ndef get_similar_documents(query, max_number_documents=3):\\n    return get_similar_documents_faiss(query, max_number_documents)\\n\\n\\nclass QueryInput(BaseModel):\\n    query: str = Field(description=\"should be enquiry query\")\\n\\nclass TerminationHandler(CallbackManagerForToolRun):\\n    pass\\n\\nclass RephraseInputQuery(BaseTool):\\n    name:str = \"rephrase_input_query\"\\n    description :str = \"Useful to rephrase the query to capture the intent of the user regarding metric information\"\\n    args_schema: Type[BaseModel] = QueryInput\\n\\n    def _run(\\n        self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None\\n    ) -> str:\\n        \"\"\"Use the tool.\"\"\"\\n        metric_description = self.rephrase_input_query(query)\\n        return metric_description\\n\\n    async def _arun(\\n        self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None\\n    ) -> str:\\n        \"\"\"Use the tool asynchronously.\"\"\"\\n        raise NotImplementedError(\"custom_search does not support async\")\\n    \\n    \\n    def rephrase_input_query(self, query, *args, **kwargs):\\n        agent = Agent(\\n                role=\\'Intent Capturer\\',\\n                goal=\\n                \\'Rephrasing the query to capture the intent of the user regarding metric information\\',\\n                backstory=\\n                \"You are an expert to understand the user\\'s intent and rephrase the query to capture the intent of the user accurately.\",\\n                llm = llm_gpt,\\n                allow_delegation=False)\\n        task = Task(\\n                agent=agent,\\n                description=\\n                f\\'Rephrase the query to capture the intent of the user regarding metric information. The query is {query}. Donot add any noise to the response\\',\\n                expected_output=\"some string\",\\n        \\n            )\\n        extracted_metrics = task.execute()\\n\\n        return extracted_metrics\\n    \\n\\n    \\nclass MetricDiscovery(BaseTool):\\n    name :str = \"metric_discovery\"\\n    description:str = \"\"\"Useful for general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\"\"\\n    args_schema: Type[BaseModel] = QueryInput\\n\\n    def _run(\\n        self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None\\n    ) -> str:\\n        \"\"\"Use the tool.\"\"\"\\n        metric_description = self.metric_discovery(query)\\n        return metric_description\\n\\n    async def _arun(\\n        self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None\\n    ) -> str:\\n        \"\"\"Use the tool asynchronously.\"\"\"\\n        raise NotImplementedError(\"custom_search does not support async\")\\n    \\n    \\n    def metric_discovery(self, query, *args, **kwargs):\\n        \"\"\"Useful for general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\"\"\\n        relevant_documents = get_similar_documents(query)\\n        agent = Agent(\\n                role=\\'Data Analyst Assistant\\',\\n                goal=\\n                \\'Empower users to understand and utilize data effectively. This includes helping them discover relevant metrics, interpreting their meaning\\',\\n                backstory=\\n                \"The primary purpose is to bridge the gap between raw data and user comprehension, fostering a data-driven culture within the organization.\",\\n                llm = llm_gpt,\\n                allow_delegation=False)  \\n        \\n        task = Task(\\n                agent=agent,\\n                description=\\n                \"\"\" You are responding to  question {metric_description} with answer from the Metadata provided to you as {relevant_documents}}.\\n                    Strictly answer the question with the information present in metadata only.\\n                    Respond with \"Sorry, the query is out of scope.\" if the answer is not present in metadata and terminate further reasoning and prcoess.\\n                    \"\"\",\\n                expected_output=\"some string\",\\n        \\n            )\\n        output = task.execute()\\n\\n        return output', '# def check_termination(task_output):\\n#     agent = Agent(\\n#                 role=\\'Determine query completion\\',\\n#                 goal=\\n#                 \\'Given task output, determine termination of crew workflow\\',\\n#                 backstory=\\n#                 \"Given user query request from user determine if no more new task is needed to be executed\",\\n#                 llm = llm_gpt,\\n#                 allow_delegation=False)\\n#     task = Task(\\n#                 agent=agent,\\n#                 description=\\n#                 f\\'Given task output, if the query is completed and the task result determines that the query is out of scope then terminate the workflow or else the required query is satisfied. Following is the task result {task_output}\\',\\n#                 expected_output=\"some string\",\\n        \\n#             )\\n#     termination_status = task.execute()\\n#     return termination_status\\nclass MetricDiscoveryTasks():\\n  def metric_isolation(self, agent, query):\\n    return Task(description=(f\"\"\"\\n        Rephrase the query to capture the intent of the user regarding metric information. The query is {query}. Donot add any noise to the response.\\n        {self.__tip_section()}\"\"\"),\\n      agent=agent,\\n      expected_output=\"Reformatted query to capture the intent of the user regarding metric information.\",\\n      # callback=callback_function,\\n    )\\n  \\n  def metric_discovery(self, agent):\\n    return Task(description=(f\"\"\"\\n        Answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\\n        {self.__tip_section()}\"\"\"),\\n      agent=agent,\\n      expected_output=\"If relevant metric exists in metadata, provide the answer. Else, respond with \\'Sorry, the query is out of scope.\\' and terminate process.\",\\n      # callback=callback_function,\\n    )\\n  def __tip_section(self):\\n    return \"If you do your BEST WORK, I\\'ll give you a $10,000 commission!\"\\n  \\n  ', 'class MetricDiscoveryAgent():\\n  def user_intent_capture(self):\\n    return Agent(\\n      role=\\'Intent Capturer\\',\\n      goal=\\n      \\'Rephrasing the query to capture the intent of the user regarding metric information\\',\\n      backstory=\\n      \"You are an expert to understand the user\\'s intent and rephrase the query to capture the intent of the user accurately.\",\\n      verbose=True,\\n      tools=[\\n        RephraseInputQuery()\\n      ],\\n      llm = llm_gpt,\\n    )\\n  def discover_metric_info(self):\\n    return Agent(\\n     role=\\'Data Analyst Assistant\\',\\n      goal=\\n      \\'Empower users to understand and utilize data effectively. This includes helping them discover relevant metrics, interpreting their meaning\\',\\n      backstory=\\n      \"The primary purpose is to bridge the gap between raw data and user comprehension, fostering a data-driven culture within the organization.\",\\n      llm = llm_gpt,\\n      verbose=True,\\n      tools=[\\n        MetricDiscovery()\\n      ],\\n    )', 'def after_task_callback(output):\\n  # Perform actions after the task, \\n  # for example, logging or updating agent state\\n  \\n  print(f\"Agent completed task with result: {output}\")\\n\\n# Assigning the function to task_callback\\ntask_callback = after_task_callback', 'def test_callback():\\n        # Accessing local variables\\n        print(\"Local variables:\", locals())\\n        \\n        # Accessing global variables\\n        print(\"Global variables:\", globals())    \\n        \\n        # Accessing built-in variables\\n        print(\"Built-in variables:\", dir(__builtins__))\\n        after_task_callback(\"output\")\\n  ', 'from abc import ABC, abstractmethod\\nclass Expert(ABC):\\n    name: str = \"\"\\n    description: str = \"\"\\n    public_description: str = \"\"\\n    arg_description: str = \"The argument to the function.\"\\n\\n    @abstractmethod\\n    def call(\\n        self,\\n        goal: str,\\n        task: str,\\n        input_str: str,\\n    ) -> str:\\n        pass', 'from crewai.process import Process\\nfrom typing import Any\\nclass MetricDiscoveryInputCrew(Expert):\\n  name = \"MetricDiscovery\"\\n  description = (\\n       \"Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\\n    )\\n  public_description = \"Metric discovery crew\"\\n  arg_description = \"Query related to metrics.\"\\n\\n  def __init__(self, query):\\n    self.query = query\\n    self.crew_process = self.crew_process()\\n    # self.llm = llm_gpt\\n  def crew_process(self):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    # print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, self.query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n    return crew\\n\\n  def run(self):\\n    result = self.crew_process.kickoff()\\n    return result\\n  \\n  def call(\\n        self, goal: str, task: str, input_str: str, *args: Any, **kwargs: Any\\n    ) -> str:\\n    pass', 'a ={\"a\" : MetricDiscoveryInputCrew()}', 'from crewai.process import Process\\nfrom typing import Any\\nclass MetricDiscoveryInputCrew(Expert):\\n  name = \"MetricDiscovery\"\\n  description = (\\n       \"Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\\n    )\\n  public_description = \"Metric discovery crew\"\\n  arg_description = \"Query related to metrics.\"\\n\\n  def __init__(self):\\n    # self.query = query\\n    self.crew_process = self.crew_process()\\n    # self.llm = llm_gpt\\n  def crew_process(self, query: str):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    # print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n    return crew\\n\\n  def run(self, query: str):\\n    result = self.crew_process.kickoff()\\n    return result\\n  \\n  def call(\\n        self, goal: str, task: str, input_str: str, *args: Any, **kwargs: Any\\n    ) -> str:\\n    pass', 'a ={\"a\" : MetricDiscoveryInputCrew()}', 'from crewai.process import Process\\nfrom typing import Any\\nclass MetricDiscoveryInputCrew(Expert):\\n  name = \"MetricDiscovery\"\\n  description = (\\n       \"Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\\n    )\\n  public_description = \"Metric discovery crew\"\\n  arg_description = \"Query related to metrics.\"\\n\\n  def crew_process(self, query: str):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    # print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n    return crew\\n  \\n\\n  def run(self, query: str):\\n    result = self.crew_process.kickoff(query)\\n    return result\\n  \\n  def call(\\n        self, goal: str, task: str, input_str: str, *args: Any, **kwargs: Any\\n    ) -> str:\\n    pass', 'a ={\"a\" : MetricDiscoveryInputCrew()}', 'objectives = parse_with_handling(task_output_parser, response.content)\\nprint(objectives)', 'intents = {\\n    \"discover_metrics\": \"Identify relevant metrics based on user objectives. (e.g., Suggest metrics to measure customer satisfaction)\",\\n    \"fetch_data\": \"Retrieve data for a specific metric the user has already identified.\",\\n    # \"analyze_trends\": \"Analyze trends within the fetched data to provide deeper insights.\",\\n    \"interpret_metrics\": \"Explain the meaning of the data in the context of the user\\'s objective.\",\\n    \"understand_metrics\": \"Provide information about a metric\\'s definition and purpose.\"\\n}\\nprompt_template = PromptTemplate.from_template(\"\"\"You are an intelligent assistant focused on helping users with metrics and data. Your primary goal is to break down user queries ({query}) into a concise list of high-level objectives.\\n\\n**Intents:**\\n\\n{intents}\\n\\nImportant Notes:\\n* Alignment with Intents: The new objectives should strictly align with the provided intents.\\n* Prioritize Clarity & Efficiency:  Minimize the number of objectives and maintain a high-level overview. \\n* Direct Match: If the query aligns perfectly with one intent (e.g., \"What\\'s the current customer churn rate?\" for Fetch Data), don\\'t alter it.\\n* Outside Scope: If the query falls outside these intents (e.g., \"Book a flight\"), return an empty list.\\n* Focus on User Need: Keep responses clear and concise, avoiding unnecessary information. \\n* Output Format:  Respond with a list containing the breakdown of objectives.\\n\\n**Here\\'s the user query: {query}\\n\\nWhat is the high-level breakdown of objectives for this query?\\n\"\"\")\\n\\n\\n\\n# Format the intent descriptions for the prompt\\nformatted_intents = \"\\\\n\".join([f\"* {intent_name}: {description}\" for intent_name, description in intents.items()])\\nquery = \"What dose the vessel name column represents?\"\\n# Insert formatted intents into the prompt template\\ncompleted_prompt = prompt_template.format(intents=formatted_intents, query=query)\\n# Use the completed prompt with the AzureChatOpenAI model\\nresponse = llm_gpt.invoke(completed_prompt)\\n\\nprint(response)', 'query = \"What is the most popular feature used by our paid subscribers\"\\n# formatted_query = input(\\n#     dedent(\"\"\"\\n#       {What is the most popular feature used by our paid subscribers}\\n#     \"\"\"))\\n# print(formatted_query)\\ncrew = MetricDiscoveryInputCrew()\\nresult = crew.run(query)', 'from crewai.process import Process\\nfrom typing import Any\\nclass MetricDiscoveryInputCrew(Expert):\\n  name = \"MetricDiscovery\"\\n  description = (\\n       \"Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\\n    )\\n  public_description = \"Metric discovery crew\"\\n  arg_description = \"Query related to metrics.\"\\n\\n  def crew_process(self, query: str):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    # print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n    return crew\\n  \\n\\n  def run(self, query: str):\\n    crew = self.crew_process.kickoff(query)\\n    result = crew.kickoff()\\n    return result\\n  \\n  def call(\\n        self, goal: str, task: str, input_str: str, *args: Any, **kwargs: Any\\n    ) -> str:\\n    pass', 'query = \"What is the most popular feature used by our paid subscribers\"\\n# formatted_query = input(\\n#     dedent(\"\"\"\\n#       {What is the most popular feature used by our paid subscribers}\\n#     \"\"\"))\\n# print(formatted_query)\\ncrew = MetricDiscoveryInputCrew()\\nresult = crew.run(query)', 'from crewai.process import Process\\nfrom typing import Any\\nclass MetricDiscoveryInputCrew(Expert):\\n  name = \"MetricDiscovery\"\\n  description = (\\n       \"Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\\n    )\\n  public_description = \"Metric discovery crew\"\\n  arg_description = \"Query related to metrics.\"\\n\\n  def crew_process(self, query: str):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    # print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n    return crew\\n  \\n\\n  def run(self, query: str):\\n    crew = self.crew_process(query)\\n    result = crew.kickoff()\\n    return result\\n  \\n  def call(\\n        self, goal: str, task: str, input_str: str, *args: Any, **kwargs: Any\\n    ) -> str:\\n    pass', 'query = \"What is the most popular feature used by our paid subscribers\"\\n# formatted_query = input(\\n#     dedent(\"\"\"\\n#       {What is the most popular feature used by our paid subscribers}\\n#     \"\"\"))\\n# print(formatted_query)\\ncrew = MetricDiscoveryInputCrew()\\nresult = crew.run(query)'], 'Out': {}, 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x109951f50>>, 'exit': <IPython.core.autocall.ZMQExitAutocall object at 0x10995b150>, 'quit': <IPython.core.autocall.ZMQExitAutocall object at 0x10995b150>, 'open': <function open at 0x108681440>, '_': '', '__': '', '___': '', '__vsc_ipynb_file__': '/Users/k.abhishek/Documents/experiments/metric_store/metric_store_gen_ai/experiments/agent_flow_v2.ipynb', '_i': 'from crewai.process import Process\\nfrom typing import Any\\nclass MetricDiscoveryInputCrew(Expert):\\n  name = \"MetricDiscovery\"\\n  description = (\\n       \"Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\\n    )\\n  public_description = \"Metric discovery crew\"\\n  arg_description = \"Query related to metrics.\"\\n\\n  def crew_process(self, query: str):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    # print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n    return crew\\n  \\n\\n  def run(self, query: str):\\n    crew = self.crew_process(query)\\n    result = crew.kickoff()\\n    return result\\n  \\n  def call(\\n        self, goal: str, task: str, input_str: str, *args: Any, **kwargs: Any\\n    ) -> str:\\n    pass', '_ii': 'query = \"What is the most popular feature used by our paid subscribers\"\\n# formatted_query = input(\\n#     dedent(\"\"\"\\n#       {What is the most popular feature used by our paid subscribers}\\n#     \"\"\"))\\n# print(formatted_query)\\ncrew = MetricDiscoveryInputCrew()\\nresult = crew.run(query)', '_iii': 'from crewai.process import Process\\nfrom typing import Any\\nclass MetricDiscoveryInputCrew(Expert):\\n  name = \"MetricDiscovery\"\\n  description = (\\n       \"Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\\n    )\\n  public_description = \"Metric discovery crew\"\\n  arg_description = \"Query related to metrics.\"\\n\\n  def crew_process(self, query: str):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    # print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n    return crew\\n  \\n\\n  def run(self, query: str):\\n    crew = self.crew_process.kickoff(query)\\n    result = crew.kickoff()\\n    return result\\n  \\n  def call(\\n        self, goal: str, task: str, input_str: str, *args: Any, **kwargs: Any\\n    ) -> str:\\n    pass', '_i1': 'a ={\"a\" : MetricDiscoveryInputCrew()}', '_i2': 'from crewai.process import Process\\nfrom typing import Any\\nclass MetricDiscoveryInputCrew(Expert):\\n  name = \"MetricDiscovery\"\\n  description = (\\n       \"Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\\n    )\\n  public_description = \"Metric discovery crew\"\\n  arg_description = \"Query related to metrics.\"\\n\\n  def __init__(self, query):\\n    self.query = query\\n    self.crew_process = self.crew_process()\\n    # self.llm = llm_gpt\\n  def crew_process(self):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    # print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, self.query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n    return crew\\n\\n  def run(self):\\n    result = self.crew_process.kickoff()\\n    return result\\n  \\n  def call(\\n        self, goal: str, task: str, input_str: str, *args: Any, **kwargs: Any\\n    ) -> str:\\n    pass', 'Process': <enum 'Process'>, 'Any': typing.Any, '_i3': '#initialize\\n#     model\\n#     environment variables\\n\\nimport sys\\nsys.path.append(\\'..\\')\\nfrom src.utils.llamaindex_retriever import LlamaIndexRetriever\\nfrom langchain.vectorstores import FAISS\\nfrom langchain.embeddings.azure_openai import AzureOpenAIEmbeddings\\nfrom langchain.embeddings.openai import OpenAIEmbeddings\\nfrom dotenv import load_dotenv\\nimport os\\nfrom langchain.chat_models import AzureChatOpenAI\\n\\ndef load_env_variables(file_path):\\n    load_dotenv(file_path)\\n    print(\"Environment variables loaded successfully!\")\\n\\nenv_file_path = \"../.env\"\\nload_env_variables = load_env_variables(env_file_path)\\nmax_tokens = 3500\\ntemperature = 0.1\\n\\n# embeddings = AzureOpenAIEmbeddings(azure_deployment=azure_deployment, openai_api_version=openai_api_version)\\nembeddings =  AzureOpenAIEmbeddings(\\n        deployment=os.getenv(\"EMB_DEPLOYMENT\"),\\n        openai_api_version=os.getenv(\"EMB_OPENAI_API_VERSION\"),\\n        model=os.getenv(\"EMB_MODEL\"),\\n        openai_api_key=os.getenv(\"EMB_OPENAI_API_KEY\"),\\n        openai_api_base=os.getenv(\"EMB_OPENAI_ENDPOINT\"),\\n        openai_api_type=os.getenv(\"EMB_API_TYPE\"),\\n    )\\n\\nllm_gpt = AzureChatOpenAI(deployment_name=os.getenv(\\'AZURE_OPENAI_DEPLOYMENT_NAME\\'), openai_api_version=os.getenv(\"OPENAI_API_VERSION\"),\\n                        openai_api_base=os.getenv(\"OPENAI_API_BASE\"), \\n                        openai_api_type= os.getenv(\"OPENAI_API_TYPE\"),\\n                        openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\\n                        max_tokens=max_tokens,\\n                        temperature=temperature)', 'sys': <module 'sys' (built-in)>, 'LlamaIndexRetriever': <class 'src.utils.llamaindex_retriever.LlamaIndexRetriever'>, 'FAISS': <class 'langchain_community.vectorstores.faiss.FAISS'>, 'AzureOpenAIEmbeddings': <class 'langchain_community.embeddings.azure_openai.AzureOpenAIEmbeddings'>, 'OpenAIEmbeddings': <class 'langchain_community.embeddings.openai.OpenAIEmbeddings'>, 'load_dotenv': <function load_dotenv at 0x12bf06c00>, 'os': <module 'os' (frozen)>, 'AzureChatOpenAI': <class 'langchain_community.chat_models.azure_openai.AzureChatOpenAI'>, 'load_env_variables': None, 'env_file_path': '../.env', 'max_tokens': 3500, 'temperature': 0.1, 'embeddings': AzureOpenAIEmbeddings(client=<openai.resources.embeddings.Embeddings object at 0x13a07c650>, async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x13988de90>, model='text-embedding-ada-002', deployment=None, openai_api_version='2023-03-15-preview', openai_api_base='https://polarisopenai.openai.azure.com//openai/deployments/text-embedding-ada-002', openai_api_type='azure', openai_proxy='', embedding_ctx_length=8191, openai_api_key='35431d6cd1874798b9ebbd6bdfbb0720', openai_organization=None, allowed_special=set(), disallowed_special='all', chunk_size=16, max_retries=2, request_timeout=None, headers=None, tiktoken_enabled=True, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, retry_min_seconds=4, retry_max_seconds=20, http_client=None, azure_endpoint=None, azure_ad_token=None, azure_ad_token_provider=None, validate_base_url=True), 'llm_gpt': AzureChatOpenAI(callbacks=[<crewai.utilities.token_counter_callback.TokenCalcHandler object at 0x13aa30210>], client=<openai.resources.chat.completions.Completions object at 0x13a114190>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x1396fae50>, temperature=0.1, openai_api_key='43b8528ab70d48359744cd0165a1167e', openai_api_base='https://polariseastus2.openai.azure.com/openai/deployments/gpt4-turbo', openai_proxy='', max_tokens=3500, openai_api_version='2023-07-01-preview', openai_api_type='azure'), '_i4': '#define utils\\nfrom src.utils.cube_semantic_custom import CubeSemanticLoader\\ndef fetch_cube_metadata(*args, **kwargs):\\n    try:\\n        # # Load document from Cube meta api\\n        loader = CubeSemanticLoader(os.getenv(\"CUBE_API_URL\"), os.getenv(\"CUBE_TOKEN\"), False)\\n        documents = loader.load()\\n        # to_json()\\n        return documents\\n    except Exception as e:\\n        # Handle exceptions gracefully and return an error response\\n        print(\"Error in fetching metadata from cube: \" + str(e))\\n        return 0\\n\\ndef create_vector_store(documents, local_vector_store_path, *args, **kwargs):\\n    print(\"Loaded documents: \" + str(documents))\\n    vectorstore = FAISS.from_documents(documents, embeddings)\\n    vectorstore.save_local(local_vector_store_path)\\n    print(\"Vector store created and saved successfully!\")\\n\\ndef load_vector_store(vector_store_path, embeddings, *args, **kwargs):\\n    # Load the vector store from the local file system\\n    vectorstore = FAISS.load_local(vector_store_path, embeddings, allow_dangerous_deserialization=True)\\n    print(\"Vector store loaded successfully!\")\\n    \\n    return vectorstore', 'CubeSemanticLoader': <class 'src.utils.cube_semantic_custom.CubeSemanticLoader'>, 'fetch_cube_metadata': <function fetch_cube_metadata at 0x13a119120>, 'create_vector_store': <function create_vector_store at 0x13a1193a0>, 'load_vector_store': <function load_vector_store at 0x13a119300>, '_i5': '#load existing vector store\\nvector_store_path = \"/Users/k.abhishek/Documents/experiments/metric_store/metric_store_gen_ai/data/vector_store/cube_meta_faiss_index\"\\nvectorstore = load_vector_store(vector_store_path, embeddings)', 'vector_store_path': '/Users/k.abhishek/Documents/experiments/metric_store/metric_store_gen_ai/data/vector_store/cube_meta_faiss_index', 'vectorstore': <langchain_community.vectorstores.faiss.FAISS object at 0x13a08f950>, '_i6': 'import json\\nfrom crewai import Agent, Task, Crew\\nfrom langchain.tools import tool\\nfrom src.utils.llamaindex_retriever import LlamaIndexRetriever\\nfrom typing import Optional, Type\\nfrom langchain.callbacks.manager import (\\n    AsyncCallbackManagerForToolRun,\\n    CallbackManagerForToolRun,\\n)\\n# Import things that are needed generically\\nfrom langchain.pydantic_v1 import BaseModel, Field\\n# from langchain.tools import BaseTool, StructuredTool, tool\\nfrom crewai_tools import BaseTool\\n\\n\\ndef get_similar_documents_faiss(query, max_number_documents=3):\\n  vectorstore = FAISS.load_local(vector_store_path, embeddings, allow_dangerous_deserialization=True)\\n  docs = vectorstore.similarity_search_with_relevance_scores(query, max_number_documents)\\n  relevant_documents = []\\n  for doc in docs:\\n      doc = doc[0]\\n      meta = {\\'text\\':doc.page_content, \\'table_metadata\\': doc.metadata}\\n      relevant_documents.append(meta)\\n  return relevant_documents\\n\\ndef get_similar_documents(query, max_number_documents=3):\\n    return get_similar_documents_faiss(query, max_number_documents)\\n\\n\\nclass QueryInput(BaseModel):\\n    query: str = Field(description=\"should be enquiry query\")\\n\\nclass TerminationHandler(CallbackManagerForToolRun):\\n    pass\\n\\nclass RephraseInputQuery(BaseTool):\\n    name:str = \"rephrase_input_query\"\\n    description :str = \"Useful to rephrase the query to capture the intent of the user regarding metric information\"\\n    args_schema: Type[BaseModel] = QueryInput\\n\\n    def _run(\\n        self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None\\n    ) -> str:\\n        \"\"\"Use the tool.\"\"\"\\n        metric_description = self.rephrase_input_query(query)\\n        return metric_description\\n\\n    async def _arun(\\n        self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None\\n    ) -> str:\\n        \"\"\"Use the tool asynchronously.\"\"\"\\n        raise NotImplementedError(\"custom_search does not support async\")\\n    \\n    \\n    def rephrase_input_query(self, query, *args, **kwargs):\\n        agent = Agent(\\n                role=\\'Intent Capturer\\',\\n                goal=\\n                \\'Rephrasing the query to capture the intent of the user regarding metric information\\',\\n                backstory=\\n                \"You are an expert to understand the user\\'s intent and rephrase the query to capture the intent of the user accurately.\",\\n                llm = llm_gpt,\\n                allow_delegation=False)\\n        task = Task(\\n                agent=agent,\\n                description=\\n                f\\'Rephrase the query to capture the intent of the user regarding metric information. The query is {query}. Donot add any noise to the response\\',\\n                expected_output=\"some string\",\\n        \\n            )\\n        extracted_metrics = task.execute()\\n\\n        return extracted_metrics\\n    \\n\\n    \\nclass MetricDiscovery(BaseTool):\\n    name :str = \"metric_discovery\"\\n    description:str = \"\"\"Useful for general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\"\"\\n    args_schema: Type[BaseModel] = QueryInput\\n\\n    def _run(\\n        self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None\\n    ) -> str:\\n        \"\"\"Use the tool.\"\"\"\\n        metric_description = self.metric_discovery(query)\\n        return metric_description\\n\\n    async def _arun(\\n        self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None\\n    ) -> str:\\n        \"\"\"Use the tool asynchronously.\"\"\"\\n        raise NotImplementedError(\"custom_search does not support async\")\\n    \\n    \\n    def metric_discovery(self, query, *args, **kwargs):\\n        \"\"\"Useful for general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\"\"\\n        relevant_documents = get_similar_documents(query)\\n        agent = Agent(\\n                role=\\'Data Analyst Assistant\\',\\n                goal=\\n                \\'Empower users to understand and utilize data effectively. This includes helping them discover relevant metrics, interpreting their meaning\\',\\n                backstory=\\n                \"The primary purpose is to bridge the gap between raw data and user comprehension, fostering a data-driven culture within the organization.\",\\n                llm = llm_gpt,\\n                allow_delegation=False)  \\n        \\n        task = Task(\\n                agent=agent,\\n                description=\\n                \"\"\" You are responding to  question {metric_description} with answer from the Metadata provided to you as {relevant_documents}}.\\n                    Strictly answer the question with the information present in metadata only.\\n                    Respond with \"Sorry, the query is out of scope.\" if the answer is not present in metadata and terminate further reasoning and prcoess.\\n                    \"\"\",\\n                expected_output=\"some string\",\\n        \\n            )\\n        output = task.execute()\\n\\n        return output', 'json': <module 'json' from '/Users/k.abhishek/anaconda3/envs/agentgpt/lib/python3.11/json/__init__.py'>, 'Agent': <class 'crewai.agent.Agent'>, 'Task': <class 'crewai.task.Task'>, 'Crew': <class 'crewai.crew.Crew'>, 'tool': <function tool at 0x109f0a160>, 'Optional': typing.Optional, 'Type': typing.Type, 'AsyncCallbackManagerForToolRun': <class 'langchain_core.callbacks.manager.AsyncCallbackManagerForToolRun'>, 'CallbackManagerForToolRun': <class 'langchain_core.callbacks.manager.CallbackManagerForToolRun'>, 'BaseModel': <class 'pydantic.v1.main.BaseModel'>, 'Field': <function Field at 0x112094e00>, 'BaseTool': <class 'crewai_tools.tools.base_tool.BaseTool'>, 'get_similar_documents_faiss': <function get_similar_documents_faiss at 0x13a11afc0>, 'get_similar_documents': <function get_similar_documents at 0x13a11af20>, 'QueryInput': <class '__main__.QueryInput'>, 'TerminationHandler': <class '__main__.TerminationHandler'>, 'RephraseInputQuery': <class '__main__.RephraseInputQuery'>, 'MetricDiscovery': <class '__main__.MetricDiscovery'>, '_i7': '# def check_termination(task_output):\\n#     agent = Agent(\\n#                 role=\\'Determine query completion\\',\\n#                 goal=\\n#                 \\'Given task output, determine termination of crew workflow\\',\\n#                 backstory=\\n#                 \"Given user query request from user determine if no more new task is needed to be executed\",\\n#                 llm = llm_gpt,\\n#                 allow_delegation=False)\\n#     task = Task(\\n#                 agent=agent,\\n#                 description=\\n#                 f\\'Given task output, if the query is completed and the task result determines that the query is out of scope then terminate the workflow or else the required query is satisfied. Following is the task result {task_output}\\',\\n#                 expected_output=\"some string\",\\n        \\n#             )\\n#     termination_status = task.execute()\\n#     return termination_status\\nclass MetricDiscoveryTasks():\\n  def metric_isolation(self, agent, query):\\n    return Task(description=(f\"\"\"\\n        Rephrase the query to capture the intent of the user regarding metric information. The query is {query}. Donot add any noise to the response.\\n        {self.__tip_section()}\"\"\"),\\n      agent=agent,\\n      expected_output=\"Reformatted query to capture the intent of the user regarding metric information.\",\\n      # callback=callback_function,\\n    )\\n  \\n  def metric_discovery(self, agent):\\n    return Task(description=(f\"\"\"\\n        Answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\\n        {self.__tip_section()}\"\"\"),\\n      agent=agent,\\n      expected_output=\"If relevant metric exists in metadata, provide the answer. Else, respond with \\'Sorry, the query is out of scope.\\' and terminate process.\",\\n      # callback=callback_function,\\n    )\\n  def __tip_section(self):\\n    return \"If you do your BEST WORK, I\\'ll give you a $10,000 commission!\"\\n  \\n  ', 'MetricDiscoveryTasks': <class '__main__.MetricDiscoveryTasks'>, '_i8': 'class MetricDiscoveryAgent():\\n  def user_intent_capture(self):\\n    return Agent(\\n      role=\\'Intent Capturer\\',\\n      goal=\\n      \\'Rephrasing the query to capture the intent of the user regarding metric information\\',\\n      backstory=\\n      \"You are an expert to understand the user\\'s intent and rephrase the query to capture the intent of the user accurately.\",\\n      verbose=True,\\n      tools=[\\n        RephraseInputQuery()\\n      ],\\n      llm = llm_gpt,\\n    )\\n  def discover_metric_info(self):\\n    return Agent(\\n     role=\\'Data Analyst Assistant\\',\\n      goal=\\n      \\'Empower users to understand and utilize data effectively. This includes helping them discover relevant metrics, interpreting their meaning\\',\\n      backstory=\\n      \"The primary purpose is to bridge the gap between raw data and user comprehension, fostering a data-driven culture within the organization.\",\\n      llm = llm_gpt,\\n      verbose=True,\\n      tools=[\\n        MetricDiscovery()\\n      ],\\n    )', 'MetricDiscoveryAgent': <class '__main__.MetricDiscoveryAgent'>, '_i9': 'def after_task_callback(output):\\n  # Perform actions after the task, \\n  # for example, logging or updating agent state\\n  \\n  print(f\"Agent completed task with result: {output}\")\\n\\n# Assigning the function to task_callback\\ntask_callback = after_task_callback', 'after_task_callback': <function after_task_callback at 0x13a8f4220>, 'task_callback': <function after_task_callback at 0x13a8f4220>, '_i10': 'def test_callback():\\n        # Accessing local variables\\n        print(\"Local variables:\", locals())\\n        \\n        # Accessing global variables\\n        print(\"Global variables:\", globals())    \\n        \\n        # Accessing built-in variables\\n        print(\"Built-in variables:\", dir(__builtins__))\\n        after_task_callback(\"output\")\\n  ', 'test_callback': <function test_callback at 0x13a8f7380>, '_i11': 'from abc import ABC, abstractmethod\\nclass Expert(ABC):\\n    name: str = \"\"\\n    description: str = \"\"\\n    public_description: str = \"\"\\n    arg_description: str = \"The argument to the function.\"\\n\\n    @abstractmethod\\n    def call(\\n        self,\\n        goal: str,\\n        task: str,\\n        input_str: str,\\n    ) -> str:\\n        pass', 'ABC': <class 'abc.ABC'>, 'abstractmethod': <function abstractmethod at 0x106abe480>, 'Expert': <class '__main__.Expert'>, '_i12': 'from crewai.process import Process\\nfrom typing import Any\\nclass MetricDiscoveryInputCrew(Expert):\\n  name = \"MetricDiscovery\"\\n  description = (\\n       \"Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\\n    )\\n  public_description = \"Metric discovery crew\"\\n  arg_description = \"Query related to metrics.\"\\n\\n  def __init__(self, query):\\n    self.query = query\\n    self.crew_process = self.crew_process()\\n    # self.llm = llm_gpt\\n  def crew_process(self):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    # print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, self.query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n    return crew\\n\\n  def run(self):\\n    result = self.crew_process.kickoff()\\n    return result\\n  \\n  def call(\\n        self, goal: str, task: str, input_str: str, *args: Any, **kwargs: Any\\n    ) -> str:\\n    pass', 'MetricDiscoveryInputCrew': <class '__main__.MetricDiscoveryInputCrew'>, '_i13': 'a ={\"a\" : MetricDiscoveryInputCrew()}', '_i14': 'from crewai.process import Process\\nfrom typing import Any\\nclass MetricDiscoveryInputCrew(Expert):\\n  name = \"MetricDiscovery\"\\n  description = (\\n       \"Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\\n    )\\n  public_description = \"Metric discovery crew\"\\n  arg_description = \"Query related to metrics.\"\\n\\n  def __init__(self):\\n    # self.query = query\\n    self.crew_process = self.crew_process()\\n    # self.llm = llm_gpt\\n  def crew_process(self, query: str):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    # print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n    return crew\\n\\n  def run(self, query: str):\\n    result = self.crew_process.kickoff()\\n    return result\\n  \\n  def call(\\n        self, goal: str, task: str, input_str: str, *args: Any, **kwargs: Any\\n    ) -> str:\\n    pass', '_i15': 'a ={\"a\" : MetricDiscoveryInputCrew()}', '_i16': 'from crewai.process import Process\\nfrom typing import Any\\nclass MetricDiscoveryInputCrew(Expert):\\n  name = \"MetricDiscovery\"\\n  description = (\\n       \"Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\\n    )\\n  public_description = \"Metric discovery crew\"\\n  arg_description = \"Query related to metrics.\"\\n\\n  def crew_process(self, query: str):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    # print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n    return crew\\n  \\n\\n  def run(self, query: str):\\n    result = self.crew_process.kickoff(query)\\n    return result\\n  \\n  def call(\\n        self, goal: str, task: str, input_str: str, *args: Any, **kwargs: Any\\n    ) -> str:\\n    pass', '_i17': 'a ={\"a\" : MetricDiscoveryInputCrew()}', 'a': {'a': <__main__.MetricDiscoveryInputCrew object at 0x13a968110>}, '_i18': 'objectives = parse_with_handling(task_output_parser, response.content)\\nprint(objectives)', '_i19': 'intents = {\\n    \"discover_metrics\": \"Identify relevant metrics based on user objectives. (e.g., Suggest metrics to measure customer satisfaction)\",\\n    \"fetch_data\": \"Retrieve data for a specific metric the user has already identified.\",\\n    # \"analyze_trends\": \"Analyze trends within the fetched data to provide deeper insights.\",\\n    \"interpret_metrics\": \"Explain the meaning of the data in the context of the user\\'s objective.\",\\n    \"understand_metrics\": \"Provide information about a metric\\'s definition and purpose.\"\\n}\\nprompt_template = PromptTemplate.from_template(\"\"\"You are an intelligent assistant focused on helping users with metrics and data. Your primary goal is to break down user queries ({query}) into a concise list of high-level objectives.\\n\\n**Intents:**\\n\\n{intents}\\n\\nImportant Notes:\\n* Alignment with Intents: The new objectives should strictly align with the provided intents.\\n* Prioritize Clarity & Efficiency:  Minimize the number of objectives and maintain a high-level overview. \\n* Direct Match: If the query aligns perfectly with one intent (e.g., \"What\\'s the current customer churn rate?\" for Fetch Data), don\\'t alter it.\\n* Outside Scope: If the query falls outside these intents (e.g., \"Book a flight\"), return an empty list.\\n* Focus on User Need: Keep responses clear and concise, avoiding unnecessary information. \\n* Output Format:  Respond with a list containing the breakdown of objectives.\\n\\n**Here\\'s the user query: {query}\\n\\nWhat is the high-level breakdown of objectives for this query?\\n\"\"\")\\n\\n\\n\\n# Format the intent descriptions for the prompt\\nformatted_intents = \"\\\\n\".join([f\"* {intent_name}: {description}\" for intent_name, description in intents.items()])\\nquery = \"What dose the vessel name column represents?\"\\n# Insert formatted intents into the prompt template\\ncompleted_prompt = prompt_template.format(intents=formatted_intents, query=query)\\n# Use the completed prompt with the AzureChatOpenAI model\\nresponse = llm_gpt.invoke(completed_prompt)\\n\\nprint(response)', 'intents': {'discover_metrics': 'Identify relevant metrics based on user objectives. (e.g., Suggest metrics to measure customer satisfaction)', 'fetch_data': 'Retrieve data for a specific metric the user has already identified.', 'interpret_metrics': \"Explain the meaning of the data in the context of the user's objective.\", 'understand_metrics': \"Provide information about a metric's definition and purpose.\"}, '_i20': 'query = \"What is the most popular feature used by our paid subscribers\"\\n# formatted_query = input(\\n#     dedent(\"\"\"\\n#       {What is the most popular feature used by our paid subscribers}\\n#     \"\"\"))\\n# print(formatted_query)\\ncrew = MetricDiscoveryInputCrew()\\nresult = crew.run(query)', 'query': 'What is the most popular feature used by our paid subscribers', 'crew': <__main__.MetricDiscoveryInputCrew object at 0x13aa42150>, '_i21': 'from crewai.process import Process\\nfrom typing import Any\\nclass MetricDiscoveryInputCrew(Expert):\\n  name = \"MetricDiscovery\"\\n  description = (\\n       \"Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\\n    )\\n  public_description = \"Metric discovery crew\"\\n  arg_description = \"Query related to metrics.\"\\n\\n  def crew_process(self, query: str):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    # print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n    return crew\\n  \\n\\n  def run(self, query: str):\\n    crew = self.crew_process.kickoff(query)\\n    result = crew.kickoff()\\n    return result\\n  \\n  def call(\\n        self, goal: str, task: str, input_str: str, *args: Any, **kwargs: Any\\n    ) -> str:\\n    pass', '_i22': 'query = \"What is the most popular feature used by our paid subscribers\"\\n# formatted_query = input(\\n#     dedent(\"\"\"\\n#       {What is the most popular feature used by our paid subscribers}\\n#     \"\"\"))\\n# print(formatted_query)\\ncrew = MetricDiscoveryInputCrew()\\nresult = crew.run(query)', '_i23': 'from crewai.process import Process\\nfrom typing import Any\\nclass MetricDiscoveryInputCrew(Expert):\\n  name = \"MetricDiscovery\"\\n  description = (\\n       \"Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\\n    )\\n  public_description = \"Metric discovery crew\"\\n  arg_description = \"Query related to metrics.\"\\n\\n  def crew_process(self, query: str):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    # print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n    return crew\\n  \\n\\n  def run(self, query: str):\\n    crew = self.crew_process(query)\\n    result = crew.kickoff()\\n    return result\\n  \\n  def call(\\n        self, goal: str, task: str, input_str: str, *args: Any, **kwargs: Any\\n    ) -> str:\\n    pass', '_i24': 'query = \"What is the most popular feature used by our paid subscribers\"\\n# formatted_query = input(\\n#     dedent(\"\"\"\\n#       {What is the most popular feature used by our paid subscribers}\\n#     \"\"\"))\\n# print(formatted_query)\\ncrew = MetricDiscoveryInputCrew()\\nresult = crew.run(query)'}\n",
      "Built-in variables: ['ArithmeticError', 'AssertionError', 'AttributeError', 'BaseException', 'BaseExceptionGroup', 'BlockingIOError', 'BrokenPipeError', 'BufferError', 'BytesWarning', 'ChildProcessError', 'ConnectionAbortedError', 'ConnectionError', 'ConnectionRefusedError', 'ConnectionResetError', 'DeprecationWarning', 'EOFError', 'Ellipsis', 'EncodingWarning', 'EnvironmentError', 'Exception', 'ExceptionGroup', 'False', 'FileExistsError', 'FileNotFoundError', 'FloatingPointError', 'FutureWarning', 'GeneratorExit', 'IOError', 'ImportError', 'ImportWarning', 'IndentationError', 'IndexError', 'InterruptedError', 'IsADirectoryError', 'KeyError', 'KeyboardInterrupt', 'LookupError', 'MemoryError', 'ModuleNotFoundError', 'NameError', 'None', 'NotADirectoryError', 'NotImplemented', 'NotImplementedError', 'OSError', 'OverflowError', 'PendingDeprecationWarning', 'PermissionError', 'ProcessLookupError', 'RecursionError', 'ReferenceError', 'ResourceWarning', 'RuntimeError', 'RuntimeWarning', 'StopAsyncIteration', 'StopIteration', 'SyntaxError', 'SyntaxWarning', 'SystemError', 'SystemExit', 'TabError', 'TimeoutError', 'True', 'TypeError', 'UnboundLocalError', 'UnicodeDecodeError', 'UnicodeEncodeError', 'UnicodeError', 'UnicodeTranslateError', 'UnicodeWarning', 'UserWarning', 'ValueError', 'Warning', 'ZeroDivisionError', '__IPYTHON__', '__build_class__', '__debug__', '__doc__', '__import__', '__loader__', '__name__', '__package__', '__pybind11_internals_v4_clang_libcpp_cxxabi1002__', '__spec__', 'abs', 'aiter', 'all', 'anext', 'any', 'ascii', 'bin', 'bool', 'breakpoint', 'bytearray', 'bytes', 'callable', 'chr', 'classmethod', 'compile', 'complex', 'copyright', 'credits', 'delattr', 'dict', 'dir', 'display', 'divmod', 'enumerate', 'eval', 'exec', 'execfile', 'filter', 'float', 'format', 'frozenset', 'get_ipython', 'getattr', 'globals', 'hasattr', 'hash', 'help', 'hex', 'id', 'input', 'int', 'isinstance', 'issubclass', 'iter', 'len', 'license', 'list', 'locals', 'map', 'max', 'memoryview', 'min', 'next', 'object', 'oct', 'open', 'ord', 'pow', 'print', 'property', 'range', 'repr', 'reversed', 'round', 'runfile', 'set', 'setattr', 'slice', 'sorted', 'staticmethod', 'str', 'sum', 'super', 'tuple', 'type', 'vars', 'zip']\n",
      "Agent completed task with result: output\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: The user is interested in understanding which feature is most frequently used by paid subscribers. To capture this intent accurately, I need to rephrase the query to focus on the metric of feature popularity among paid subscribers.\n",
      "\n",
      "Action: rephrase_input_query\n",
      "\n",
      "Action Input: {\"query\": \"What is the most popular feature used by our paid subscribers\"}\n",
      "\u001b[0m\u001b[95m \n",
      "\n",
      "Please provide the feature among our paid subscribers that has the highest usage statistics.\n",
      "\u001b[00m\n",
      "\u001b[32;1m\u001b[1;3mThought: I now know the final answer\n",
      "\n",
      "Final Answer: Please provide the feature among our paid subscribers that has the highest usage statistics.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: To provide the user with the feature among our paid subscribers that has the highest usage statistics, I need to discover the relevant metric that would indicate feature usage among paid subscribers. I will use the metric_discovery tool to find this information.\n",
      "\n",
      "Action: metric_discovery\n",
      "\n",
      "Action Input: {\"query\": \"highest usage statistics among paid subscribers\"}\n",
      "\u001b[0m\u001b[95m \n",
      "\n",
      "Sorry, the query is out of scope.\n",
      "\u001b[00m\n",
      "\u001b[32;1m\u001b[1;3mThought: Since the metric_discovery tool returned a response indicating that the query is out of scope, it means that there is no relevant metric available in the metadata that I can access. Therefore, I must respond to the user accordingly.\n",
      "\n",
      "Final Answer: Sorry, the query is out of scope.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the most popular feature used by our paid subscribers\"\n",
    "# formatted_query = input(\n",
    "#     dedent(\"\"\"\n",
    "#       {What is the most popular feature used by our paid subscribers}\n",
    "#     \"\"\"))\n",
    "# print(formatted_query)\n",
    "crew = MetricDiscoveryInputCrew()\n",
    "result = crew.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "Sorry, the query is out of scope.\n"
     ]
    }
   ],
   "source": [
    "print(type(result))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "experts_info = {\"MetricDiscovery\" : MetricDiscoveryInputCrew()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "# Define the prompt template\n",
    "prompt_create_objectives = PromptTemplate(\n",
    "    input_variables=[\"goal\", \"chat_history\"],\n",
    "    template=\"\"\"\n",
    "You are an intelligent assistant that helps users break down their goals into high-level, smaller objectives. The system you are part of serves as an interface between users and a database containing various metrics. You have access to metadata of these metrics, including table columns information.\n",
    "Goal: {goal}\n",
    "{chat_history}\n",
    "Using the provided goal and any relevant chat history, break down the goal into high-level, smaller objectives whose intents are different. Make sure each objective is clear and distinct.\n",
    ") \"\"\")\n",
    "\n",
    "goal =\"Can you show me the average user signup rate for the past month, segmented by device type?\"\n",
    "chat_history = \"\"\n",
    "\n",
    "prompt = prompt_create_objectives.format_prompt(\n",
    "                goal=goal,\n",
    "                chat_history=chat_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"text='\\\\nYou are an intelligent assistant that helps users break down their goals into high-level, smaller objectives. The system you are part of serves as an interface between users and a database containing various metrics. You have access to metadata of these metrics, including table columns information.\\\\nGoal: Can you show me the average user signup rate for the past month, segmented by device type?\\\\n\\\\nUsing the provided goal and any relevant chat history, break down the goal into high-level, smaller objectives whose intents are different. Make sure each objective is clear and distinct.\\\\n) '\""
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = llm_service.invoke(str(prompt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"To achieve the goal of showing the average user signup rate for the past month, segmented by device type, we can break down the task into the following high-level, smaller objectives:\\n\\n1. **Data Retrieval Objective**: Access the database to retrieve user signup data for the past month. This involves:\\n   - Identifying the correct database and table(s) that contain user signup information.\\n   - Determining the relevant columns that store signup dates and device types.\\n   - Constructing and executing a query to fetch the data within the date range of the past month.\\n\\n2. **Data Segmentation Objective**: Segment the retrieved data by device type. This requires:\\n   - Grouping the signup data based on the device type column.\\n   - Ensuring that each group represents a unique device type.\\n\\n3. **Calculation Objective**: Calculate the average signup rate for each device type. This involves:\\n   - Counting the number of signups for each device type.\\n   - Calculating the total number of days in the past month to determine the period over which the average will be calculated.\\n   - Dividing the total signups by the number of days to find the average daily signup rate per device type.\\n\\n4. **Data Presentation Objective**: Present the calculated average signup rates in a clear and understandable format. This includes:\\n   - Formatting the results in a table or chart that clearly shows the average signup rates segmented by device type.\\n   - Ensuring the time frame (past month) is clearly indicated in the presentation.\\n   - Providing any additional context or explanations that may help the user understand the data.\\n\\n5. **User Interface Interaction Objective**: Interact with the user to deliver the results and offer further assistance. This involves:\\n   - Displaying the results to the user through the system's interface.\\n   - Asking the user if they need any further breakdowns, comparisons, or additional data.\\n   - Being prepared to refine the query or presentation based on user feedback.\\n\\nEach of these objectives is distinct and requires different actions and intents to be fulfilled. Together, they contribute to achieving the overall goal of providing the average user signup rate for the past month, segmented by device type.\""
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective breakdown into smaller task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='- Discover Metrics: Identify the top three metrics that indicate the overall health of our business.' response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 283, 'total_tokens': 301}, 'model_name': 'gpt-4', 'system_fingerprint': 'fp_811936bd4f', 'finish_reason': 'stop', 'logprobs': None} id='run-c616fcc8-b9c9-48e5-870c-4a36a9eabe8f-0'\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "# Define the prompt template\n",
    "prompt_template = PromptTemplate.from_template(\"\"\"\n",
    "You are an intelligent assistant whose only and only goal is to break down user's query {query} into high-level, smaller objectives in form of list. You serve as an interface between users and a database containing various metrics/KPIs/measures.\n",
    "Strictly note that it is not necessary to break down the query in all the following intents. The intents are only for reference. If the query is straightforward and aligns with any one of the intent, then do not change the query. \n",
    "Try to minimize the number of objectives and keep them as high-level as possible. \n",
    "Each smaller objective should strictly fall into one of the following intent:\n",
    "Discover Metrics:** If you'd like to measure something specific, I can identify relevant metrics. For example, are you interested in suggest some metrics based on objective?\n",
    "Fetch Data:** If you already know the metric you're interested in, I can retrieve the data from the database.\n",
    "Interpret Metrics:** Once you have the data, I can explain what it means in the context of your objective. \n",
    "Understand Metrics:** If you're unsure about a metric's definition or purpose, I can provide more information.\n",
    "\n",
    "Don't add noise to the response.\n",
    "Respond with a list.\n",
    "However, if the query involves something else entirely, like action outside current intents, give empty list.\"\"\")\n",
    "def complete(prompt, user_query):\n",
    "  \"\"\"\n",
    "  Completes the prompt with the user objective.\n",
    "\n",
    "  Args:\n",
    "      prompt: The prompt template.\n",
    "      user_objective: The user's objective.\n",
    "\n",
    "  Returns:\n",
    "      The completed prompt.\n",
    "  \"\"\"\n",
    "  return prompt.format(query=user_query)\n",
    "\n",
    "# Example usage\n",
    "user_objective = \"What are the top three metrics that indicate the overall health of our business?\"\n",
    "completed_prompt = complete(prompt_template, user_objective)\n",
    "\n",
    "# Use the completed prompt with the AzureChatOpenAI model\n",
    "response = llm_service.invoke(completed_prompt)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt_template = \"\"\"You are an intelligent assistant focused on helping users with metrics and data. Your primary goal is to break down user queries ({query}) into a concise list of high-level objectives. Intents: * Discover Metrics: Identify relevant metrics based on user objectives. (e.g., Suggest metrics to measure customer satisfaction) * Fetch Data: Retrieve data for a specific metric the user has already identified. * Analyze Trends: Analyze trends within the fetched data to provide deeper insights. * Interpret Metrics: Explain the meaning of the data in the context of the user's objective. * Understand Metrics: Provide information about a metric's definition and purpose. Important Notes: * Prioritize Clarity & Efficiency: Minimize the number of objectives and maintain a high-level overview. * Direct Match: If the query aligns perfectly with one intent (e.g., \"What's the current customer churn rate?\" for Fetch Data), don't alter it. * Outside Scope: If the query falls outside these intents (e.g., \"Book a flight\"), return an empty list. * Focus on User Need: Keep responses clear and concise, avoiding unnecessary information. * Output Format: Respond with a list containing the breakdown of objectives. **Here's the user query: {query} What is the high-level breakdown of objectives for this query? \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='- understand_metrics: Clarify what the \"vessel name\" column signifies in the dataset.' response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 288, 'total_tokens': 307}, 'model_name': 'gpt-4', 'system_fingerprint': 'fp_811936bd4f', 'finish_reason': 'stop', 'logprobs': None} id='run-27e344c2-3c5b-4c84-8783-646da5ade68c-0'\n"
     ]
    }
   ],
   "source": [
    "intents = {\n",
    "    \"discover_metrics\": \"Identify relevant metrics based on user objectives. (e.g., Suggest metrics to measure customer satisfaction)\",\n",
    "    \"fetch_data\": \"Retrieve data for a specific metric the user has already identified.\",\n",
    "    # \"analyze_trends\": \"Analyze trends within the fetched data to provide deeper insights.\",\n",
    "    \"interpret_metrics\": \"Explain the meaning of the data in the context of the user's objective.\",\n",
    "    \"understand_metrics\": \"Provide information about a metric's definition and purpose.\"\n",
    "}\n",
    "prompt_template = PromptTemplate.from_template(\"\"\"You are an intelligent assistant focused on helping users with metrics and data. Your primary goal is to break down user queries ({query}) into a concise list of high-level objectives.\n",
    "\n",
    "**Intents:**\n",
    "\n",
    "{intents}\n",
    "\n",
    "Important Notes:\n",
    "* Alignment with Intents: The new objectives should strictly align with the provided intents.\n",
    "* Prioritize Clarity & Efficiency:  Minimize the number of objectives and maintain a high-level overview. \n",
    "* Direct Match: If the query aligns perfectly with one intent (e.g., \"What's the current customer churn rate?\" for Fetch Data), don't alter it.\n",
    "* Outside Scope: If the query falls outside these intents (e.g., \"Book a flight\"), return an empty list.\n",
    "* Focus on User Need: Keep responses clear and concise, avoiding unnecessary information. \n",
    "* Output Format:  Respond with a list containing the breakdown of objectives.\n",
    "\n",
    "**Here's the user query: {query}\n",
    "\n",
    "What is the high-level breakdown of objectives for this query?\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "# Format the intent descriptions for the prompt\n",
    "formatted_intents = \"\\n\".join([f\"* {intent_name}: {description}\" for intent_name, description in intents.items()])\n",
    "query = \"What dose the vessel name column represents?\"\n",
    "# Insert formatted intents into the prompt template\n",
    "completed_prompt = prompt_template.format(intents=formatted_intents, query=query)\n",
    "# Use the completed prompt with the AzureChatOpenAI model\n",
    "response = llm_service.invoke(completed_prompt)\n",
    "\n",
    "print(response)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import re\n",
    "from typing import List, TypeVar\n",
    "from langchain.schema import BaseOutputParser, OutputParserException\n",
    "T = TypeVar(\"T\")\n",
    "\n",
    "class TaskOutputParser(BaseOutputParser[List[str]]):\n",
    "    \"\"\"\n",
    "    Extension of LangChain's BaseOutputParser\n",
    "    Responsible for parsing task creation output into a list of task strings\n",
    "    \"\"\"\n",
    "\n",
    "    completed_tasks: List[str] = []\n",
    "\n",
    "    def __init__(self, *, completed_tasks: List[str]):\n",
    "        super().__init__()\n",
    "        self.completed_tasks = completed_tasks\n",
    "\n",
    "    def parse(self, text: str) -> List[str]:\n",
    "        try:\n",
    "            array_str = extract_array(text)\n",
    "            all_tasks = [\n",
    "                remove_prefix(task) for task in array_str if real_tasks_filter(task)\n",
    "            ]\n",
    "            return [task for task in all_tasks if task not in self.completed_tasks]\n",
    "        except Exception as e:\n",
    "            msg = f\"Failed to parse tasks from completion '{text}'. Exception: {e}\"\n",
    "            raise OutputParserException(msg)\n",
    "\n",
    "    def get_format_instructions(self) -> str:\n",
    "        return \"\"\"\n",
    "        The response should be a JSON array of strings. Example:\n",
    "\n",
    "        [\"Search the web for NBA news\", \"Write some code to build a web scraper\"]\n",
    "\n",
    "        This should be parsable by json.loads()\n",
    "        \"\"\"\n",
    "\n",
    "def handle_multiline_string(input_str: str) -> List[str]:\n",
    "    # Handle multiline string as a list\n",
    "    processed_lines = [\n",
    "        re.sub(r\".*?(\\d+\\..+)\", r\"\\1\", line).strip()\n",
    "        for line in input_str.split(\"\\n\")\n",
    "        if line.strip() != \"\"\n",
    "    ]\n",
    "\n",
    "    # Check if there is at least one line that starts with a digit and a period\n",
    "    if any(re.match(r\"\\d+\\..+\", line) for line in processed_lines):\n",
    "        return processed_lines\n",
    "    else:\n",
    "        # raise RuntimeError(f\"Failed to extract array from {input_str}\")\n",
    "        print(f\"Failed to extract array from {input_str}\")\n",
    "        return [input_str]\n",
    "\n",
    "def extract_array(input_str: str) -> List[str]:\n",
    "    regex = (\n",
    "        r\"\\[\\s*\\]|\"  # Empty array check\n",
    "        r\"(\\[(?:\\s*(?:\\\"(?:[^\\\"\\\\]|\\\\.)*\\\"|\\'(?:[^\\'\\\\]|\\\\.)*\\')\\s*,?)*\\s*\\])\"\n",
    "    )\n",
    "    match = re.search(regex, input_str)\n",
    "    if match is not None:\n",
    "        return ast.literal_eval(match[0])\n",
    "    else:\n",
    "        return handle_multiline_string(input_str)\n",
    "    \n",
    "def remove_prefix(input_str: str) -> str:\n",
    "    prefix_pattern = (\n",
    "        r\"^(Task\\s*\\d*\\.\\s*|Task\\s*\\d*[-:]?\\s*|Step\\s*\\d*[\"\n",
    "        r\"-:]?\\s*|Step\\s*[-:]?\\s*|\\d+\\.\\s*|\\d+\\s*[-:]?\\s*|^\\.\\s*|^\\.*)\"\n",
    "    )\n",
    "    return re.sub(prefix_pattern, \"\", input_str, flags=re.IGNORECASE)\n",
    "\n",
    "\n",
    "def real_tasks_filter(input_str: str) -> bool:\n",
    "    no_task_regex = (\n",
    "        r\"^No( (new|further|additional|extra|other))? tasks? (is )?(\"\n",
    "        r\"required|needed|added|created|inputted).*\"\n",
    "    )\n",
    "    task_complete_regex = r\"^Task (complete|completed|finished|done|over|success).*\"\n",
    "    do_nothing_regex = r\"^(\\s*|Do nothing(\\s.*)?)$\"\n",
    "\n",
    "    return (\n",
    "        not re.search(no_task_regex, input_str, re.IGNORECASE)\n",
    "        and not re.search(task_complete_regex, input_str, re.IGNORECASE)\n",
    "        and not re.search(do_nothing_regex, input_str, re.IGNORECASE)\n",
    "    )\n",
    "\n",
    "def parse_with_handling(parser: BaseOutputParser[T], completion: str) -> T:\n",
    "    try:\n",
    "        return parser.parse(completion)\n",
    "    except OutputParserException as e:\n",
    "        raise e\n",
    "    \n",
    "\n",
    "task_output_parser = TaskOutputParser(completed_tasks=[])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to extract array from - understand_metrics: Clarify what the \"vessel name\" column signifies in the dataset.\n",
      "['- understand_metrics: Clarify what the \"vessel name\" column signifies in the dataset.']\n"
     ]
    }
   ],
   "source": [
    "objectives = parse_with_handling(task_output_parser, response.content)\n",
    "print(objectives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Available experts\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "from typing import Type, TypedDict\n",
    "\n",
    "class ExpertDescription(TypedDict):\n",
    "    \"\"\"Representation of a callable expert\"\"\"\n",
    "    name: str\n",
    "    \"\"\"The name of the expert.\"\"\"\n",
    "    description: str\n",
    "    \"\"\"A description of the expert.\"\"\"\n",
    "    parameters: dict[str, object]\n",
    "    \"\"\"The parameters of the expert.\"\"\"\n",
    "\n",
    "def get_expert_function(expert: Type[Expert]) -> ExpertDescription:\n",
    "    \"\"\"A function that will return the tool's function specification\"\"\"\n",
    "    name = get_expert_name(expert)\n",
    "    return {\n",
    "        \"name\": name,\n",
    "        \"description\": expert.description,\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"reasoning\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": (\n",
    "                        f\"Reasoning is how the task will be accomplished with the current expert. \"\n",
    "                        \"Detail your overall plan along with any concerns you have.\"\n",
    "                        \"Ensure this reasoning value is in the user defined langauge \"\n",
    "                    ),\n",
    "                },\n",
    "                \"arg\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": expert.arg_description,\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"reasoning\", \"arg\"],\n",
    "        },\n",
    "    }\n",
    "\n",
    "def get_expert_name(expert: Type[Expert]) -> str:\n",
    "    return expert.name\n",
    "\n",
    "# def format_expert_name(expert_name: str) -> str:\n",
    "#     return expert_name.lower()\n",
    "\n",
    "def get_available_experts() -> List[Type[Expert]]:\n",
    "    return [\n",
    "        MetricDiscoveryInputCrew\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_experts = get_available_experts()\n",
    "experts = list(map(get_expert_function, available_experts))\n",
    "expert_descriptions = {expert['name'] : expert['description'] for expert in experts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MetricDiscovery': 'Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'MetricDiscovery',\n",
       "  'description': 'Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'reasoning': {'type': 'string',\n",
       "     'description': 'Reasoning is how the task will be accomplished with the current expert. Detail your overall plan along with any concerns you have.Ensure this reasoning value is in the user defined langauge '},\n",
       "    'arg': {'type': 'string', 'description': 'Query related to metrics.'}},\n",
       "   'required': ['reasoning', 'arg']}}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_task_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    High level objective: \"{goal}\"\n",
    "    Current task: \"{task}\"\n",
    "\n",
    "    Based on this information, use the best expert to make progress or accomplish the task entirely. Each expert has a name and description of their expertise. \n",
    "    Select the correct expert by being smart and efficient. Ensure \"reasoning\" and only \"reasoning\" is in the english language.\n",
    "    Following are the list of experts {experts}\n",
    "\n",
    "    Note you MUST select a expert and return the name and reasoning of the expert in form of dictionary.\n",
    "    \"\"\",\n",
    "    input_variables=[\"goal\", \"task\", \"experts\"],\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 14:11:50,170 - 140704419426240 - __init__.py-__init__:518 - WARNING: Overriding of current TracerProvider is not allowed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local variables: {}\n",
      "Global variables: {'__name__': '__main__', '__doc__': 'Automatically created module for IPython interactive environment', '__package__': None, '__loader__': None, '__spec__': None, '__builtin__': <module 'builtins' (built-in)>, '__builtins__': <module 'builtins' (built-in)>, '_ih': ['', 'a ={\"a\" : MetricDiscoveryInputCrew()}', 'from crewai.process import Process\\nfrom typing import Any\\nclass MetricDiscoveryInputCrew(Expert):\\n  name = \"MetricDiscovery\"\\n  description = (\\n       \"Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\\n    )\\n  public_description = \"Metric discovery crew\"\\n  arg_description = \"Query related to metrics.\"\\n\\n  def __init__(self, query):\\n    self.query = query\\n    self.crew_process = self.crew_process()\\n    # self.llm = llm_gpt\\n  def crew_process(self):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    # print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, self.query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n    return crew\\n\\n  def run(self):\\n    result = self.crew_process.kickoff()\\n    return result\\n  \\n  def call(\\n        self, goal: str, task: str, input_str: str, *args: Any, **kwargs: Any\\n    ) -> str:\\n    pass', '#initialize\\n#     model\\n#     environment variables\\n\\nimport sys\\nsys.path.append(\\'..\\')\\nfrom src.utils.llamaindex_retriever import LlamaIndexRetriever\\nfrom langchain.vectorstores import FAISS\\nfrom langchain.embeddings.azure_openai import AzureOpenAIEmbeddings\\nfrom langchain.embeddings.openai import OpenAIEmbeddings\\nfrom dotenv import load_dotenv\\nimport os\\nfrom langchain.chat_models import AzureChatOpenAI\\n\\ndef load_env_variables(file_path):\\n    load_dotenv(file_path)\\n    print(\"Environment variables loaded successfully!\")\\n\\nenv_file_path = \"../.env\"\\nload_env_variables = load_env_variables(env_file_path)\\nmax_tokens = 3500\\ntemperature = 0.1\\n\\n# embeddings = AzureOpenAIEmbeddings(azure_deployment=azure_deployment, openai_api_version=openai_api_version)\\nembeddings =  AzureOpenAIEmbeddings(\\n        deployment=os.getenv(\"EMB_DEPLOYMENT\"),\\n        openai_api_version=os.getenv(\"EMB_OPENAI_API_VERSION\"),\\n        model=os.getenv(\"EMB_MODEL\"),\\n        openai_api_key=os.getenv(\"EMB_OPENAI_API_KEY\"),\\n        openai_api_base=os.getenv(\"EMB_OPENAI_ENDPOINT\"),\\n        openai_api_type=os.getenv(\"EMB_API_TYPE\"),\\n    )\\n\\nllm_gpt = AzureChatOpenAI(deployment_name=os.getenv(\\'AZURE_OPENAI_DEPLOYMENT_NAME\\'), openai_api_version=os.getenv(\"OPENAI_API_VERSION\"),\\n                        openai_api_base=os.getenv(\"OPENAI_API_BASE\"), \\n                        openai_api_type= os.getenv(\"OPENAI_API_TYPE\"),\\n                        openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\\n                        max_tokens=max_tokens,\\n                        temperature=temperature)', '#define utils\\nfrom src.utils.cube_semantic_custom import CubeSemanticLoader\\ndef fetch_cube_metadata(*args, **kwargs):\\n    try:\\n        # # Load document from Cube meta api\\n        loader = CubeSemanticLoader(os.getenv(\"CUBE_API_URL\"), os.getenv(\"CUBE_TOKEN\"), False)\\n        documents = loader.load()\\n        # to_json()\\n        return documents\\n    except Exception as e:\\n        # Handle exceptions gracefully and return an error response\\n        print(\"Error in fetching metadata from cube: \" + str(e))\\n        return 0\\n\\ndef create_vector_store(documents, local_vector_store_path, *args, **kwargs):\\n    print(\"Loaded documents: \" + str(documents))\\n    vectorstore = FAISS.from_documents(documents, embeddings)\\n    vectorstore.save_local(local_vector_store_path)\\n    print(\"Vector store created and saved successfully!\")\\n\\ndef load_vector_store(vector_store_path, embeddings, *args, **kwargs):\\n    # Load the vector store from the local file system\\n    vectorstore = FAISS.load_local(vector_store_path, embeddings, allow_dangerous_deserialization=True)\\n    print(\"Vector store loaded successfully!\")\\n    \\n    return vectorstore', '#load existing vector store\\nvector_store_path = \"/Users/k.abhishek/Documents/experiments/metric_store/metric_store_gen_ai/data/vector_store/cube_meta_faiss_index\"\\nvectorstore = load_vector_store(vector_store_path, embeddings)', 'import json\\nfrom crewai import Agent, Task, Crew\\nfrom langchain.tools import tool\\nfrom src.utils.llamaindex_retriever import LlamaIndexRetriever\\nfrom typing import Optional, Type\\nfrom langchain.callbacks.manager import (\\n    AsyncCallbackManagerForToolRun,\\n    CallbackManagerForToolRun,\\n)\\n# Import things that are needed generically\\nfrom langchain.pydantic_v1 import BaseModel, Field\\n# from langchain.tools import BaseTool, StructuredTool, tool\\nfrom crewai_tools import BaseTool\\n\\n\\ndef get_similar_documents_faiss(query, max_number_documents=3):\\n  vectorstore = FAISS.load_local(vector_store_path, embeddings, allow_dangerous_deserialization=True)\\n  docs = vectorstore.similarity_search_with_relevance_scores(query, max_number_documents)\\n  relevant_documents = []\\n  for doc in docs:\\n      doc = doc[0]\\n      meta = {\\'text\\':doc.page_content, \\'table_metadata\\': doc.metadata}\\n      relevant_documents.append(meta)\\n  return relevant_documents\\n\\ndef get_similar_documents(query, max_number_documents=3):\\n    return get_similar_documents_faiss(query, max_number_documents)\\n\\n\\nclass QueryInput(BaseModel):\\n    query: str = Field(description=\"should be enquiry query\")\\n\\nclass TerminationHandler(CallbackManagerForToolRun):\\n    pass\\n\\nclass RephraseInputQuery(BaseTool):\\n    name:str = \"rephrase_input_query\"\\n    description :str = \"Useful to rephrase the query to capture the intent of the user regarding metric information\"\\n    args_schema: Type[BaseModel] = QueryInput\\n\\n    def _run(\\n        self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None\\n    ) -> str:\\n        \"\"\"Use the tool.\"\"\"\\n        metric_description = self.rephrase_input_query(query)\\n        return metric_description\\n\\n    async def _arun(\\n        self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None\\n    ) -> str:\\n        \"\"\"Use the tool asynchronously.\"\"\"\\n        raise NotImplementedError(\"custom_search does not support async\")\\n    \\n    \\n    def rephrase_input_query(self, query, *args, **kwargs):\\n        agent = Agent(\\n                role=\\'Intent Capturer\\',\\n                goal=\\n                \\'Rephrasing the query to capture the intent of the user regarding metric information\\',\\n                backstory=\\n                \"You are an expert to understand the user\\'s intent and rephrase the query to capture the intent of the user accurately.\",\\n                llm = llm_gpt,\\n                allow_delegation=False)\\n        task = Task(\\n                agent=agent,\\n                description=\\n                f\\'Rephrase the query to capture the intent of the user regarding metric information. The query is {query}. Donot add any noise to the response\\',\\n                expected_output=\"some string\",\\n        \\n            )\\n        extracted_metrics = task.execute()\\n\\n        return extracted_metrics\\n    \\n\\n    \\nclass MetricDiscovery(BaseTool):\\n    name :str = \"metric_discovery\"\\n    description:str = \"\"\"Useful for general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\"\"\\n    args_schema: Type[BaseModel] = QueryInput\\n\\n    def _run(\\n        self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None\\n    ) -> str:\\n        \"\"\"Use the tool.\"\"\"\\n        metric_description = self.metric_discovery(query)\\n        return metric_description\\n\\n    async def _arun(\\n        self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None\\n    ) -> str:\\n        \"\"\"Use the tool asynchronously.\"\"\"\\n        raise NotImplementedError(\"custom_search does not support async\")\\n    \\n    \\n    def metric_discovery(self, query, *args, **kwargs):\\n        \"\"\"Useful for general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\"\"\\n        relevant_documents = get_similar_documents(query)\\n        agent = Agent(\\n                role=\\'Data Analyst Assistant\\',\\n                goal=\\n                \\'Empower users to understand and utilize data effectively. This includes helping them discover relevant metrics, interpreting their meaning\\',\\n                backstory=\\n                \"The primary purpose is to bridge the gap between raw data and user comprehension, fostering a data-driven culture within the organization.\",\\n                llm = llm_gpt,\\n                allow_delegation=False)  \\n        \\n        task = Task(\\n                agent=agent,\\n                description=\\n                \"\"\" You are responding to  question {metric_description} with answer from the Metadata provided to you as {relevant_documents}}.\\n                    Strictly answer the question with the information present in metadata only.\\n                    Respond with \"Sorry, the query is out of scope.\" if the answer is not present in metadata and terminate further reasoning and prcoess.\\n                    \"\"\",\\n                expected_output=\"some string\",\\n        \\n            )\\n        output = task.execute()\\n\\n        return output', '# def check_termination(task_output):\\n#     agent = Agent(\\n#                 role=\\'Determine query completion\\',\\n#                 goal=\\n#                 \\'Given task output, determine termination of crew workflow\\',\\n#                 backstory=\\n#                 \"Given user query request from user determine if no more new task is needed to be executed\",\\n#                 llm = llm_gpt,\\n#                 allow_delegation=False)\\n#     task = Task(\\n#                 agent=agent,\\n#                 description=\\n#                 f\\'Given task output, if the query is completed and the task result determines that the query is out of scope then terminate the workflow or else the required query is satisfied. Following is the task result {task_output}\\',\\n#                 expected_output=\"some string\",\\n        \\n#             )\\n#     termination_status = task.execute()\\n#     return termination_status\\nclass MetricDiscoveryTasks():\\n  def metric_isolation(self, agent, query):\\n    return Task(description=(f\"\"\"\\n        Rephrase the query to capture the intent of the user regarding metric information. The query is {query}. Donot add any noise to the response.\\n        {self.__tip_section()}\"\"\"),\\n      agent=agent,\\n      expected_output=\"Reformatted query to capture the intent of the user regarding metric information.\",\\n      # callback=callback_function,\\n    )\\n  \\n  def metric_discovery(self, agent):\\n    return Task(description=(f\"\"\"\\n        Answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\\n        {self.__tip_section()}\"\"\"),\\n      agent=agent,\\n      expected_output=\"If relevant metric exists in metadata, provide the answer. Else, respond with \\'Sorry, the query is out of scope.\\' and terminate process.\",\\n      # callback=callback_function,\\n    )\\n  def __tip_section(self):\\n    return \"If you do your BEST WORK, I\\'ll give you a $10,000 commission!\"\\n  \\n  ', 'class MetricDiscoveryAgent():\\n  def user_intent_capture(self):\\n    return Agent(\\n      role=\\'Intent Capturer\\',\\n      goal=\\n      \\'Rephrasing the query to capture the intent of the user regarding metric information\\',\\n      backstory=\\n      \"You are an expert to understand the user\\'s intent and rephrase the query to capture the intent of the user accurately.\",\\n      verbose=True,\\n      tools=[\\n        RephraseInputQuery()\\n      ],\\n      llm = llm_gpt,\\n    )\\n  def discover_metric_info(self):\\n    return Agent(\\n     role=\\'Data Analyst Assistant\\',\\n      goal=\\n      \\'Empower users to understand and utilize data effectively. This includes helping them discover relevant metrics, interpreting their meaning\\',\\n      backstory=\\n      \"The primary purpose is to bridge the gap between raw data and user comprehension, fostering a data-driven culture within the organization.\",\\n      llm = llm_gpt,\\n      verbose=True,\\n      tools=[\\n        MetricDiscovery()\\n      ],\\n    )', 'def after_task_callback(output):\\n  # Perform actions after the task, \\n  # for example, logging or updating agent state\\n  \\n  print(f\"Agent completed task with result: {output}\")\\n\\n# Assigning the function to task_callback\\ntask_callback = after_task_callback', 'def test_callback():\\n        # Accessing local variables\\n        print(\"Local variables:\", locals())\\n        \\n        # Accessing global variables\\n        print(\"Global variables:\", globals())    \\n        \\n        # Accessing built-in variables\\n        print(\"Built-in variables:\", dir(__builtins__))\\n        after_task_callback(\"output\")\\n  ', 'from abc import ABC, abstractmethod\\nclass Expert(ABC):\\n    name: str = \"\"\\n    description: str = \"\"\\n    public_description: str = \"\"\\n    arg_description: str = \"The argument to the function.\"\\n\\n    @abstractmethod\\n    def call(\\n        self,\\n        goal: str,\\n        task: str,\\n        input_str: str,\\n    ) -> str:\\n        pass', 'from crewai.process import Process\\nfrom typing import Any\\nclass MetricDiscoveryInputCrew(Expert):\\n  name = \"MetricDiscovery\"\\n  description = (\\n       \"Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\\n    )\\n  public_description = \"Metric discovery crew\"\\n  arg_description = \"Query related to metrics.\"\\n\\n  def __init__(self, query):\\n    self.query = query\\n    self.crew_process = self.crew_process()\\n    # self.llm = llm_gpt\\n  def crew_process(self):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    # print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, self.query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n    return crew\\n\\n  def run(self):\\n    result = self.crew_process.kickoff()\\n    return result\\n  \\n  def call(\\n        self, goal: str, task: str, input_str: str, *args: Any, **kwargs: Any\\n    ) -> str:\\n    pass', 'a ={\"a\" : MetricDiscoveryInputCrew()}', 'from crewai.process import Process\\nfrom typing import Any\\nclass MetricDiscoveryInputCrew(Expert):\\n  name = \"MetricDiscovery\"\\n  description = (\\n       \"Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\\n    )\\n  public_description = \"Metric discovery crew\"\\n  arg_description = \"Query related to metrics.\"\\n\\n  def __init__(self):\\n    # self.query = query\\n    self.crew_process = self.crew_process()\\n    # self.llm = llm_gpt\\n  def crew_process(self, query: str):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    # print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n    return crew\\n\\n  def run(self, query: str):\\n    result = self.crew_process.kickoff()\\n    return result\\n  \\n  def call(\\n        self, goal: str, task: str, input_str: str, *args: Any, **kwargs: Any\\n    ) -> str:\\n    pass', 'a ={\"a\" : MetricDiscoveryInputCrew()}', 'from crewai.process import Process\\nfrom typing import Any\\nclass MetricDiscoveryInputCrew(Expert):\\n  name = \"MetricDiscovery\"\\n  description = (\\n       \"Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\\n    )\\n  public_description = \"Metric discovery crew\"\\n  arg_description = \"Query related to metrics.\"\\n\\n  def crew_process(self, query: str):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    # print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n    return crew\\n  \\n\\n  def run(self, query: str):\\n    result = self.crew_process.kickoff(query)\\n    return result\\n  \\n  def call(\\n        self, goal: str, task: str, input_str: str, *args: Any, **kwargs: Any\\n    ) -> str:\\n    pass', 'a ={\"a\" : MetricDiscoveryInputCrew()}', 'objectives = parse_with_handling(task_output_parser, response.content)\\nprint(objectives)', 'intents = {\\n    \"discover_metrics\": \"Identify relevant metrics based on user objectives. (e.g., Suggest metrics to measure customer satisfaction)\",\\n    \"fetch_data\": \"Retrieve data for a specific metric the user has already identified.\",\\n    # \"analyze_trends\": \"Analyze trends within the fetched data to provide deeper insights.\",\\n    \"interpret_metrics\": \"Explain the meaning of the data in the context of the user\\'s objective.\",\\n    \"understand_metrics\": \"Provide information about a metric\\'s definition and purpose.\"\\n}\\nprompt_template = PromptTemplate.from_template(\"\"\"You are an intelligent assistant focused on helping users with metrics and data. Your primary goal is to break down user queries ({query}) into a concise list of high-level objectives.\\n\\n**Intents:**\\n\\n{intents}\\n\\nImportant Notes:\\n* Alignment with Intents: The new objectives should strictly align with the provided intents.\\n* Prioritize Clarity & Efficiency:  Minimize the number of objectives and maintain a high-level overview. \\n* Direct Match: If the query aligns perfectly with one intent (e.g., \"What\\'s the current customer churn rate?\" for Fetch Data), don\\'t alter it.\\n* Outside Scope: If the query falls outside these intents (e.g., \"Book a flight\"), return an empty list.\\n* Focus on User Need: Keep responses clear and concise, avoiding unnecessary information. \\n* Output Format:  Respond with a list containing the breakdown of objectives.\\n\\n**Here\\'s the user query: {query}\\n\\nWhat is the high-level breakdown of objectives for this query?\\n\"\"\")\\n\\n\\n\\n# Format the intent descriptions for the prompt\\nformatted_intents = \"\\\\n\".join([f\"* {intent_name}: {description}\" for intent_name, description in intents.items()])\\nquery = \"What dose the vessel name column represents?\"\\n# Insert formatted intents into the prompt template\\ncompleted_prompt = prompt_template.format(intents=formatted_intents, query=query)\\n# Use the completed prompt with the AzureChatOpenAI model\\nresponse = llm_gpt.invoke(completed_prompt)\\n\\nprint(response)', 'query = \"What is the most popular feature used by our paid subscribers\"\\n# formatted_query = input(\\n#     dedent(\"\"\"\\n#       {What is the most popular feature used by our paid subscribers}\\n#     \"\"\"))\\n# print(formatted_query)\\ncrew = MetricDiscoveryInputCrew()\\nresult = crew.run(query)', 'from crewai.process import Process\\nfrom typing import Any\\nclass MetricDiscoveryInputCrew(Expert):\\n  name = \"MetricDiscovery\"\\n  description = (\\n       \"Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\\n    )\\n  public_description = \"Metric discovery crew\"\\n  arg_description = \"Query related to metrics.\"\\n\\n  def crew_process(self, query: str):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    # print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n    return crew\\n  \\n\\n  def run(self, query: str):\\n    crew = self.crew_process.kickoff(query)\\n    result = crew.kickoff()\\n    return result\\n  \\n  def call(\\n        self, goal: str, task: str, input_str: str, *args: Any, **kwargs: Any\\n    ) -> str:\\n    pass', 'query = \"What is the most popular feature used by our paid subscribers\"\\n# formatted_query = input(\\n#     dedent(\"\"\"\\n#       {What is the most popular feature used by our paid subscribers}\\n#     \"\"\"))\\n# print(formatted_query)\\ncrew = MetricDiscoveryInputCrew()\\nresult = crew.run(query)', 'from crewai.process import Process\\nfrom typing import Any\\nclass MetricDiscoveryInputCrew(Expert):\\n  name = \"MetricDiscovery\"\\n  description = (\\n       \"Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\\n    )\\n  public_description = \"Metric discovery crew\"\\n  arg_description = \"Query related to metrics.\"\\n\\n  def crew_process(self, query: str):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    # print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n    return crew\\n  \\n\\n  def run(self, query: str):\\n    crew = self.crew_process(query)\\n    result = crew.kickoff()\\n    return result\\n  \\n  def call(\\n        self, goal: str, task: str, input_str: str, *args: Any, **kwargs: Any\\n    ) -> str:\\n    pass', 'query = \"What is the most popular feature used by our paid subscribers\"\\n# formatted_query = input(\\n#     dedent(\"\"\"\\n#       {What is the most popular feature used by our paid subscribers}\\n#     \"\"\"))\\n# print(formatted_query)\\ncrew = MetricDiscoveryInputCrew()\\nresult = crew.run(query)', 'print(result)', 'type(result)\\nprint(result)', 'print(type(result))\\nprint(result)', 'intents = {\\n    \"discover_metrics\": \"Identify relevant metrics based on user objectives. (e.g., Suggest metrics to measure customer satisfaction)\",\\n    \"fetch_data\": \"Retrieve data for a specific metric the user has already identified.\",\\n    # \"analyze_trends\": \"Analyze trends within the fetched data to provide deeper insights.\",\\n    \"interpret_metrics\": \"Explain the meaning of the data in the context of the user\\'s objective.\",\\n    \"understand_metrics\": \"Provide information about a metric\\'s definition and purpose.\"\\n}\\nprompt_template = PromptTemplate.from_template(\"\"\"You are an intelligent assistant focused on helping users with metrics and data. Your primary goal is to break down user queries ({query}) into a concise list of high-level objectives.\\n\\n**Intents:**\\n\\n{intents}\\n\\nImportant Notes:\\n* Alignment with Intents: The new objectives should strictly align with the provided intents.\\n* Prioritize Clarity & Efficiency:  Minimize the number of objectives and maintain a high-level overview. \\n* Direct Match: If the query aligns perfectly with one intent (e.g., \"What\\'s the current customer churn rate?\" for Fetch Data), don\\'t alter it.\\n* Outside Scope: If the query falls outside these intents (e.g., \"Book a flight\"), return an empty list.\\n* Focus on User Need: Keep responses clear and concise, avoiding unnecessary information. \\n* Output Format:  Respond with a list containing the breakdown of objectives.\\n\\n**Here\\'s the user query: {query}\\n\\nWhat is the high-level breakdown of objectives for this query?\\n\"\"\")\\n\\n\\n\\n# Format the intent descriptions for the prompt\\nformatted_intents = \"\\\\n\".join([f\"* {intent_name}: {description}\" for intent_name, description in intents.items()])\\nquery = \"What dose the vessel name column represents?\"\\n# Insert formatted intents into the prompt template\\ncompleted_prompt = prompt_template.format(intents=formatted_intents, query=query)\\n# Use the completed prompt with the AzureChatOpenAI model\\nresponse = llm_gpt.invoke(completed_prompt)\\n\\nprint(response)', 'from langchain import PromptTemplate\\n# Define the prompt template\\nprompt_template = PromptTemplate.from_template(\"\"\"\\nYou are an intelligent assistant whose only and only goal is to break down user\\'s query {query} into high-level, smaller objectives in form of list. You serve as an interface between users and a database containing various metrics/KPIs/measures.\\nStrictly note that it is not necessary to break down the query in all the following intents. The intents are only for reference. If the query is straightforward and aligns with any one of the intent, then do not change the query. \\nTry to minimize the number of objectives and keep them as high-level as possible. \\nEach smaller objective should strictly fall into one of the following intent:\\nDiscover Metrics:** If you\\'d like to measure something specific, I can identify relevant metrics. For example, are you interested in suggest some metrics based on objective?\\nFetch Data:** If you already know the metric you\\'re interested in, I can retrieve the data from the database.\\nInterpret Metrics:** Once you have the data, I can explain what it means in the context of your objective. \\nUnderstand Metrics:** If you\\'re unsure about a metric\\'s definition or purpose, I can provide more information.\\n\\nDon\\'t add noise to the response.\\nRespond with a list.\\nHowever, if the query involves something else entirely, like action outside current intents, give empty list.\"\"\")\\ndef complete(prompt, user_query):\\n  \"\"\"\\n  Completes the prompt with the user objective.\\n\\n  Args:\\n      prompt: The prompt template.\\n      user_objective: The user\\'s objective.\\n\\n  Returns:\\n      The completed prompt.\\n  \"\"\"\\n  return prompt.format(query=user_query)\\n\\n# Example usage\\nuser_objective = \"What are the top three metrics that indicate the overall health of our business?\"\\ncompleted_prompt = complete(prompt_template, user_objective)\\n\\n# Use the completed prompt with the AzureChatOpenAI model\\nresponse = llm_gpt.invoke(completed_prompt)\\n\\nprint(response)', 'intents = {\\n    \"discover_metrics\": \"Identify relevant metrics based on user objectives. (e.g., Suggest metrics to measure customer satisfaction)\",\\n    \"fetch_data\": \"Retrieve data for a specific metric the user has already identified.\",\\n    # \"analyze_trends\": \"Analyze trends within the fetched data to provide deeper insights.\",\\n    \"interpret_metrics\": \"Explain the meaning of the data in the context of the user\\'s objective.\",\\n    \"understand_metrics\": \"Provide information about a metric\\'s definition and purpose.\"\\n}\\nprompt_template = PromptTemplate.from_template(\"\"\"You are an intelligent assistant focused on helping users with metrics and data. Your primary goal is to break down user queries ({query}) into a concise list of high-level objectives.\\n\\n**Intents:**\\n\\n{intents}\\n\\nImportant Notes:\\n* Alignment with Intents: The new objectives should strictly align with the provided intents.\\n* Prioritize Clarity & Efficiency:  Minimize the number of objectives and maintain a high-level overview. \\n* Direct Match: If the query aligns perfectly with one intent (e.g., \"What\\'s the current customer churn rate?\" for Fetch Data), don\\'t alter it.\\n* Outside Scope: If the query falls outside these intents (e.g., \"Book a flight\"), return an empty list.\\n* Focus on User Need: Keep responses clear and concise, avoiding unnecessary information. \\n* Output Format:  Respond with a list containing the breakdown of objectives.\\n\\n**Here\\'s the user query: {query}\\n\\nWhat is the high-level breakdown of objectives for this query?\\n\"\"\")\\n\\n\\n\\n# Format the intent descriptions for the prompt\\nformatted_intents = \"\\\\n\".join([f\"* {intent_name}: {description}\" for intent_name, description in intents.items()])\\nquery = \"What dose the vessel name column represents?\"\\n# Insert formatted intents into the prompt template\\ncompleted_prompt = prompt_template.format(intents=formatted_intents, query=query)\\n# Use the completed prompt with the AzureChatOpenAI model\\nresponse = llm_gpt.invoke(completed_prompt)\\n\\nprint(response)', 'import ast\\nimport re\\nfrom typing import List, TypeVar\\nfrom langchain.schema import BaseOutputParser, OutputParserException\\nT = TypeVar(\"T\")\\n\\nclass TaskOutputParser(BaseOutputParser[List[str]]):\\n    \"\"\"\\n    Extension of LangChain\\'s BaseOutputParser\\n    Responsible for parsing task creation output into a list of task strings\\n    \"\"\"\\n\\n    completed_tasks: List[str] = []\\n\\n    def __init__(self, *, completed_tasks: List[str]):\\n        super().__init__()\\n        self.completed_tasks = completed_tasks\\n\\n    def parse(self, text: str) -> List[str]:\\n        try:\\n            array_str = extract_array(text)\\n            all_tasks = [\\n                remove_prefix(task) for task in array_str if real_tasks_filter(task)\\n            ]\\n            return [task for task in all_tasks if task not in self.completed_tasks]\\n        except Exception as e:\\n            msg = f\"Failed to parse tasks from completion \\'{text}\\'. Exception: {e}\"\\n            raise OutputParserException(msg)\\n\\n    def get_format_instructions(self) -> str:\\n        return \"\"\"\\n        The response should be a JSON array of strings. Example:\\n\\n        [\"Search the web for NBA news\", \"Write some code to build a web scraper\"]\\n\\n        This should be parsable by json.loads()\\n        \"\"\"\\n\\ndef handle_multiline_string(input_str: str) -> List[str]:\\n    # Handle multiline string as a list\\n    processed_lines = [\\n        re.sub(r\".*?(\\\\d+\\\\..+)\", r\"\\\\1\", line).strip()\\n        for line in input_str.split(\"\\\\n\")\\n        if line.strip() != \"\"\\n    ]\\n\\n    # Check if there is at least one line that starts with a digit and a period\\n    if any(re.match(r\"\\\\d+\\\\..+\", line) for line in processed_lines):\\n        return processed_lines\\n    else:\\n        # raise RuntimeError(f\"Failed to extract array from {input_str}\")\\n        print(f\"Failed to extract array from {input_str}\")\\n        return [input_str]\\n\\ndef extract_array(input_str: str) -> List[str]:\\n    regex = (\\n        r\"\\\\[\\\\s*\\\\]|\"  # Empty array check\\n        r\"(\\\\[(?:\\\\s*(?:\\\\\"(?:[^\\\\\"\\\\\\\\]|\\\\\\\\.)*\\\\\"|\\\\\\'(?:[^\\\\\\'\\\\\\\\]|\\\\\\\\.)*\\\\\\')\\\\s*,?)*\\\\s*\\\\])\"\\n    )\\n    match = re.search(regex, input_str)\\n    if match is not None:\\n        return ast.literal_eval(match[0])\\n    else:\\n        return handle_multiline_string(input_str)\\n    \\ndef remove_prefix(input_str: str) -> str:\\n    prefix_pattern = (\\n        r\"^(Task\\\\s*\\\\d*\\\\.\\\\s*|Task\\\\s*\\\\d*[-:]?\\\\s*|Step\\\\s*\\\\d*[\"\\n        r\"-:]?\\\\s*|Step\\\\s*[-:]?\\\\s*|\\\\d+\\\\.\\\\s*|\\\\d+\\\\s*[-:]?\\\\s*|^\\\\.\\\\s*|^\\\\.*)\"\\n    )\\n    return re.sub(prefix_pattern, \"\", input_str, flags=re.IGNORECASE)\\n\\n\\ndef real_tasks_filter(input_str: str) -> bool:\\n    no_task_regex = (\\n        r\"^No( (new|further|additional|extra|other))? tasks? (is )?(\"\\n        r\"required|needed|added|created|inputted).*\"\\n    )\\n    task_complete_regex = r\"^Task (complete|completed|finished|done|over|success).*\"\\n    do_nothing_regex = r\"^(\\\\s*|Do nothing(\\\\s.*)?)$\"\\n\\n    return (\\n        not re.search(no_task_regex, input_str, re.IGNORECASE)\\n        and not re.search(task_complete_regex, input_str, re.IGNORECASE)\\n        and not re.search(do_nothing_regex, input_str, re.IGNORECASE)\\n    )\\n\\ndef parse_with_handling(parser: BaseOutputParser[T], completion: str) -> T:\\n    try:\\n        return parser.parse(completion)\\n    except OutputParserException as e:\\n        raise e\\n    \\n\\ntask_output_parser = TaskOutputParser(completed_tasks=[])', 'objectives = parse_with_handling(task_output_parser, response.content)\\nprint(objectives)', 'analyze_task_prompt = PromptTemplate(\\n    template=\"\"\"\\n    High level objective: \"{goal}\"\\n    Current task: \"{task}\"\\n\\n    Based on this information, use the best expert to make progress or accomplish the task entirely. Each expert has a name and description of their expertise. \\n    Select the correct expert by being smart and efficient. Ensure \"reasoning\" and only \"reasoning\" is in the english language.\\n    Following are the list of experts {experts}\\n\\n    Note you MUST select a expert and return the name of the expert.\\n    \"\"\",\\n    input_variables=[\"goal\", \"task\", \"experts\"],\\n)', 'for objective in objectives:\\n    analyze_prompt = analyze_task_prompt.format(goal=query, task=objective, experts=expert_descriptions)\\n    expert_name = llm_gpt.invoke(analyze_prompt)\\n    print(expert_name)', 'import ast\\nimport re\\nfrom typing import List, TypeVar\\nfrom langchain.schema import BaseOutputParser, OutputParserException\\nT = TypeVar(\"T\")\\n\\nclass TaskOutputParser(BaseOutputParser[List[str]]):\\n    \"\"\"\\n    Extension of LangChain\\'s BaseOutputParser\\n    Responsible for parsing task creation output into a list of task strings\\n    \"\"\"\\n\\n    completed_tasks: List[str] = []\\n\\n    def __init__(self, *, completed_tasks: List[str]):\\n        super().__init__()\\n        self.completed_tasks = completed_tasks\\n\\n    def parse(self, text: str) -> List[str]:\\n        try:\\n            array_str = extract_array(text)\\n            all_tasks = [\\n                remove_prefix(task) for task in array_str if real_tasks_filter(task)\\n            ]\\n            return [task for task in all_tasks if task not in self.completed_tasks]\\n        except Exception as e:\\n            msg = f\"Failed to parse tasks from completion \\'{text}\\'. Exception: {e}\"\\n            raise OutputParserException(msg)\\n\\n    def get_format_instructions(self) -> str:\\n        return \"\"\"\\n        The response should be a JSON array of strings. Example:\\n\\n        [\"Search the web for NBA news\", \"Write some code to build a web scraper\"]\\n\\n        This should be parsable by json.loads()\\n        \"\"\"\\n\\ndef handle_multiline_string(input_str: str) -> List[str]:\\n    # Handle multiline string as a list\\n    processed_lines = [\\n        re.sub(r\".*?(\\\\d+\\\\..+)\", r\"\\\\1\", line).strip()\\n        for line in input_str.split(\"\\\\n\")\\n        if line.strip() != \"\"\\n    ]\\n\\n    # Check if there is at least one line that starts with a digit and a period\\n    if any(re.match(r\"\\\\d+\\\\..+\", line) for line in processed_lines):\\n        return processed_lines\\n    else:\\n        # raise RuntimeError(f\"Failed to extract array from {input_str}\")\\n        print(f\"Failed to extract array from {input_str}\")\\n        return [input_str]\\n\\ndef extract_array(input_str: str) -> List[str]:\\n    regex = (\\n        r\"\\\\[\\\\s*\\\\]|\"  # Empty array check\\n        r\"(\\\\[(?:\\\\s*(?:\\\\\"(?:[^\\\\\"\\\\\\\\]|\\\\\\\\.)*\\\\\"|\\\\\\'(?:[^\\\\\\'\\\\\\\\]|\\\\\\\\.)*\\\\\\')\\\\s*,?)*\\\\s*\\\\])\"\\n    )\\n    match = re.search(regex, input_str)\\n    if match is not None:\\n        return ast.literal_eval(match[0])\\n    else:\\n        return handle_multiline_string(input_str)\\n    \\ndef remove_prefix(input_str: str) -> str:\\n    prefix_pattern = (\\n        r\"^(Task\\\\s*\\\\d*\\\\.\\\\s*|Task\\\\s*\\\\d*[-:]?\\\\s*|Step\\\\s*\\\\d*[\"\\n        r\"-:]?\\\\s*|Step\\\\s*[-:]?\\\\s*|\\\\d+\\\\.\\\\s*|\\\\d+\\\\s*[-:]?\\\\s*|^\\\\.\\\\s*|^\\\\.*)\"\\n    )\\n    return re.sub(prefix_pattern, \"\", input_str, flags=re.IGNORECASE)\\n\\n\\ndef real_tasks_filter(input_str: str) -> bool:\\n    no_task_regex = (\\n        r\"^No( (new|further|additional|extra|other))? tasks? (is )?(\"\\n        r\"required|needed|added|created|inputted).*\"\\n    )\\n    task_complete_regex = r\"^Task (complete|completed|finished|done|over|success).*\"\\n    do_nothing_regex = r\"^(\\\\s*|Do nothing(\\\\s.*)?)$\"\\n\\n    return (\\n        not re.search(no_task_regex, input_str, re.IGNORECASE)\\n        and not re.search(task_complete_regex, input_str, re.IGNORECASE)\\n        and not re.search(do_nothing_regex, input_str, re.IGNORECASE)\\n    )\\n\\ndef parse_with_handling(parser: BaseOutputParser[T], completion: str) -> T:\\n    try:\\n        return parser.parse(completion)\\n    except OutputParserException as e:\\n        raise e\\n    \\n\\ntask_output_parser = TaskOutputParser(completed_tasks=[])', 'objectives = parse_with_handling(task_output_parser, response.content)\\nprint(objectives)', '#Available experts\\nfrom typing import Any, Dict, List, Optional, Union\\nfrom typing import Type, TypedDict\\n\\nclass ExpertDescription(TypedDict):\\n    \"\"\"Representation of a callable expert\"\"\"\\n    name: str\\n    \"\"\"The name of the expert.\"\"\"\\n    description: str\\n    \"\"\"A description of the expert.\"\"\"\\n    parameters: dict[str, object]\\n    \"\"\"The parameters of the expert.\"\"\"\\n\\ndef get_expert_function(expert: Type[Expert]) -> ExpertDescription:\\n    \"\"\"A function that will return the tool\\'s function specification\"\"\"\\n    name = get_expert_name(expert)\\n    return {\\n        \"name\": name,\\n        \"description\": expert.description,\\n        \"parameters\": {\\n            \"type\": \"object\",\\n            \"properties\": {\\n                \"reasoning\": {\\n                    \"type\": \"string\",\\n                    \"description\": (\\n                        f\"Reasoning is how the task will be accomplished with the current expert. \"\\n                        \"Detail your overall plan along with any concerns you have.\"\\n                        \"Ensure this reasoning value is in the user defined langauge \"\\n                    ),\\n                },\\n                \"arg\": {\\n                    \"type\": \"string\",\\n                    \"description\": expert.arg_description,\\n                },\\n            },\\n            \"required\": [\"reasoning\", \"arg\"],\\n        },\\n    }\\n\\ndef get_expert_name(expert: Type[Expert]) -> str:\\n    return expert.name\\n\\n# def format_expert_name(expert_name: str) -> str:\\n#     return expert_name.lower()\\n\\ndef get_available_experts() -> List[Type[Expert]]:\\n    return [\\n        MetricDiscoveryInputCrew\\n    ]', \"available_experts = get_available_experts()\\nexperts = list(map(get_expert_function, available_experts))\\nexpert_descriptions = {expert['name'] : expert['description'] for expert in experts}\", 'expert_descriptions', 'experts', 'analyze_task_prompt = PromptTemplate(\\n    template=\"\"\"\\n    High level objective: \"{goal}\"\\n    Current task: \"{task}\"\\n\\n    Based on this information, use the best expert to make progress or accomplish the task entirely. Each expert has a name and description of their expertise. \\n    Select the correct expert by being smart and efficient. Ensure \"reasoning\" and only \"reasoning\" is in the english language.\\n    Following are the list of experts {experts}\\n\\n    Note you MUST select a expert and return the name of the expert.\\n    \"\"\",\\n    input_variables=[\"goal\", \"task\", \"experts\"],\\n)', 'for objective in objectives:\\n    analyze_prompt = analyze_task_prompt.format(goal=query, task=objective, experts=expert_descriptions)\\n    expert_name = llm_gpt.invoke(analyze_prompt)\\n    print(expert_name)', 'type(expert_name)', 'type(dir(expert_name))', 'type(expert_name.content)', 'dir(expert_name)', 'dir(expert_name.content)', 'expert_name.content', 'type(expert_name.content)', 'dict(expert_name.content)', 'analyze_task_prompt = PromptTemplate(\\n    template=\"\"\"\\n    High level objective: \"{goal}\"\\n    Current task: \"{task}\"\\n\\n    Based on this information, use the best expert to make progress or accomplish the task entirely. Each expert has a name and description of their expertise. \\n    Select the correct expert by being smart and efficient. Ensure \"reasoning\" and only \"reasoning\" is in the english language.\\n    Following are the list of experts {experts}\\n\\n    Note you MUST select a expert and return the name and reasoning of the expert in form of dictionary.\\n    \"\"\",\\n    input_variables=[\"goal\", \"task\", \"experts\"],\\n)', 'for objective in objectives:\\n    analyze_prompt = analyze_task_prompt.format(goal=query, task=objective, experts=expert_descriptions)\\n    expert_name = llm_gpt.invoke(analyze_prompt)\\n    print(expert_name)', 'dict(expert_name.content)', 'type(expert_name.content)', 'type(expert_name..name)', 'type(expert_name.name)', \"type(expert_name['name'])\", 'import json \\ndictionary_data = json.loads(expert_name.content)', 'dictionary_data', 'experts_info = {\"Metric\" : MetricDiscoveryInputCrew()}', 'experts_info = {\"MetricDiscovery\" : MetricDiscoveryInputCrew()}', \"expert = experts_info.get(dictionary_data['name'])\", 'type(expert)', \"import json \\nfor objective in objectives:\\n    analyze_prompt = analyze_task_prompt.format(goal=query, task=objective, experts=expert_descriptions)\\n    response = llm_service.invoke(analyze_prompt)\\n    selected_expert = json.loads(response.content)\\n    expert_object = experts_info.get(selected_expert['name'])\\n    output = expert_object.run(objective)\", \"import json \\nfor objective in objectives:\\n    analyze_prompt = analyze_task_prompt.format(goal=query, task=objective, experts=expert_descriptions)\\n    response = llm_gpt.invoke(analyze_prompt)\\n    selected_expert = json.loads(response.content)\\n    expert_object = experts_info.get(selected_expert['name'])\\n    output = expert_object.run(objective)\"], '_oh': {39: {'MetricDiscovery': 'Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.'}, 40: [{'name': 'MetricDiscovery', 'description': 'Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.', 'parameters': {'type': 'object', 'properties': {'reasoning': {'type': 'string', 'description': 'Reasoning is how the task will be accomplished with the current expert. Detail your overall plan along with any concerns you have.Ensure this reasoning value is in the user defined langauge '}, 'arg': {'type': 'string', 'description': 'Query related to metrics.'}}, 'required': ['reasoning', 'arg']}}], 43: <class 'langchain_core.messages.ai.AIMessage'>, 44: <class 'list'>, 45: <class 'str'>, 46: ['Config', '__abstractmethods__', '__add__', '__annotations__', '__class__', '__class_vars__', '__config__', '__custom_root_type__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__exclude_fields__', '__fields__', '__fields_set__', '__format__', '__ge__', '__get_validators__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__include_fields__', '__init__', '__init_subclass__', '__iter__', '__json_encoder__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__post_root_validators__', '__pre_root_validators__', '__pretty__', '__private_attributes__', '__reduce__', '__reduce_ex__', '__repr__', '__repr_args__', '__repr_name__', '__repr_str__', '__rich_repr__', '__schema_cache__', '__setattr__', '__setstate__', '__signature__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__try_update_forward_refs__', '__validators__', '_abc_impl', '_backwards_compat_tool_calls', '_calculate_keys', '_copy_and_set_values', '_decompose_class', '_enforce_dict_if_root', '_get_value', '_init_private_attributes', '_iter', 'additional_kwargs', 'construct', 'content', 'copy', 'dict', 'example', 'from_orm', 'get_lc_namespace', 'id', 'invalid_tool_calls', 'is_lc_serializable', 'json', 'lc_attributes', 'lc_id', 'lc_secrets', 'name', 'parse_file', 'parse_obj', 'parse_raw', 'pretty_print', 'pretty_repr', 'response_metadata', 'schema', 'schema_json', 'to_json', 'to_json_not_implemented', 'tool_calls', 'type', 'update_forward_refs', 'validate'], 47: ['__add__', '__class__', '__contains__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getnewargs__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mod__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__rmod__', '__rmul__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'capitalize', 'casefold', 'center', 'count', 'encode', 'endswith', 'expandtabs', 'find', 'format', 'format_map', 'index', 'isalnum', 'isalpha', 'isascii', 'isdecimal', 'isdigit', 'isidentifier', 'islower', 'isnumeric', 'isprintable', 'isspace', 'istitle', 'isupper', 'join', 'ljust', 'lower', 'lstrip', 'maketrans', 'partition', 'removeprefix', 'removesuffix', 'replace', 'rfind', 'rindex', 'rjust', 'rpartition', 'rsplit', 'rstrip', 'split', 'splitlines', 'startswith', 'strip', 'swapcase', 'title', 'translate', 'upper', 'zfill'], 48: 'Expert: MetricDiscovery\\n\\nReasoning: The task at hand is to clarify the significance of the \"vessel name\" column in a dataset, which falls under the explanation and interpretation of a specific column within a table. The MetricDiscovery expert is described as being used to answer questions related to the explanation, description, and interpretation of metrics, measures, KPIs, tables, or columns. Therefore, this expert is best suited to provide clarity on what the \"vessel name\" column represents.', 49: <class 'str'>, 54: <class 'str'>, 56: <class 'NoneType'>, 59: {'name': 'MetricDiscovery', 'reasoning': \"The 'vessel name' column in a dataset likely refers to the names of ships or boats that are part of the data being analyzed. The MetricDiscovery expert is suitable for explaining, describing, and interpreting what this column signifies within the context of the dataset, as it falls under the expertise of understanding metrics, measures, and the contents of columns in a dataset.\"}, 63: <class '__main__.MetricDiscoveryInputCrew'>}, '_dh': [PosixPath('/Users/k.abhishek/Documents/experiments/metric_store/metric_store_gen_ai/experiments')], 'In': ['', 'a ={\"a\" : MetricDiscoveryInputCrew()}', 'from crewai.process import Process\\nfrom typing import Any\\nclass MetricDiscoveryInputCrew(Expert):\\n  name = \"MetricDiscovery\"\\n  description = (\\n       \"Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\\n    )\\n  public_description = \"Metric discovery crew\"\\n  arg_description = \"Query related to metrics.\"\\n\\n  def __init__(self, query):\\n    self.query = query\\n    self.crew_process = self.crew_process()\\n    # self.llm = llm_gpt\\n  def crew_process(self):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    # print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, self.query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n    return crew\\n\\n  def run(self):\\n    result = self.crew_process.kickoff()\\n    return result\\n  \\n  def call(\\n        self, goal: str, task: str, input_str: str, *args: Any, **kwargs: Any\\n    ) -> str:\\n    pass', '#initialize\\n#     model\\n#     environment variables\\n\\nimport sys\\nsys.path.append(\\'..\\')\\nfrom src.utils.llamaindex_retriever import LlamaIndexRetriever\\nfrom langchain.vectorstores import FAISS\\nfrom langchain.embeddings.azure_openai import AzureOpenAIEmbeddings\\nfrom langchain.embeddings.openai import OpenAIEmbeddings\\nfrom dotenv import load_dotenv\\nimport os\\nfrom langchain.chat_models import AzureChatOpenAI\\n\\ndef load_env_variables(file_path):\\n    load_dotenv(file_path)\\n    print(\"Environment variables loaded successfully!\")\\n\\nenv_file_path = \"../.env\"\\nload_env_variables = load_env_variables(env_file_path)\\nmax_tokens = 3500\\ntemperature = 0.1\\n\\n# embeddings = AzureOpenAIEmbeddings(azure_deployment=azure_deployment, openai_api_version=openai_api_version)\\nembeddings =  AzureOpenAIEmbeddings(\\n        deployment=os.getenv(\"EMB_DEPLOYMENT\"),\\n        openai_api_version=os.getenv(\"EMB_OPENAI_API_VERSION\"),\\n        model=os.getenv(\"EMB_MODEL\"),\\n        openai_api_key=os.getenv(\"EMB_OPENAI_API_KEY\"),\\n        openai_api_base=os.getenv(\"EMB_OPENAI_ENDPOINT\"),\\n        openai_api_type=os.getenv(\"EMB_API_TYPE\"),\\n    )\\n\\nllm_gpt = AzureChatOpenAI(deployment_name=os.getenv(\\'AZURE_OPENAI_DEPLOYMENT_NAME\\'), openai_api_version=os.getenv(\"OPENAI_API_VERSION\"),\\n                        openai_api_base=os.getenv(\"OPENAI_API_BASE\"), \\n                        openai_api_type= os.getenv(\"OPENAI_API_TYPE\"),\\n                        openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\\n                        max_tokens=max_tokens,\\n                        temperature=temperature)', '#define utils\\nfrom src.utils.cube_semantic_custom import CubeSemanticLoader\\ndef fetch_cube_metadata(*args, **kwargs):\\n    try:\\n        # # Load document from Cube meta api\\n        loader = CubeSemanticLoader(os.getenv(\"CUBE_API_URL\"), os.getenv(\"CUBE_TOKEN\"), False)\\n        documents = loader.load()\\n        # to_json()\\n        return documents\\n    except Exception as e:\\n        # Handle exceptions gracefully and return an error response\\n        print(\"Error in fetching metadata from cube: \" + str(e))\\n        return 0\\n\\ndef create_vector_store(documents, local_vector_store_path, *args, **kwargs):\\n    print(\"Loaded documents: \" + str(documents))\\n    vectorstore = FAISS.from_documents(documents, embeddings)\\n    vectorstore.save_local(local_vector_store_path)\\n    print(\"Vector store created and saved successfully!\")\\n\\ndef load_vector_store(vector_store_path, embeddings, *args, **kwargs):\\n    # Load the vector store from the local file system\\n    vectorstore = FAISS.load_local(vector_store_path, embeddings, allow_dangerous_deserialization=True)\\n    print(\"Vector store loaded successfully!\")\\n    \\n    return vectorstore', '#load existing vector store\\nvector_store_path = \"/Users/k.abhishek/Documents/experiments/metric_store/metric_store_gen_ai/data/vector_store/cube_meta_faiss_index\"\\nvectorstore = load_vector_store(vector_store_path, embeddings)', 'import json\\nfrom crewai import Agent, Task, Crew\\nfrom langchain.tools import tool\\nfrom src.utils.llamaindex_retriever import LlamaIndexRetriever\\nfrom typing import Optional, Type\\nfrom langchain.callbacks.manager import (\\n    AsyncCallbackManagerForToolRun,\\n    CallbackManagerForToolRun,\\n)\\n# Import things that are needed generically\\nfrom langchain.pydantic_v1 import BaseModel, Field\\n# from langchain.tools import BaseTool, StructuredTool, tool\\nfrom crewai_tools import BaseTool\\n\\n\\ndef get_similar_documents_faiss(query, max_number_documents=3):\\n  vectorstore = FAISS.load_local(vector_store_path, embeddings, allow_dangerous_deserialization=True)\\n  docs = vectorstore.similarity_search_with_relevance_scores(query, max_number_documents)\\n  relevant_documents = []\\n  for doc in docs:\\n      doc = doc[0]\\n      meta = {\\'text\\':doc.page_content, \\'table_metadata\\': doc.metadata}\\n      relevant_documents.append(meta)\\n  return relevant_documents\\n\\ndef get_similar_documents(query, max_number_documents=3):\\n    return get_similar_documents_faiss(query, max_number_documents)\\n\\n\\nclass QueryInput(BaseModel):\\n    query: str = Field(description=\"should be enquiry query\")\\n\\nclass TerminationHandler(CallbackManagerForToolRun):\\n    pass\\n\\nclass RephraseInputQuery(BaseTool):\\n    name:str = \"rephrase_input_query\"\\n    description :str = \"Useful to rephrase the query to capture the intent of the user regarding metric information\"\\n    args_schema: Type[BaseModel] = QueryInput\\n\\n    def _run(\\n        self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None\\n    ) -> str:\\n        \"\"\"Use the tool.\"\"\"\\n        metric_description = self.rephrase_input_query(query)\\n        return metric_description\\n\\n    async def _arun(\\n        self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None\\n    ) -> str:\\n        \"\"\"Use the tool asynchronously.\"\"\"\\n        raise NotImplementedError(\"custom_search does not support async\")\\n    \\n    \\n    def rephrase_input_query(self, query, *args, **kwargs):\\n        agent = Agent(\\n                role=\\'Intent Capturer\\',\\n                goal=\\n                \\'Rephrasing the query to capture the intent of the user regarding metric information\\',\\n                backstory=\\n                \"You are an expert to understand the user\\'s intent and rephrase the query to capture the intent of the user accurately.\",\\n                llm = llm_gpt,\\n                allow_delegation=False)\\n        task = Task(\\n                agent=agent,\\n                description=\\n                f\\'Rephrase the query to capture the intent of the user regarding metric information. The query is {query}. Donot add any noise to the response\\',\\n                expected_output=\"some string\",\\n        \\n            )\\n        extracted_metrics = task.execute()\\n\\n        return extracted_metrics\\n    \\n\\n    \\nclass MetricDiscovery(BaseTool):\\n    name :str = \"metric_discovery\"\\n    description:str = \"\"\"Useful for general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\"\"\\n    args_schema: Type[BaseModel] = QueryInput\\n\\n    def _run(\\n        self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None\\n    ) -> str:\\n        \"\"\"Use the tool.\"\"\"\\n        metric_description = self.metric_discovery(query)\\n        return metric_description\\n\\n    async def _arun(\\n        self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None\\n    ) -> str:\\n        \"\"\"Use the tool asynchronously.\"\"\"\\n        raise NotImplementedError(\"custom_search does not support async\")\\n    \\n    \\n    def metric_discovery(self, query, *args, **kwargs):\\n        \"\"\"Useful for general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\"\"\\n        relevant_documents = get_similar_documents(query)\\n        agent = Agent(\\n                role=\\'Data Analyst Assistant\\',\\n                goal=\\n                \\'Empower users to understand and utilize data effectively. This includes helping them discover relevant metrics, interpreting their meaning\\',\\n                backstory=\\n                \"The primary purpose is to bridge the gap between raw data and user comprehension, fostering a data-driven culture within the organization.\",\\n                llm = llm_gpt,\\n                allow_delegation=False)  \\n        \\n        task = Task(\\n                agent=agent,\\n                description=\\n                \"\"\" You are responding to  question {metric_description} with answer from the Metadata provided to you as {relevant_documents}}.\\n                    Strictly answer the question with the information present in metadata only.\\n                    Respond with \"Sorry, the query is out of scope.\" if the answer is not present in metadata and terminate further reasoning and prcoess.\\n                    \"\"\",\\n                expected_output=\"some string\",\\n        \\n            )\\n        output = task.execute()\\n\\n        return output', '# def check_termination(task_output):\\n#     agent = Agent(\\n#                 role=\\'Determine query completion\\',\\n#                 goal=\\n#                 \\'Given task output, determine termination of crew workflow\\',\\n#                 backstory=\\n#                 \"Given user query request from user determine if no more new task is needed to be executed\",\\n#                 llm = llm_gpt,\\n#                 allow_delegation=False)\\n#     task = Task(\\n#                 agent=agent,\\n#                 description=\\n#                 f\\'Given task output, if the query is completed and the task result determines that the query is out of scope then terminate the workflow or else the required query is satisfied. Following is the task result {task_output}\\',\\n#                 expected_output=\"some string\",\\n        \\n#             )\\n#     termination_status = task.execute()\\n#     return termination_status\\nclass MetricDiscoveryTasks():\\n  def metric_isolation(self, agent, query):\\n    return Task(description=(f\"\"\"\\n        Rephrase the query to capture the intent of the user regarding metric information. The query is {query}. Donot add any noise to the response.\\n        {self.__tip_section()}\"\"\"),\\n      agent=agent,\\n      expected_output=\"Reformatted query to capture the intent of the user regarding metric information.\",\\n      # callback=callback_function,\\n    )\\n  \\n  def metric_discovery(self, agent):\\n    return Task(description=(f\"\"\"\\n        Answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\\n        {self.__tip_section()}\"\"\"),\\n      agent=agent,\\n      expected_output=\"If relevant metric exists in metadata, provide the answer. Else, respond with \\'Sorry, the query is out of scope.\\' and terminate process.\",\\n      # callback=callback_function,\\n    )\\n  def __tip_section(self):\\n    return \"If you do your BEST WORK, I\\'ll give you a $10,000 commission!\"\\n  \\n  ', 'class MetricDiscoveryAgent():\\n  def user_intent_capture(self):\\n    return Agent(\\n      role=\\'Intent Capturer\\',\\n      goal=\\n      \\'Rephrasing the query to capture the intent of the user regarding metric information\\',\\n      backstory=\\n      \"You are an expert to understand the user\\'s intent and rephrase the query to capture the intent of the user accurately.\",\\n      verbose=True,\\n      tools=[\\n        RephraseInputQuery()\\n      ],\\n      llm = llm_gpt,\\n    )\\n  def discover_metric_info(self):\\n    return Agent(\\n     role=\\'Data Analyst Assistant\\',\\n      goal=\\n      \\'Empower users to understand and utilize data effectively. This includes helping them discover relevant metrics, interpreting their meaning\\',\\n      backstory=\\n      \"The primary purpose is to bridge the gap between raw data and user comprehension, fostering a data-driven culture within the organization.\",\\n      llm = llm_gpt,\\n      verbose=True,\\n      tools=[\\n        MetricDiscovery()\\n      ],\\n    )', 'def after_task_callback(output):\\n  # Perform actions after the task, \\n  # for example, logging or updating agent state\\n  \\n  print(f\"Agent completed task with result: {output}\")\\n\\n# Assigning the function to task_callback\\ntask_callback = after_task_callback', 'def test_callback():\\n        # Accessing local variables\\n        print(\"Local variables:\", locals())\\n        \\n        # Accessing global variables\\n        print(\"Global variables:\", globals())    \\n        \\n        # Accessing built-in variables\\n        print(\"Built-in variables:\", dir(__builtins__))\\n        after_task_callback(\"output\")\\n  ', 'from abc import ABC, abstractmethod\\nclass Expert(ABC):\\n    name: str = \"\"\\n    description: str = \"\"\\n    public_description: str = \"\"\\n    arg_description: str = \"The argument to the function.\"\\n\\n    @abstractmethod\\n    def call(\\n        self,\\n        goal: str,\\n        task: str,\\n        input_str: str,\\n    ) -> str:\\n        pass', 'from crewai.process import Process\\nfrom typing import Any\\nclass MetricDiscoveryInputCrew(Expert):\\n  name = \"MetricDiscovery\"\\n  description = (\\n       \"Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\\n    )\\n  public_description = \"Metric discovery crew\"\\n  arg_description = \"Query related to metrics.\"\\n\\n  def __init__(self, query):\\n    self.query = query\\n    self.crew_process = self.crew_process()\\n    # self.llm = llm_gpt\\n  def crew_process(self):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    # print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, self.query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n    return crew\\n\\n  def run(self):\\n    result = self.crew_process.kickoff()\\n    return result\\n  \\n  def call(\\n        self, goal: str, task: str, input_str: str, *args: Any, **kwargs: Any\\n    ) -> str:\\n    pass', 'a ={\"a\" : MetricDiscoveryInputCrew()}', 'from crewai.process import Process\\nfrom typing import Any\\nclass MetricDiscoveryInputCrew(Expert):\\n  name = \"MetricDiscovery\"\\n  description = (\\n       \"Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\\n    )\\n  public_description = \"Metric discovery crew\"\\n  arg_description = \"Query related to metrics.\"\\n\\n  def __init__(self):\\n    # self.query = query\\n    self.crew_process = self.crew_process()\\n    # self.llm = llm_gpt\\n  def crew_process(self, query: str):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    # print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n    return crew\\n\\n  def run(self, query: str):\\n    result = self.crew_process.kickoff()\\n    return result\\n  \\n  def call(\\n        self, goal: str, task: str, input_str: str, *args: Any, **kwargs: Any\\n    ) -> str:\\n    pass', 'a ={\"a\" : MetricDiscoveryInputCrew()}', 'from crewai.process import Process\\nfrom typing import Any\\nclass MetricDiscoveryInputCrew(Expert):\\n  name = \"MetricDiscovery\"\\n  description = (\\n       \"Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\\n    )\\n  public_description = \"Metric discovery crew\"\\n  arg_description = \"Query related to metrics.\"\\n\\n  def crew_process(self, query: str):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    # print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n    return crew\\n  \\n\\n  def run(self, query: str):\\n    result = self.crew_process.kickoff(query)\\n    return result\\n  \\n  def call(\\n        self, goal: str, task: str, input_str: str, *args: Any, **kwargs: Any\\n    ) -> str:\\n    pass', 'a ={\"a\" : MetricDiscoveryInputCrew()}', 'objectives = parse_with_handling(task_output_parser, response.content)\\nprint(objectives)', 'intents = {\\n    \"discover_metrics\": \"Identify relevant metrics based on user objectives. (e.g., Suggest metrics to measure customer satisfaction)\",\\n    \"fetch_data\": \"Retrieve data for a specific metric the user has already identified.\",\\n    # \"analyze_trends\": \"Analyze trends within the fetched data to provide deeper insights.\",\\n    \"interpret_metrics\": \"Explain the meaning of the data in the context of the user\\'s objective.\",\\n    \"understand_metrics\": \"Provide information about a metric\\'s definition and purpose.\"\\n}\\nprompt_template = PromptTemplate.from_template(\"\"\"You are an intelligent assistant focused on helping users with metrics and data. Your primary goal is to break down user queries ({query}) into a concise list of high-level objectives.\\n\\n**Intents:**\\n\\n{intents}\\n\\nImportant Notes:\\n* Alignment with Intents: The new objectives should strictly align with the provided intents.\\n* Prioritize Clarity & Efficiency:  Minimize the number of objectives and maintain a high-level overview. \\n* Direct Match: If the query aligns perfectly with one intent (e.g., \"What\\'s the current customer churn rate?\" for Fetch Data), don\\'t alter it.\\n* Outside Scope: If the query falls outside these intents (e.g., \"Book a flight\"), return an empty list.\\n* Focus on User Need: Keep responses clear and concise, avoiding unnecessary information. \\n* Output Format:  Respond with a list containing the breakdown of objectives.\\n\\n**Here\\'s the user query: {query}\\n\\nWhat is the high-level breakdown of objectives for this query?\\n\"\"\")\\n\\n\\n\\n# Format the intent descriptions for the prompt\\nformatted_intents = \"\\\\n\".join([f\"* {intent_name}: {description}\" for intent_name, description in intents.items()])\\nquery = \"What dose the vessel name column represents?\"\\n# Insert formatted intents into the prompt template\\ncompleted_prompt = prompt_template.format(intents=formatted_intents, query=query)\\n# Use the completed prompt with the AzureChatOpenAI model\\nresponse = llm_gpt.invoke(completed_prompt)\\n\\nprint(response)', 'query = \"What is the most popular feature used by our paid subscribers\"\\n# formatted_query = input(\\n#     dedent(\"\"\"\\n#       {What is the most popular feature used by our paid subscribers}\\n#     \"\"\"))\\n# print(formatted_query)\\ncrew = MetricDiscoveryInputCrew()\\nresult = crew.run(query)', 'from crewai.process import Process\\nfrom typing import Any\\nclass MetricDiscoveryInputCrew(Expert):\\n  name = \"MetricDiscovery\"\\n  description = (\\n       \"Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\\n    )\\n  public_description = \"Metric discovery crew\"\\n  arg_description = \"Query related to metrics.\"\\n\\n  def crew_process(self, query: str):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    # print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n    return crew\\n  \\n\\n  def run(self, query: str):\\n    crew = self.crew_process.kickoff(query)\\n    result = crew.kickoff()\\n    return result\\n  \\n  def call(\\n        self, goal: str, task: str, input_str: str, *args: Any, **kwargs: Any\\n    ) -> str:\\n    pass', 'query = \"What is the most popular feature used by our paid subscribers\"\\n# formatted_query = input(\\n#     dedent(\"\"\"\\n#       {What is the most popular feature used by our paid subscribers}\\n#     \"\"\"))\\n# print(formatted_query)\\ncrew = MetricDiscoveryInputCrew()\\nresult = crew.run(query)', 'from crewai.process import Process\\nfrom typing import Any\\nclass MetricDiscoveryInputCrew(Expert):\\n  name = \"MetricDiscovery\"\\n  description = (\\n       \"Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\\n    )\\n  public_description = \"Metric discovery crew\"\\n  arg_description = \"Query related to metrics.\"\\n\\n  def crew_process(self, query: str):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    # print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n    return crew\\n  \\n\\n  def run(self, query: str):\\n    crew = self.crew_process(query)\\n    result = crew.kickoff()\\n    return result\\n  \\n  def call(\\n        self, goal: str, task: str, input_str: str, *args: Any, **kwargs: Any\\n    ) -> str:\\n    pass', 'query = \"What is the most popular feature used by our paid subscribers\"\\n# formatted_query = input(\\n#     dedent(\"\"\"\\n#       {What is the most popular feature used by our paid subscribers}\\n#     \"\"\"))\\n# print(formatted_query)\\ncrew = MetricDiscoveryInputCrew()\\nresult = crew.run(query)', 'print(result)', 'type(result)\\nprint(result)', 'print(type(result))\\nprint(result)', 'intents = {\\n    \"discover_metrics\": \"Identify relevant metrics based on user objectives. (e.g., Suggest metrics to measure customer satisfaction)\",\\n    \"fetch_data\": \"Retrieve data for a specific metric the user has already identified.\",\\n    # \"analyze_trends\": \"Analyze trends within the fetched data to provide deeper insights.\",\\n    \"interpret_metrics\": \"Explain the meaning of the data in the context of the user\\'s objective.\",\\n    \"understand_metrics\": \"Provide information about a metric\\'s definition and purpose.\"\\n}\\nprompt_template = PromptTemplate.from_template(\"\"\"You are an intelligent assistant focused on helping users with metrics and data. Your primary goal is to break down user queries ({query}) into a concise list of high-level objectives.\\n\\n**Intents:**\\n\\n{intents}\\n\\nImportant Notes:\\n* Alignment with Intents: The new objectives should strictly align with the provided intents.\\n* Prioritize Clarity & Efficiency:  Minimize the number of objectives and maintain a high-level overview. \\n* Direct Match: If the query aligns perfectly with one intent (e.g., \"What\\'s the current customer churn rate?\" for Fetch Data), don\\'t alter it.\\n* Outside Scope: If the query falls outside these intents (e.g., \"Book a flight\"), return an empty list.\\n* Focus on User Need: Keep responses clear and concise, avoiding unnecessary information. \\n* Output Format:  Respond with a list containing the breakdown of objectives.\\n\\n**Here\\'s the user query: {query}\\n\\nWhat is the high-level breakdown of objectives for this query?\\n\"\"\")\\n\\n\\n\\n# Format the intent descriptions for the prompt\\nformatted_intents = \"\\\\n\".join([f\"* {intent_name}: {description}\" for intent_name, description in intents.items()])\\nquery = \"What dose the vessel name column represents?\"\\n# Insert formatted intents into the prompt template\\ncompleted_prompt = prompt_template.format(intents=formatted_intents, query=query)\\n# Use the completed prompt with the AzureChatOpenAI model\\nresponse = llm_gpt.invoke(completed_prompt)\\n\\nprint(response)', 'from langchain import PromptTemplate\\n# Define the prompt template\\nprompt_template = PromptTemplate.from_template(\"\"\"\\nYou are an intelligent assistant whose only and only goal is to break down user\\'s query {query} into high-level, smaller objectives in form of list. You serve as an interface between users and a database containing various metrics/KPIs/measures.\\nStrictly note that it is not necessary to break down the query in all the following intents. The intents are only for reference. If the query is straightforward and aligns with any one of the intent, then do not change the query. \\nTry to minimize the number of objectives and keep them as high-level as possible. \\nEach smaller objective should strictly fall into one of the following intent:\\nDiscover Metrics:** If you\\'d like to measure something specific, I can identify relevant metrics. For example, are you interested in suggest some metrics based on objective?\\nFetch Data:** If you already know the metric you\\'re interested in, I can retrieve the data from the database.\\nInterpret Metrics:** Once you have the data, I can explain what it means in the context of your objective. \\nUnderstand Metrics:** If you\\'re unsure about a metric\\'s definition or purpose, I can provide more information.\\n\\nDon\\'t add noise to the response.\\nRespond with a list.\\nHowever, if the query involves something else entirely, like action outside current intents, give empty list.\"\"\")\\ndef complete(prompt, user_query):\\n  \"\"\"\\n  Completes the prompt with the user objective.\\n\\n  Args:\\n      prompt: The prompt template.\\n      user_objective: The user\\'s objective.\\n\\n  Returns:\\n      The completed prompt.\\n  \"\"\"\\n  return prompt.format(query=user_query)\\n\\n# Example usage\\nuser_objective = \"What are the top three metrics that indicate the overall health of our business?\"\\ncompleted_prompt = complete(prompt_template, user_objective)\\n\\n# Use the completed prompt with the AzureChatOpenAI model\\nresponse = llm_gpt.invoke(completed_prompt)\\n\\nprint(response)', 'intents = {\\n    \"discover_metrics\": \"Identify relevant metrics based on user objectives. (e.g., Suggest metrics to measure customer satisfaction)\",\\n    \"fetch_data\": \"Retrieve data for a specific metric the user has already identified.\",\\n    # \"analyze_trends\": \"Analyze trends within the fetched data to provide deeper insights.\",\\n    \"interpret_metrics\": \"Explain the meaning of the data in the context of the user\\'s objective.\",\\n    \"understand_metrics\": \"Provide information about a metric\\'s definition and purpose.\"\\n}\\nprompt_template = PromptTemplate.from_template(\"\"\"You are an intelligent assistant focused on helping users with metrics and data. Your primary goal is to break down user queries ({query}) into a concise list of high-level objectives.\\n\\n**Intents:**\\n\\n{intents}\\n\\nImportant Notes:\\n* Alignment with Intents: The new objectives should strictly align with the provided intents.\\n* Prioritize Clarity & Efficiency:  Minimize the number of objectives and maintain a high-level overview. \\n* Direct Match: If the query aligns perfectly with one intent (e.g., \"What\\'s the current customer churn rate?\" for Fetch Data), don\\'t alter it.\\n* Outside Scope: If the query falls outside these intents (e.g., \"Book a flight\"), return an empty list.\\n* Focus on User Need: Keep responses clear and concise, avoiding unnecessary information. \\n* Output Format:  Respond with a list containing the breakdown of objectives.\\n\\n**Here\\'s the user query: {query}\\n\\nWhat is the high-level breakdown of objectives for this query?\\n\"\"\")\\n\\n\\n\\n# Format the intent descriptions for the prompt\\nformatted_intents = \"\\\\n\".join([f\"* {intent_name}: {description}\" for intent_name, description in intents.items()])\\nquery = \"What dose the vessel name column represents?\"\\n# Insert formatted intents into the prompt template\\ncompleted_prompt = prompt_template.format(intents=formatted_intents, query=query)\\n# Use the completed prompt with the AzureChatOpenAI model\\nresponse = llm_gpt.invoke(completed_prompt)\\n\\nprint(response)', 'import ast\\nimport re\\nfrom typing import List, TypeVar\\nfrom langchain.schema import BaseOutputParser, OutputParserException\\nT = TypeVar(\"T\")\\n\\nclass TaskOutputParser(BaseOutputParser[List[str]]):\\n    \"\"\"\\n    Extension of LangChain\\'s BaseOutputParser\\n    Responsible for parsing task creation output into a list of task strings\\n    \"\"\"\\n\\n    completed_tasks: List[str] = []\\n\\n    def __init__(self, *, completed_tasks: List[str]):\\n        super().__init__()\\n        self.completed_tasks = completed_tasks\\n\\n    def parse(self, text: str) -> List[str]:\\n        try:\\n            array_str = extract_array(text)\\n            all_tasks = [\\n                remove_prefix(task) for task in array_str if real_tasks_filter(task)\\n            ]\\n            return [task for task in all_tasks if task not in self.completed_tasks]\\n        except Exception as e:\\n            msg = f\"Failed to parse tasks from completion \\'{text}\\'. Exception: {e}\"\\n            raise OutputParserException(msg)\\n\\n    def get_format_instructions(self) -> str:\\n        return \"\"\"\\n        The response should be a JSON array of strings. Example:\\n\\n        [\"Search the web for NBA news\", \"Write some code to build a web scraper\"]\\n\\n        This should be parsable by json.loads()\\n        \"\"\"\\n\\ndef handle_multiline_string(input_str: str) -> List[str]:\\n    # Handle multiline string as a list\\n    processed_lines = [\\n        re.sub(r\".*?(\\\\d+\\\\..+)\", r\"\\\\1\", line).strip()\\n        for line in input_str.split(\"\\\\n\")\\n        if line.strip() != \"\"\\n    ]\\n\\n    # Check if there is at least one line that starts with a digit and a period\\n    if any(re.match(r\"\\\\d+\\\\..+\", line) for line in processed_lines):\\n        return processed_lines\\n    else:\\n        # raise RuntimeError(f\"Failed to extract array from {input_str}\")\\n        print(f\"Failed to extract array from {input_str}\")\\n        return [input_str]\\n\\ndef extract_array(input_str: str) -> List[str]:\\n    regex = (\\n        r\"\\\\[\\\\s*\\\\]|\"  # Empty array check\\n        r\"(\\\\[(?:\\\\s*(?:\\\\\"(?:[^\\\\\"\\\\\\\\]|\\\\\\\\.)*\\\\\"|\\\\\\'(?:[^\\\\\\'\\\\\\\\]|\\\\\\\\.)*\\\\\\')\\\\s*,?)*\\\\s*\\\\])\"\\n    )\\n    match = re.search(regex, input_str)\\n    if match is not None:\\n        return ast.literal_eval(match[0])\\n    else:\\n        return handle_multiline_string(input_str)\\n    \\ndef remove_prefix(input_str: str) -> str:\\n    prefix_pattern = (\\n        r\"^(Task\\\\s*\\\\d*\\\\.\\\\s*|Task\\\\s*\\\\d*[-:]?\\\\s*|Step\\\\s*\\\\d*[\"\\n        r\"-:]?\\\\s*|Step\\\\s*[-:]?\\\\s*|\\\\d+\\\\.\\\\s*|\\\\d+\\\\s*[-:]?\\\\s*|^\\\\.\\\\s*|^\\\\.*)\"\\n    )\\n    return re.sub(prefix_pattern, \"\", input_str, flags=re.IGNORECASE)\\n\\n\\ndef real_tasks_filter(input_str: str) -> bool:\\n    no_task_regex = (\\n        r\"^No( (new|further|additional|extra|other))? tasks? (is )?(\"\\n        r\"required|needed|added|created|inputted).*\"\\n    )\\n    task_complete_regex = r\"^Task (complete|completed|finished|done|over|success).*\"\\n    do_nothing_regex = r\"^(\\\\s*|Do nothing(\\\\s.*)?)$\"\\n\\n    return (\\n        not re.search(no_task_regex, input_str, re.IGNORECASE)\\n        and not re.search(task_complete_regex, input_str, re.IGNORECASE)\\n        and not re.search(do_nothing_regex, input_str, re.IGNORECASE)\\n    )\\n\\ndef parse_with_handling(parser: BaseOutputParser[T], completion: str) -> T:\\n    try:\\n        return parser.parse(completion)\\n    except OutputParserException as e:\\n        raise e\\n    \\n\\ntask_output_parser = TaskOutputParser(completed_tasks=[])', 'objectives = parse_with_handling(task_output_parser, response.content)\\nprint(objectives)', 'analyze_task_prompt = PromptTemplate(\\n    template=\"\"\"\\n    High level objective: \"{goal}\"\\n    Current task: \"{task}\"\\n\\n    Based on this information, use the best expert to make progress or accomplish the task entirely. Each expert has a name and description of their expertise. \\n    Select the correct expert by being smart and efficient. Ensure \"reasoning\" and only \"reasoning\" is in the english language.\\n    Following are the list of experts {experts}\\n\\n    Note you MUST select a expert and return the name of the expert.\\n    \"\"\",\\n    input_variables=[\"goal\", \"task\", \"experts\"],\\n)', 'for objective in objectives:\\n    analyze_prompt = analyze_task_prompt.format(goal=query, task=objective, experts=expert_descriptions)\\n    expert_name = llm_gpt.invoke(analyze_prompt)\\n    print(expert_name)', 'import ast\\nimport re\\nfrom typing import List, TypeVar\\nfrom langchain.schema import BaseOutputParser, OutputParserException\\nT = TypeVar(\"T\")\\n\\nclass TaskOutputParser(BaseOutputParser[List[str]]):\\n    \"\"\"\\n    Extension of LangChain\\'s BaseOutputParser\\n    Responsible for parsing task creation output into a list of task strings\\n    \"\"\"\\n\\n    completed_tasks: List[str] = []\\n\\n    def __init__(self, *, completed_tasks: List[str]):\\n        super().__init__()\\n        self.completed_tasks = completed_tasks\\n\\n    def parse(self, text: str) -> List[str]:\\n        try:\\n            array_str = extract_array(text)\\n            all_tasks = [\\n                remove_prefix(task) for task in array_str if real_tasks_filter(task)\\n            ]\\n            return [task for task in all_tasks if task not in self.completed_tasks]\\n        except Exception as e:\\n            msg = f\"Failed to parse tasks from completion \\'{text}\\'. Exception: {e}\"\\n            raise OutputParserException(msg)\\n\\n    def get_format_instructions(self) -> str:\\n        return \"\"\"\\n        The response should be a JSON array of strings. Example:\\n\\n        [\"Search the web for NBA news\", \"Write some code to build a web scraper\"]\\n\\n        This should be parsable by json.loads()\\n        \"\"\"\\n\\ndef handle_multiline_string(input_str: str) -> List[str]:\\n    # Handle multiline string as a list\\n    processed_lines = [\\n        re.sub(r\".*?(\\\\d+\\\\..+)\", r\"\\\\1\", line).strip()\\n        for line in input_str.split(\"\\\\n\")\\n        if line.strip() != \"\"\\n    ]\\n\\n    # Check if there is at least one line that starts with a digit and a period\\n    if any(re.match(r\"\\\\d+\\\\..+\", line) for line in processed_lines):\\n        return processed_lines\\n    else:\\n        # raise RuntimeError(f\"Failed to extract array from {input_str}\")\\n        print(f\"Failed to extract array from {input_str}\")\\n        return [input_str]\\n\\ndef extract_array(input_str: str) -> List[str]:\\n    regex = (\\n        r\"\\\\[\\\\s*\\\\]|\"  # Empty array check\\n        r\"(\\\\[(?:\\\\s*(?:\\\\\"(?:[^\\\\\"\\\\\\\\]|\\\\\\\\.)*\\\\\"|\\\\\\'(?:[^\\\\\\'\\\\\\\\]|\\\\\\\\.)*\\\\\\')\\\\s*,?)*\\\\s*\\\\])\"\\n    )\\n    match = re.search(regex, input_str)\\n    if match is not None:\\n        return ast.literal_eval(match[0])\\n    else:\\n        return handle_multiline_string(input_str)\\n    \\ndef remove_prefix(input_str: str) -> str:\\n    prefix_pattern = (\\n        r\"^(Task\\\\s*\\\\d*\\\\.\\\\s*|Task\\\\s*\\\\d*[-:]?\\\\s*|Step\\\\s*\\\\d*[\"\\n        r\"-:]?\\\\s*|Step\\\\s*[-:]?\\\\s*|\\\\d+\\\\.\\\\s*|\\\\d+\\\\s*[-:]?\\\\s*|^\\\\.\\\\s*|^\\\\.*)\"\\n    )\\n    return re.sub(prefix_pattern, \"\", input_str, flags=re.IGNORECASE)\\n\\n\\ndef real_tasks_filter(input_str: str) -> bool:\\n    no_task_regex = (\\n        r\"^No( (new|further|additional|extra|other))? tasks? (is )?(\"\\n        r\"required|needed|added|created|inputted).*\"\\n    )\\n    task_complete_regex = r\"^Task (complete|completed|finished|done|over|success).*\"\\n    do_nothing_regex = r\"^(\\\\s*|Do nothing(\\\\s.*)?)$\"\\n\\n    return (\\n        not re.search(no_task_regex, input_str, re.IGNORECASE)\\n        and not re.search(task_complete_regex, input_str, re.IGNORECASE)\\n        and not re.search(do_nothing_regex, input_str, re.IGNORECASE)\\n    )\\n\\ndef parse_with_handling(parser: BaseOutputParser[T], completion: str) -> T:\\n    try:\\n        return parser.parse(completion)\\n    except OutputParserException as e:\\n        raise e\\n    \\n\\ntask_output_parser = TaskOutputParser(completed_tasks=[])', 'objectives = parse_with_handling(task_output_parser, response.content)\\nprint(objectives)', '#Available experts\\nfrom typing import Any, Dict, List, Optional, Union\\nfrom typing import Type, TypedDict\\n\\nclass ExpertDescription(TypedDict):\\n    \"\"\"Representation of a callable expert\"\"\"\\n    name: str\\n    \"\"\"The name of the expert.\"\"\"\\n    description: str\\n    \"\"\"A description of the expert.\"\"\"\\n    parameters: dict[str, object]\\n    \"\"\"The parameters of the expert.\"\"\"\\n\\ndef get_expert_function(expert: Type[Expert]) -> ExpertDescription:\\n    \"\"\"A function that will return the tool\\'s function specification\"\"\"\\n    name = get_expert_name(expert)\\n    return {\\n        \"name\": name,\\n        \"description\": expert.description,\\n        \"parameters\": {\\n            \"type\": \"object\",\\n            \"properties\": {\\n                \"reasoning\": {\\n                    \"type\": \"string\",\\n                    \"description\": (\\n                        f\"Reasoning is how the task will be accomplished with the current expert. \"\\n                        \"Detail your overall plan along with any concerns you have.\"\\n                        \"Ensure this reasoning value is in the user defined langauge \"\\n                    ),\\n                },\\n                \"arg\": {\\n                    \"type\": \"string\",\\n                    \"description\": expert.arg_description,\\n                },\\n            },\\n            \"required\": [\"reasoning\", \"arg\"],\\n        },\\n    }\\n\\ndef get_expert_name(expert: Type[Expert]) -> str:\\n    return expert.name\\n\\n# def format_expert_name(expert_name: str) -> str:\\n#     return expert_name.lower()\\n\\ndef get_available_experts() -> List[Type[Expert]]:\\n    return [\\n        MetricDiscoveryInputCrew\\n    ]', \"available_experts = get_available_experts()\\nexperts = list(map(get_expert_function, available_experts))\\nexpert_descriptions = {expert['name'] : expert['description'] for expert in experts}\", 'expert_descriptions', 'experts', 'analyze_task_prompt = PromptTemplate(\\n    template=\"\"\"\\n    High level objective: \"{goal}\"\\n    Current task: \"{task}\"\\n\\n    Based on this information, use the best expert to make progress or accomplish the task entirely. Each expert has a name and description of their expertise. \\n    Select the correct expert by being smart and efficient. Ensure \"reasoning\" and only \"reasoning\" is in the english language.\\n    Following are the list of experts {experts}\\n\\n    Note you MUST select a expert and return the name of the expert.\\n    \"\"\",\\n    input_variables=[\"goal\", \"task\", \"experts\"],\\n)', 'for objective in objectives:\\n    analyze_prompt = analyze_task_prompt.format(goal=query, task=objective, experts=expert_descriptions)\\n    expert_name = llm_gpt.invoke(analyze_prompt)\\n    print(expert_name)', 'type(expert_name)', 'type(dir(expert_name))', 'type(expert_name.content)', 'dir(expert_name)', 'dir(expert_name.content)', 'expert_name.content', 'type(expert_name.content)', 'dict(expert_name.content)', 'analyze_task_prompt = PromptTemplate(\\n    template=\"\"\"\\n    High level objective: \"{goal}\"\\n    Current task: \"{task}\"\\n\\n    Based on this information, use the best expert to make progress or accomplish the task entirely. Each expert has a name and description of their expertise. \\n    Select the correct expert by being smart and efficient. Ensure \"reasoning\" and only \"reasoning\" is in the english language.\\n    Following are the list of experts {experts}\\n\\n    Note you MUST select a expert and return the name and reasoning of the expert in form of dictionary.\\n    \"\"\",\\n    input_variables=[\"goal\", \"task\", \"experts\"],\\n)', 'for objective in objectives:\\n    analyze_prompt = analyze_task_prompt.format(goal=query, task=objective, experts=expert_descriptions)\\n    expert_name = llm_gpt.invoke(analyze_prompt)\\n    print(expert_name)', 'dict(expert_name.content)', 'type(expert_name.content)', 'type(expert_name..name)', 'type(expert_name.name)', \"type(expert_name['name'])\", 'import json \\ndictionary_data = json.loads(expert_name.content)', 'dictionary_data', 'experts_info = {\"Metric\" : MetricDiscoveryInputCrew()}', 'experts_info = {\"MetricDiscovery\" : MetricDiscoveryInputCrew()}', \"expert = experts_info.get(dictionary_data['name'])\", 'type(expert)', \"import json \\nfor objective in objectives:\\n    analyze_prompt = analyze_task_prompt.format(goal=query, task=objective, experts=expert_descriptions)\\n    response = llm_service.invoke(analyze_prompt)\\n    selected_expert = json.loads(response.content)\\n    expert_object = experts_info.get(selected_expert['name'])\\n    output = expert_object.run(objective)\", \"import json \\nfor objective in objectives:\\n    analyze_prompt = analyze_task_prompt.format(goal=query, task=objective, experts=expert_descriptions)\\n    response = llm_gpt.invoke(analyze_prompt)\\n    selected_expert = json.loads(response.content)\\n    expert_object = experts_info.get(selected_expert['name'])\\n    output = expert_object.run(objective)\"], 'Out': {39: {'MetricDiscovery': 'Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.'}, 40: [{'name': 'MetricDiscovery', 'description': 'Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.', 'parameters': {'type': 'object', 'properties': {'reasoning': {'type': 'string', 'description': 'Reasoning is how the task will be accomplished with the current expert. Detail your overall plan along with any concerns you have.Ensure this reasoning value is in the user defined langauge '}, 'arg': {'type': 'string', 'description': 'Query related to metrics.'}}, 'required': ['reasoning', 'arg']}}], 43: <class 'langchain_core.messages.ai.AIMessage'>, 44: <class 'list'>, 45: <class 'str'>, 46: ['Config', '__abstractmethods__', '__add__', '__annotations__', '__class__', '__class_vars__', '__config__', '__custom_root_type__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__exclude_fields__', '__fields__', '__fields_set__', '__format__', '__ge__', '__get_validators__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__include_fields__', '__init__', '__init_subclass__', '__iter__', '__json_encoder__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__post_root_validators__', '__pre_root_validators__', '__pretty__', '__private_attributes__', '__reduce__', '__reduce_ex__', '__repr__', '__repr_args__', '__repr_name__', '__repr_str__', '__rich_repr__', '__schema_cache__', '__setattr__', '__setstate__', '__signature__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__try_update_forward_refs__', '__validators__', '_abc_impl', '_backwards_compat_tool_calls', '_calculate_keys', '_copy_and_set_values', '_decompose_class', '_enforce_dict_if_root', '_get_value', '_init_private_attributes', '_iter', 'additional_kwargs', 'construct', 'content', 'copy', 'dict', 'example', 'from_orm', 'get_lc_namespace', 'id', 'invalid_tool_calls', 'is_lc_serializable', 'json', 'lc_attributes', 'lc_id', 'lc_secrets', 'name', 'parse_file', 'parse_obj', 'parse_raw', 'pretty_print', 'pretty_repr', 'response_metadata', 'schema', 'schema_json', 'to_json', 'to_json_not_implemented', 'tool_calls', 'type', 'update_forward_refs', 'validate'], 47: ['__add__', '__class__', '__contains__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getnewargs__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mod__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__rmod__', '__rmul__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'capitalize', 'casefold', 'center', 'count', 'encode', 'endswith', 'expandtabs', 'find', 'format', 'format_map', 'index', 'isalnum', 'isalpha', 'isascii', 'isdecimal', 'isdigit', 'isidentifier', 'islower', 'isnumeric', 'isprintable', 'isspace', 'istitle', 'isupper', 'join', 'ljust', 'lower', 'lstrip', 'maketrans', 'partition', 'removeprefix', 'removesuffix', 'replace', 'rfind', 'rindex', 'rjust', 'rpartition', 'rsplit', 'rstrip', 'split', 'splitlines', 'startswith', 'strip', 'swapcase', 'title', 'translate', 'upper', 'zfill'], 48: 'Expert: MetricDiscovery\\n\\nReasoning: The task at hand is to clarify the significance of the \"vessel name\" column in a dataset, which falls under the explanation and interpretation of a specific column within a table. The MetricDiscovery expert is described as being used to answer questions related to the explanation, description, and interpretation of metrics, measures, KPIs, tables, or columns. Therefore, this expert is best suited to provide clarity on what the \"vessel name\" column represents.', 49: <class 'str'>, 54: <class 'str'>, 56: <class 'NoneType'>, 59: {'name': 'MetricDiscovery', 'reasoning': \"The 'vessel name' column in a dataset likely refers to the names of ships or boats that are part of the data being analyzed. The MetricDiscovery expert is suitable for explaining, describing, and interpreting what this column signifies within the context of the dataset, as it falls under the expertise of understanding metrics, measures, and the contents of columns in a dataset.\"}, 63: <class '__main__.MetricDiscoveryInputCrew'>}, 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x109951f50>>, 'exit': <IPython.core.autocall.ZMQExitAutocall object at 0x10995b150>, 'quit': <IPython.core.autocall.ZMQExitAutocall object at 0x10995b150>, 'open': <function open at 0x108681440>, '_': <class '__main__.MetricDiscoveryInputCrew'>, '__': {'name': 'MetricDiscovery', 'reasoning': \"The 'vessel name' column in a dataset likely refers to the names of ships or boats that are part of the data being analyzed. The MetricDiscovery expert is suitable for explaining, describing, and interpreting what this column signifies within the context of the dataset, as it falls under the expertise of understanding metrics, measures, and the contents of columns in a dataset.\"}, '___': <class 'NoneType'>, '__vsc_ipynb_file__': '/Users/k.abhishek/Documents/experiments/metric_store/metric_store_gen_ai/experiments/agent_flow_v2.ipynb', '_i': \"import json \\nfor objective in objectives:\\n    analyze_prompt = analyze_task_prompt.format(goal=query, task=objective, experts=expert_descriptions)\\n    response = llm_service.invoke(analyze_prompt)\\n    selected_expert = json.loads(response.content)\\n    expert_object = experts_info.get(selected_expert['name'])\\n    output = expert_object.run(objective)\", '_ii': 'type(expert)', '_iii': \"expert = experts_info.get(dictionary_data['name'])\", '_i1': 'a ={\"a\" : MetricDiscoveryInputCrew()}', '_i2': 'from crewai.process import Process\\nfrom typing import Any\\nclass MetricDiscoveryInputCrew(Expert):\\n  name = \"MetricDiscovery\"\\n  description = (\\n       \"Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\\n    )\\n  public_description = \"Metric discovery crew\"\\n  arg_description = \"Query related to metrics.\"\\n\\n  def __init__(self, query):\\n    self.query = query\\n    self.crew_process = self.crew_process()\\n    # self.llm = llm_gpt\\n  def crew_process(self):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    # print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, self.query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n    return crew\\n\\n  def run(self):\\n    result = self.crew_process.kickoff()\\n    return result\\n  \\n  def call(\\n        self, goal: str, task: str, input_str: str, *args: Any, **kwargs: Any\\n    ) -> str:\\n    pass', 'Process': <enum 'Process'>, 'Any': typing.Any, '_i3': '#initialize\\n#     model\\n#     environment variables\\n\\nimport sys\\nsys.path.append(\\'..\\')\\nfrom src.utils.llamaindex_retriever import LlamaIndexRetriever\\nfrom langchain.vectorstores import FAISS\\nfrom langchain.embeddings.azure_openai import AzureOpenAIEmbeddings\\nfrom langchain.embeddings.openai import OpenAIEmbeddings\\nfrom dotenv import load_dotenv\\nimport os\\nfrom langchain.chat_models import AzureChatOpenAI\\n\\ndef load_env_variables(file_path):\\n    load_dotenv(file_path)\\n    print(\"Environment variables loaded successfully!\")\\n\\nenv_file_path = \"../.env\"\\nload_env_variables = load_env_variables(env_file_path)\\nmax_tokens = 3500\\ntemperature = 0.1\\n\\n# embeddings = AzureOpenAIEmbeddings(azure_deployment=azure_deployment, openai_api_version=openai_api_version)\\nembeddings =  AzureOpenAIEmbeddings(\\n        deployment=os.getenv(\"EMB_DEPLOYMENT\"),\\n        openai_api_version=os.getenv(\"EMB_OPENAI_API_VERSION\"),\\n        model=os.getenv(\"EMB_MODEL\"),\\n        openai_api_key=os.getenv(\"EMB_OPENAI_API_KEY\"),\\n        openai_api_base=os.getenv(\"EMB_OPENAI_ENDPOINT\"),\\n        openai_api_type=os.getenv(\"EMB_API_TYPE\"),\\n    )\\n\\nllm_gpt = AzureChatOpenAI(deployment_name=os.getenv(\\'AZURE_OPENAI_DEPLOYMENT_NAME\\'), openai_api_version=os.getenv(\"OPENAI_API_VERSION\"),\\n                        openai_api_base=os.getenv(\"OPENAI_API_BASE\"), \\n                        openai_api_type= os.getenv(\"OPENAI_API_TYPE\"),\\n                        openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\\n                        max_tokens=max_tokens,\\n                        temperature=temperature)', 'sys': <module 'sys' (built-in)>, 'LlamaIndexRetriever': <class 'src.utils.llamaindex_retriever.LlamaIndexRetriever'>, 'FAISS': <class 'langchain_community.vectorstores.faiss.FAISS'>, 'AzureOpenAIEmbeddings': <class 'langchain_community.embeddings.azure_openai.AzureOpenAIEmbeddings'>, 'OpenAIEmbeddings': <class 'langchain_community.embeddings.openai.OpenAIEmbeddings'>, 'load_dotenv': <function load_dotenv at 0x12bf06c00>, 'os': <module 'os' (frozen)>, 'AzureChatOpenAI': <class 'langchain_community.chat_models.azure_openai.AzureChatOpenAI'>, 'load_env_variables': None, 'env_file_path': '../.env', 'max_tokens': 3500, 'temperature': 0.1, 'embeddings': AzureOpenAIEmbeddings(client=<openai.resources.embeddings.Embeddings object at 0x13a07c650>, async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x13988de90>, model='text-embedding-ada-002', deployment=None, openai_api_version='2023-03-15-preview', openai_api_base='https://polarisopenai.openai.azure.com//openai/deployments/text-embedding-ada-002', openai_api_type='azure', openai_proxy='', embedding_ctx_length=8191, openai_api_key='35431d6cd1874798b9ebbd6bdfbb0720', openai_organization=None, allowed_special=set(), disallowed_special='all', chunk_size=16, max_retries=2, request_timeout=None, headers=None, tiktoken_enabled=True, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, retry_min_seconds=4, retry_max_seconds=20, http_client=None, azure_endpoint=None, azure_ad_token=None, azure_ad_token_provider=None, validate_base_url=True), 'llm_gpt': AzureChatOpenAI(callbacks=[<crewai.utilities.token_counter_callback.TokenCalcHandler object at 0x13aa30210>], client=<openai.resources.chat.completions.Completions object at 0x13a114190>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x1396fae50>, temperature=0.1, openai_api_key='43b8528ab70d48359744cd0165a1167e', openai_api_base='https://polariseastus2.openai.azure.com/openai/deployments/gpt4-turbo', openai_proxy='', max_tokens=3500, openai_api_version='2023-07-01-preview', openai_api_type='azure'), '_i4': '#define utils\\nfrom src.utils.cube_semantic_custom import CubeSemanticLoader\\ndef fetch_cube_metadata(*args, **kwargs):\\n    try:\\n        # # Load document from Cube meta api\\n        loader = CubeSemanticLoader(os.getenv(\"CUBE_API_URL\"), os.getenv(\"CUBE_TOKEN\"), False)\\n        documents = loader.load()\\n        # to_json()\\n        return documents\\n    except Exception as e:\\n        # Handle exceptions gracefully and return an error response\\n        print(\"Error in fetching metadata from cube: \" + str(e))\\n        return 0\\n\\ndef create_vector_store(documents, local_vector_store_path, *args, **kwargs):\\n    print(\"Loaded documents: \" + str(documents))\\n    vectorstore = FAISS.from_documents(documents, embeddings)\\n    vectorstore.save_local(local_vector_store_path)\\n    print(\"Vector store created and saved successfully!\")\\n\\ndef load_vector_store(vector_store_path, embeddings, *args, **kwargs):\\n    # Load the vector store from the local file system\\n    vectorstore = FAISS.load_local(vector_store_path, embeddings, allow_dangerous_deserialization=True)\\n    print(\"Vector store loaded successfully!\")\\n    \\n    return vectorstore', 'CubeSemanticLoader': <class 'src.utils.cube_semantic_custom.CubeSemanticLoader'>, 'fetch_cube_metadata': <function fetch_cube_metadata at 0x13a119120>, 'create_vector_store': <function create_vector_store at 0x13a1193a0>, 'load_vector_store': <function load_vector_store at 0x13a119300>, '_i5': '#load existing vector store\\nvector_store_path = \"/Users/k.abhishek/Documents/experiments/metric_store/metric_store_gen_ai/data/vector_store/cube_meta_faiss_index\"\\nvectorstore = load_vector_store(vector_store_path, embeddings)', 'vector_store_path': '/Users/k.abhishek/Documents/experiments/metric_store/metric_store_gen_ai/data/vector_store/cube_meta_faiss_index', 'vectorstore': <langchain_community.vectorstores.faiss.FAISS object at 0x13a08f950>, '_i6': 'import json\\nfrom crewai import Agent, Task, Crew\\nfrom langchain.tools import tool\\nfrom src.utils.llamaindex_retriever import LlamaIndexRetriever\\nfrom typing import Optional, Type\\nfrom langchain.callbacks.manager import (\\n    AsyncCallbackManagerForToolRun,\\n    CallbackManagerForToolRun,\\n)\\n# Import things that are needed generically\\nfrom langchain.pydantic_v1 import BaseModel, Field\\n# from langchain.tools import BaseTool, StructuredTool, tool\\nfrom crewai_tools import BaseTool\\n\\n\\ndef get_similar_documents_faiss(query, max_number_documents=3):\\n  vectorstore = FAISS.load_local(vector_store_path, embeddings, allow_dangerous_deserialization=True)\\n  docs = vectorstore.similarity_search_with_relevance_scores(query, max_number_documents)\\n  relevant_documents = []\\n  for doc in docs:\\n      doc = doc[0]\\n      meta = {\\'text\\':doc.page_content, \\'table_metadata\\': doc.metadata}\\n      relevant_documents.append(meta)\\n  return relevant_documents\\n\\ndef get_similar_documents(query, max_number_documents=3):\\n    return get_similar_documents_faiss(query, max_number_documents)\\n\\n\\nclass QueryInput(BaseModel):\\n    query: str = Field(description=\"should be enquiry query\")\\n\\nclass TerminationHandler(CallbackManagerForToolRun):\\n    pass\\n\\nclass RephraseInputQuery(BaseTool):\\n    name:str = \"rephrase_input_query\"\\n    description :str = \"Useful to rephrase the query to capture the intent of the user regarding metric information\"\\n    args_schema: Type[BaseModel] = QueryInput\\n\\n    def _run(\\n        self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None\\n    ) -> str:\\n        \"\"\"Use the tool.\"\"\"\\n        metric_description = self.rephrase_input_query(query)\\n        return metric_description\\n\\n    async def _arun(\\n        self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None\\n    ) -> str:\\n        \"\"\"Use the tool asynchronously.\"\"\"\\n        raise NotImplementedError(\"custom_search does not support async\")\\n    \\n    \\n    def rephrase_input_query(self, query, *args, **kwargs):\\n        agent = Agent(\\n                role=\\'Intent Capturer\\',\\n                goal=\\n                \\'Rephrasing the query to capture the intent of the user regarding metric information\\',\\n                backstory=\\n                \"You are an expert to understand the user\\'s intent and rephrase the query to capture the intent of the user accurately.\",\\n                llm = llm_gpt,\\n                allow_delegation=False)\\n        task = Task(\\n                agent=agent,\\n                description=\\n                f\\'Rephrase the query to capture the intent of the user regarding metric information. The query is {query}. Donot add any noise to the response\\',\\n                expected_output=\"some string\",\\n        \\n            )\\n        extracted_metrics = task.execute()\\n\\n        return extracted_metrics\\n    \\n\\n    \\nclass MetricDiscovery(BaseTool):\\n    name :str = \"metric_discovery\"\\n    description:str = \"\"\"Useful for general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\"\"\\n    args_schema: Type[BaseModel] = QueryInput\\n\\n    def _run(\\n        self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None\\n    ) -> str:\\n        \"\"\"Use the tool.\"\"\"\\n        metric_description = self.metric_discovery(query)\\n        return metric_description\\n\\n    async def _arun(\\n        self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None\\n    ) -> str:\\n        \"\"\"Use the tool asynchronously.\"\"\"\\n        raise NotImplementedError(\"custom_search does not support async\")\\n    \\n    \\n    def metric_discovery(self, query, *args, **kwargs):\\n        \"\"\"Useful for general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\"\"\\n        relevant_documents = get_similar_documents(query)\\n        agent = Agent(\\n                role=\\'Data Analyst Assistant\\',\\n                goal=\\n                \\'Empower users to understand and utilize data effectively. This includes helping them discover relevant metrics, interpreting their meaning\\',\\n                backstory=\\n                \"The primary purpose is to bridge the gap between raw data and user comprehension, fostering a data-driven culture within the organization.\",\\n                llm = llm_gpt,\\n                allow_delegation=False)  \\n        \\n        task = Task(\\n                agent=agent,\\n                description=\\n                \"\"\" You are responding to  question {metric_description} with answer from the Metadata provided to you as {relevant_documents}}.\\n                    Strictly answer the question with the information present in metadata only.\\n                    Respond with \"Sorry, the query is out of scope.\" if the answer is not present in metadata and terminate further reasoning and prcoess.\\n                    \"\"\",\\n                expected_output=\"some string\",\\n        \\n            )\\n        output = task.execute()\\n\\n        return output', 'json': <module 'json' from '/Users/k.abhishek/anaconda3/envs/agentgpt/lib/python3.11/json/__init__.py'>, 'Agent': <class 'crewai.agent.Agent'>, 'Task': <class 'crewai.task.Task'>, 'Crew': <class 'crewai.crew.Crew'>, 'tool': <function tool at 0x109f0a160>, 'Optional': typing.Optional, 'Type': typing.Type, 'AsyncCallbackManagerForToolRun': <class 'langchain_core.callbacks.manager.AsyncCallbackManagerForToolRun'>, 'CallbackManagerForToolRun': <class 'langchain_core.callbacks.manager.CallbackManagerForToolRun'>, 'BaseModel': <class 'pydantic.v1.main.BaseModel'>, 'Field': <function Field at 0x112094e00>, 'BaseTool': <class 'crewai_tools.tools.base_tool.BaseTool'>, 'get_similar_documents_faiss': <function get_similar_documents_faiss at 0x13a11afc0>, 'get_similar_documents': <function get_similar_documents at 0x13a11af20>, 'QueryInput': <class '__main__.QueryInput'>, 'TerminationHandler': <class '__main__.TerminationHandler'>, 'RephraseInputQuery': <class '__main__.RephraseInputQuery'>, 'MetricDiscovery': <class '__main__.MetricDiscovery'>, '_i7': '# def check_termination(task_output):\\n#     agent = Agent(\\n#                 role=\\'Determine query completion\\',\\n#                 goal=\\n#                 \\'Given task output, determine termination of crew workflow\\',\\n#                 backstory=\\n#                 \"Given user query request from user determine if no more new task is needed to be executed\",\\n#                 llm = llm_gpt,\\n#                 allow_delegation=False)\\n#     task = Task(\\n#                 agent=agent,\\n#                 description=\\n#                 f\\'Given task output, if the query is completed and the task result determines that the query is out of scope then terminate the workflow or else the required query is satisfied. Following is the task result {task_output}\\',\\n#                 expected_output=\"some string\",\\n        \\n#             )\\n#     termination_status = task.execute()\\n#     return termination_status\\nclass MetricDiscoveryTasks():\\n  def metric_isolation(self, agent, query):\\n    return Task(description=(f\"\"\"\\n        Rephrase the query to capture the intent of the user regarding metric information. The query is {query}. Donot add any noise to the response.\\n        {self.__tip_section()}\"\"\"),\\n      agent=agent,\\n      expected_output=\"Reformatted query to capture the intent of the user regarding metric information.\",\\n      # callback=callback_function,\\n    )\\n  \\n  def metric_discovery(self, agent):\\n    return Task(description=(f\"\"\"\\n        Answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\\n        {self.__tip_section()}\"\"\"),\\n      agent=agent,\\n      expected_output=\"If relevant metric exists in metadata, provide the answer. Else, respond with \\'Sorry, the query is out of scope.\\' and terminate process.\",\\n      # callback=callback_function,\\n    )\\n  def __tip_section(self):\\n    return \"If you do your BEST WORK, I\\'ll give you a $10,000 commission!\"\\n  \\n  ', 'MetricDiscoveryTasks': <class '__main__.MetricDiscoveryTasks'>, '_i8': 'class MetricDiscoveryAgent():\\n  def user_intent_capture(self):\\n    return Agent(\\n      role=\\'Intent Capturer\\',\\n      goal=\\n      \\'Rephrasing the query to capture the intent of the user regarding metric information\\',\\n      backstory=\\n      \"You are an expert to understand the user\\'s intent and rephrase the query to capture the intent of the user accurately.\",\\n      verbose=True,\\n      tools=[\\n        RephraseInputQuery()\\n      ],\\n      llm = llm_gpt,\\n    )\\n  def discover_metric_info(self):\\n    return Agent(\\n     role=\\'Data Analyst Assistant\\',\\n      goal=\\n      \\'Empower users to understand and utilize data effectively. This includes helping them discover relevant metrics, interpreting their meaning\\',\\n      backstory=\\n      \"The primary purpose is to bridge the gap between raw data and user comprehension, fostering a data-driven culture within the organization.\",\\n      llm = llm_gpt,\\n      verbose=True,\\n      tools=[\\n        MetricDiscovery()\\n      ],\\n    )', 'MetricDiscoveryAgent': <class '__main__.MetricDiscoveryAgent'>, '_i9': 'def after_task_callback(output):\\n  # Perform actions after the task, \\n  # for example, logging or updating agent state\\n  \\n  print(f\"Agent completed task with result: {output}\")\\n\\n# Assigning the function to task_callback\\ntask_callback = after_task_callback', 'after_task_callback': <function after_task_callback at 0x13a8f4220>, 'task_callback': <function after_task_callback at 0x13a8f4220>, '_i10': 'def test_callback():\\n        # Accessing local variables\\n        print(\"Local variables:\", locals())\\n        \\n        # Accessing global variables\\n        print(\"Global variables:\", globals())    \\n        \\n        # Accessing built-in variables\\n        print(\"Built-in variables:\", dir(__builtins__))\\n        after_task_callback(\"output\")\\n  ', 'test_callback': <function test_callback at 0x13a8f7380>, '_i11': 'from abc import ABC, abstractmethod\\nclass Expert(ABC):\\n    name: str = \"\"\\n    description: str = \"\"\\n    public_description: str = \"\"\\n    arg_description: str = \"The argument to the function.\"\\n\\n    @abstractmethod\\n    def call(\\n        self,\\n        goal: str,\\n        task: str,\\n        input_str: str,\\n    ) -> str:\\n        pass', 'ABC': <class 'abc.ABC'>, 'abstractmethod': <function abstractmethod at 0x106abe480>, 'Expert': <class '__main__.Expert'>, '_i12': 'from crewai.process import Process\\nfrom typing import Any\\nclass MetricDiscoveryInputCrew(Expert):\\n  name = \"MetricDiscovery\"\\n  description = (\\n       \"Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\\n    )\\n  public_description = \"Metric discovery crew\"\\n  arg_description = \"Query related to metrics.\"\\n\\n  def __init__(self, query):\\n    self.query = query\\n    self.crew_process = self.crew_process()\\n    # self.llm = llm_gpt\\n  def crew_process(self):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    # print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, self.query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n    return crew\\n\\n  def run(self):\\n    result = self.crew_process.kickoff()\\n    return result\\n  \\n  def call(\\n        self, goal: str, task: str, input_str: str, *args: Any, **kwargs: Any\\n    ) -> str:\\n    pass', 'MetricDiscoveryInputCrew': <class '__main__.MetricDiscoveryInputCrew'>, '_i13': 'a ={\"a\" : MetricDiscoveryInputCrew()}', '_i14': 'from crewai.process import Process\\nfrom typing import Any\\nclass MetricDiscoveryInputCrew(Expert):\\n  name = \"MetricDiscovery\"\\n  description = (\\n       \"Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\\n    )\\n  public_description = \"Metric discovery crew\"\\n  arg_description = \"Query related to metrics.\"\\n\\n  def __init__(self):\\n    # self.query = query\\n    self.crew_process = self.crew_process()\\n    # self.llm = llm_gpt\\n  def crew_process(self, query: str):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    # print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n    return crew\\n\\n  def run(self, query: str):\\n    result = self.crew_process.kickoff()\\n    return result\\n  \\n  def call(\\n        self, goal: str, task: str, input_str: str, *args: Any, **kwargs: Any\\n    ) -> str:\\n    pass', '_i15': 'a ={\"a\" : MetricDiscoveryInputCrew()}', '_i16': 'from crewai.process import Process\\nfrom typing import Any\\nclass MetricDiscoveryInputCrew(Expert):\\n  name = \"MetricDiscovery\"\\n  description = (\\n       \"Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\\n    )\\n  public_description = \"Metric discovery crew\"\\n  arg_description = \"Query related to metrics.\"\\n\\n  def crew_process(self, query: str):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    # print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n    return crew\\n  \\n\\n  def run(self, query: str):\\n    result = self.crew_process.kickoff(query)\\n    return result\\n  \\n  def call(\\n        self, goal: str, task: str, input_str: str, *args: Any, **kwargs: Any\\n    ) -> str:\\n    pass', '_i17': 'a ={\"a\" : MetricDiscoveryInputCrew()}', 'a': {'a': <__main__.MetricDiscoveryInputCrew object at 0x13a968110>}, '_i18': 'objectives = parse_with_handling(task_output_parser, response.content)\\nprint(objectives)', '_i19': 'intents = {\\n    \"discover_metrics\": \"Identify relevant metrics based on user objectives. (e.g., Suggest metrics to measure customer satisfaction)\",\\n    \"fetch_data\": \"Retrieve data for a specific metric the user has already identified.\",\\n    # \"analyze_trends\": \"Analyze trends within the fetched data to provide deeper insights.\",\\n    \"interpret_metrics\": \"Explain the meaning of the data in the context of the user\\'s objective.\",\\n    \"understand_metrics\": \"Provide information about a metric\\'s definition and purpose.\"\\n}\\nprompt_template = PromptTemplate.from_template(\"\"\"You are an intelligent assistant focused on helping users with metrics and data. Your primary goal is to break down user queries ({query}) into a concise list of high-level objectives.\\n\\n**Intents:**\\n\\n{intents}\\n\\nImportant Notes:\\n* Alignment with Intents: The new objectives should strictly align with the provided intents.\\n* Prioritize Clarity & Efficiency:  Minimize the number of objectives and maintain a high-level overview. \\n* Direct Match: If the query aligns perfectly with one intent (e.g., \"What\\'s the current customer churn rate?\" for Fetch Data), don\\'t alter it.\\n* Outside Scope: If the query falls outside these intents (e.g., \"Book a flight\"), return an empty list.\\n* Focus on User Need: Keep responses clear and concise, avoiding unnecessary information. \\n* Output Format:  Respond with a list containing the breakdown of objectives.\\n\\n**Here\\'s the user query: {query}\\n\\nWhat is the high-level breakdown of objectives for this query?\\n\"\"\")\\n\\n\\n\\n# Format the intent descriptions for the prompt\\nformatted_intents = \"\\\\n\".join([f\"* {intent_name}: {description}\" for intent_name, description in intents.items()])\\nquery = \"What dose the vessel name column represents?\"\\n# Insert formatted intents into the prompt template\\ncompleted_prompt = prompt_template.format(intents=formatted_intents, query=query)\\n# Use the completed prompt with the AzureChatOpenAI model\\nresponse = llm_gpt.invoke(completed_prompt)\\n\\nprint(response)', 'intents': {'discover_metrics': 'Identify relevant metrics based on user objectives. (e.g., Suggest metrics to measure customer satisfaction)', 'fetch_data': 'Retrieve data for a specific metric the user has already identified.', 'interpret_metrics': \"Explain the meaning of the data in the context of the user's objective.\", 'understand_metrics': \"Provide information about a metric's definition and purpose.\"}, '_i20': 'query = \"What is the most popular feature used by our paid subscribers\"\\n# formatted_query = input(\\n#     dedent(\"\"\"\\n#       {What is the most popular feature used by our paid subscribers}\\n#     \"\"\"))\\n# print(formatted_query)\\ncrew = MetricDiscoveryInputCrew()\\nresult = crew.run(query)', 'query': 'What dose the vessel name column represents?', 'crew': <__main__.MetricDiscoveryInputCrew object at 0x13aa42150>, '_i21': 'from crewai.process import Process\\nfrom typing import Any\\nclass MetricDiscoveryInputCrew(Expert):\\n  name = \"MetricDiscovery\"\\n  description = (\\n       \"Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\\n    )\\n  public_description = \"Metric discovery crew\"\\n  arg_description = \"Query related to metrics.\"\\n\\n  def crew_process(self, query: str):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    # print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n    return crew\\n  \\n\\n  def run(self, query: str):\\n    crew = self.crew_process.kickoff(query)\\n    result = crew.kickoff()\\n    return result\\n  \\n  def call(\\n        self, goal: str, task: str, input_str: str, *args: Any, **kwargs: Any\\n    ) -> str:\\n    pass', '_i22': 'query = \"What is the most popular feature used by our paid subscribers\"\\n# formatted_query = input(\\n#     dedent(\"\"\"\\n#       {What is the most popular feature used by our paid subscribers}\\n#     \"\"\"))\\n# print(formatted_query)\\ncrew = MetricDiscoveryInputCrew()\\nresult = crew.run(query)', '_i23': 'from crewai.process import Process\\nfrom typing import Any\\nclass MetricDiscoveryInputCrew(Expert):\\n  name = \"MetricDiscovery\"\\n  description = (\\n       \"Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\\n    )\\n  public_description = \"Metric discovery crew\"\\n  arg_description = \"Query related to metrics.\"\\n\\n  def crew_process(self, query: str):\\n    agents = MetricDiscoveryAgent()\\n    tasks = MetricDiscoveryTasks()\\n    # print(agents)\\n    # print(tasks)\\n    user_intent_capture_agent = agents.user_intent_capture()\\n    discover_metric_info_agent = agents.discover_metric_info()\\n    # print(metric_isolator_agent)\\n    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\\n    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, query)\\n    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\\n    \\n    # print(\"Metric_isolator_task\", metric_isolator_task)\\n    crew = Crew(\\n      agents=[\\n        user_intent_capture_agent,\\n        discover_metric_info_agent,\\n      ],\\n      tasks=[\\n        metric_isolator_task,\\n        metric_discover_task\\n      ],\\n      verbose=False,\\n      process=Process.sequential,\\n      step_callback=test_callback()\\n    )\\n    return crew\\n  \\n\\n  def run(self, query: str):\\n    crew = self.crew_process(query)\\n    result = crew.kickoff()\\n    return result\\n  \\n  def call(\\n        self, goal: str, task: str, input_str: str, *args: Any, **kwargs: Any\\n    ) -> str:\\n    pass', '_i24': 'query = \"What is the most popular feature used by our paid subscribers\"\\n# formatted_query = input(\\n#     dedent(\"\"\"\\n#       {What is the most popular feature used by our paid subscribers}\\n#     \"\"\"))\\n# print(formatted_query)\\ncrew = MetricDiscoveryInputCrew()\\nresult = crew.run(query)', 'result': 'Sorry, the query is out of scope.', '_i25': 'print(result)', '_i26': 'type(result)\\nprint(result)', '_i27': 'print(type(result))\\nprint(result)', '_i28': 'intents = {\\n    \"discover_metrics\": \"Identify relevant metrics based on user objectives. (e.g., Suggest metrics to measure customer satisfaction)\",\\n    \"fetch_data\": \"Retrieve data for a specific metric the user has already identified.\",\\n    # \"analyze_trends\": \"Analyze trends within the fetched data to provide deeper insights.\",\\n    \"interpret_metrics\": \"Explain the meaning of the data in the context of the user\\'s objective.\",\\n    \"understand_metrics\": \"Provide information about a metric\\'s definition and purpose.\"\\n}\\nprompt_template = PromptTemplate.from_template(\"\"\"You are an intelligent assistant focused on helping users with metrics and data. Your primary goal is to break down user queries ({query}) into a concise list of high-level objectives.\\n\\n**Intents:**\\n\\n{intents}\\n\\nImportant Notes:\\n* Alignment with Intents: The new objectives should strictly align with the provided intents.\\n* Prioritize Clarity & Efficiency:  Minimize the number of objectives and maintain a high-level overview. \\n* Direct Match: If the query aligns perfectly with one intent (e.g., \"What\\'s the current customer churn rate?\" for Fetch Data), don\\'t alter it.\\n* Outside Scope: If the query falls outside these intents (e.g., \"Book a flight\"), return an empty list.\\n* Focus on User Need: Keep responses clear and concise, avoiding unnecessary information. \\n* Output Format:  Respond with a list containing the breakdown of objectives.\\n\\n**Here\\'s the user query: {query}\\n\\nWhat is the high-level breakdown of objectives for this query?\\n\"\"\")\\n\\n\\n\\n# Format the intent descriptions for the prompt\\nformatted_intents = \"\\\\n\".join([f\"* {intent_name}: {description}\" for intent_name, description in intents.items()])\\nquery = \"What dose the vessel name column represents?\"\\n# Insert formatted intents into the prompt template\\ncompleted_prompt = prompt_template.format(intents=formatted_intents, query=query)\\n# Use the completed prompt with the AzureChatOpenAI model\\nresponse = llm_gpt.invoke(completed_prompt)\\n\\nprint(response)', '_i29': 'from langchain import PromptTemplate\\n# Define the prompt template\\nprompt_template = PromptTemplate.from_template(\"\"\"\\nYou are an intelligent assistant whose only and only goal is to break down user\\'s query {query} into high-level, smaller objectives in form of list. You serve as an interface between users and a database containing various metrics/KPIs/measures.\\nStrictly note that it is not necessary to break down the query in all the following intents. The intents are only for reference. If the query is straightforward and aligns with any one of the intent, then do not change the query. \\nTry to minimize the number of objectives and keep them as high-level as possible. \\nEach smaller objective should strictly fall into one of the following intent:\\nDiscover Metrics:** If you\\'d like to measure something specific, I can identify relevant metrics. For example, are you interested in suggest some metrics based on objective?\\nFetch Data:** If you already know the metric you\\'re interested in, I can retrieve the data from the database.\\nInterpret Metrics:** Once you have the data, I can explain what it means in the context of your objective. \\nUnderstand Metrics:** If you\\'re unsure about a metric\\'s definition or purpose, I can provide more information.\\n\\nDon\\'t add noise to the response.\\nRespond with a list.\\nHowever, if the query involves something else entirely, like action outside current intents, give empty list.\"\"\")\\ndef complete(prompt, user_query):\\n  \"\"\"\\n  Completes the prompt with the user objective.\\n\\n  Args:\\n      prompt: The prompt template.\\n      user_objective: The user\\'s objective.\\n\\n  Returns:\\n      The completed prompt.\\n  \"\"\"\\n  return prompt.format(query=user_query)\\n\\n# Example usage\\nuser_objective = \"What are the top three metrics that indicate the overall health of our business?\"\\ncompleted_prompt = complete(prompt_template, user_objective)\\n\\n# Use the completed prompt with the AzureChatOpenAI model\\nresponse = llm_gpt.invoke(completed_prompt)\\n\\nprint(response)', 'PromptTemplate': <class 'langchain_core.prompts.prompt.PromptTemplate'>, 'prompt_template': PromptTemplate(input_variables=['intents', 'query'], template='You are an intelligent assistant focused on helping users with metrics and data. Your primary goal is to break down user queries ({query}) into a concise list of high-level objectives.\\n\\n**Intents:**\\n\\n{intents}\\n\\nImportant Notes:\\n* Alignment with Intents: The new objectives should strictly align with the provided intents.\\n* Prioritize Clarity & Efficiency:  Minimize the number of objectives and maintain a high-level overview. \\n* Direct Match: If the query aligns perfectly with one intent (e.g., \"What\\'s the current customer churn rate?\" for Fetch Data), don\\'t alter it.\\n* Outside Scope: If the query falls outside these intents (e.g., \"Book a flight\"), return an empty list.\\n* Focus on User Need: Keep responses clear and concise, avoiding unnecessary information. \\n* Output Format:  Respond with a list containing the breakdown of objectives.\\n\\n**Here\\'s the user query: {query}\\n\\nWhat is the high-level breakdown of objectives for this query?\\n'), 'complete': <function complete at 0x13a9d0cc0>, 'user_objective': 'What are the top three metrics that indicate the overall health of our business?', 'completed_prompt': 'You are an intelligent assistant focused on helping users with metrics and data. Your primary goal is to break down user queries (What dose the vessel name column represents?) into a concise list of high-level objectives.\\n\\n**Intents:**\\n\\n* discover_metrics: Identify relevant metrics based on user objectives. (e.g., Suggest metrics to measure customer satisfaction)\\n* fetch_data: Retrieve data for a specific metric the user has already identified.\\n* interpret_metrics: Explain the meaning of the data in the context of the user\\'s objective.\\n* understand_metrics: Provide information about a metric\\'s definition and purpose.\\n\\nImportant Notes:\\n* Alignment with Intents: The new objectives should strictly align with the provided intents.\\n* Prioritize Clarity & Efficiency:  Minimize the number of objectives and maintain a high-level overview. \\n* Direct Match: If the query aligns perfectly with one intent (e.g., \"What\\'s the current customer churn rate?\" for Fetch Data), don\\'t alter it.\\n* Outside Scope: If the query falls outside these intents (e.g., \"Book a flight\"), return an empty list.\\n* Focus on User Need: Keep responses clear and concise, avoiding unnecessary information. \\n* Output Format:  Respond with a list containing the breakdown of objectives.\\n\\n**Here\\'s the user query: What dose the vessel name column represents?\\n\\nWhat is the high-level breakdown of objectives for this query?\\n', 'response': AIMessage(content='{\\n    \"name\": \"MetricDiscovery\",\\n    \"reasoning\": \"The \\'vessel name\\' column in a dataset likely refers to the names of ships or maritime vessels that are relevant to the data being analyzed. The MetricDiscovery expert is suitable for explaining, interpreting, and providing a description of what this column signifies within the context of the dataset, as it falls under the expertise of understanding metrics, measures, and the interpretation of table columns.\"\\n}', response_metadata={'token_usage': {'completion_tokens': 91, 'prompt_tokens': 169, 'total_tokens': 260}, 'model_name': 'gpt-4', 'system_fingerprint': 'fp_811936bd4f', 'finish_reason': 'stop', 'logprobs': None}, id='run-5a732590-7a7e-4532-9696-04ada0d59613-0'), '_i30': 'intents = {\\n    \"discover_metrics\": \"Identify relevant metrics based on user objectives. (e.g., Suggest metrics to measure customer satisfaction)\",\\n    \"fetch_data\": \"Retrieve data for a specific metric the user has already identified.\",\\n    # \"analyze_trends\": \"Analyze trends within the fetched data to provide deeper insights.\",\\n    \"interpret_metrics\": \"Explain the meaning of the data in the context of the user\\'s objective.\",\\n    \"understand_metrics\": \"Provide information about a metric\\'s definition and purpose.\"\\n}\\nprompt_template = PromptTemplate.from_template(\"\"\"You are an intelligent assistant focused on helping users with metrics and data. Your primary goal is to break down user queries ({query}) into a concise list of high-level objectives.\\n\\n**Intents:**\\n\\n{intents}\\n\\nImportant Notes:\\n* Alignment with Intents: The new objectives should strictly align with the provided intents.\\n* Prioritize Clarity & Efficiency:  Minimize the number of objectives and maintain a high-level overview. \\n* Direct Match: If the query aligns perfectly with one intent (e.g., \"What\\'s the current customer churn rate?\" for Fetch Data), don\\'t alter it.\\n* Outside Scope: If the query falls outside these intents (e.g., \"Book a flight\"), return an empty list.\\n* Focus on User Need: Keep responses clear and concise, avoiding unnecessary information. \\n* Output Format:  Respond with a list containing the breakdown of objectives.\\n\\n**Here\\'s the user query: {query}\\n\\nWhat is the high-level breakdown of objectives for this query?\\n\"\"\")\\n\\n\\n\\n# Format the intent descriptions for the prompt\\nformatted_intents = \"\\\\n\".join([f\"* {intent_name}: {description}\" for intent_name, description in intents.items()])\\nquery = \"What dose the vessel name column represents?\"\\n# Insert formatted intents into the prompt template\\ncompleted_prompt = prompt_template.format(intents=formatted_intents, query=query)\\n# Use the completed prompt with the AzureChatOpenAI model\\nresponse = llm_gpt.invoke(completed_prompt)\\n\\nprint(response)', 'formatted_intents': \"* discover_metrics: Identify relevant metrics based on user objectives. (e.g., Suggest metrics to measure customer satisfaction)\\n* fetch_data: Retrieve data for a specific metric the user has already identified.\\n* interpret_metrics: Explain the meaning of the data in the context of the user's objective.\\n* understand_metrics: Provide information about a metric's definition and purpose.\", '_i31': 'import ast\\nimport re\\nfrom typing import List, TypeVar\\nfrom langchain.schema import BaseOutputParser, OutputParserException\\nT = TypeVar(\"T\")\\n\\nclass TaskOutputParser(BaseOutputParser[List[str]]):\\n    \"\"\"\\n    Extension of LangChain\\'s BaseOutputParser\\n    Responsible for parsing task creation output into a list of task strings\\n    \"\"\"\\n\\n    completed_tasks: List[str] = []\\n\\n    def __init__(self, *, completed_tasks: List[str]):\\n        super().__init__()\\n        self.completed_tasks = completed_tasks\\n\\n    def parse(self, text: str) -> List[str]:\\n        try:\\n            array_str = extract_array(text)\\n            all_tasks = [\\n                remove_prefix(task) for task in array_str if real_tasks_filter(task)\\n            ]\\n            return [task for task in all_tasks if task not in self.completed_tasks]\\n        except Exception as e:\\n            msg = f\"Failed to parse tasks from completion \\'{text}\\'. Exception: {e}\"\\n            raise OutputParserException(msg)\\n\\n    def get_format_instructions(self) -> str:\\n        return \"\"\"\\n        The response should be a JSON array of strings. Example:\\n\\n        [\"Search the web for NBA news\", \"Write some code to build a web scraper\"]\\n\\n        This should be parsable by json.loads()\\n        \"\"\"\\n\\ndef handle_multiline_string(input_str: str) -> List[str]:\\n    # Handle multiline string as a list\\n    processed_lines = [\\n        re.sub(r\".*?(\\\\d+\\\\..+)\", r\"\\\\1\", line).strip()\\n        for line in input_str.split(\"\\\\n\")\\n        if line.strip() != \"\"\\n    ]\\n\\n    # Check if there is at least one line that starts with a digit and a period\\n    if any(re.match(r\"\\\\d+\\\\..+\", line) for line in processed_lines):\\n        return processed_lines\\n    else:\\n        # raise RuntimeError(f\"Failed to extract array from {input_str}\")\\n        print(f\"Failed to extract array from {input_str}\")\\n        return [input_str]\\n\\ndef extract_array(input_str: str) -> List[str]:\\n    regex = (\\n        r\"\\\\[\\\\s*\\\\]|\"  # Empty array check\\n        r\"(\\\\[(?:\\\\s*(?:\\\\\"(?:[^\\\\\"\\\\\\\\]|\\\\\\\\.)*\\\\\"|\\\\\\'(?:[^\\\\\\'\\\\\\\\]|\\\\\\\\.)*\\\\\\')\\\\s*,?)*\\\\s*\\\\])\"\\n    )\\n    match = re.search(regex, input_str)\\n    if match is not None:\\n        return ast.literal_eval(match[0])\\n    else:\\n        return handle_multiline_string(input_str)\\n    \\ndef remove_prefix(input_str: str) -> str:\\n    prefix_pattern = (\\n        r\"^(Task\\\\s*\\\\d*\\\\.\\\\s*|Task\\\\s*\\\\d*[-:]?\\\\s*|Step\\\\s*\\\\d*[\"\\n        r\"-:]?\\\\s*|Step\\\\s*[-:]?\\\\s*|\\\\d+\\\\.\\\\s*|\\\\d+\\\\s*[-:]?\\\\s*|^\\\\.\\\\s*|^\\\\.*)\"\\n    )\\n    return re.sub(prefix_pattern, \"\", input_str, flags=re.IGNORECASE)\\n\\n\\ndef real_tasks_filter(input_str: str) -> bool:\\n    no_task_regex = (\\n        r\"^No( (new|further|additional|extra|other))? tasks? (is )?(\"\\n        r\"required|needed|added|created|inputted).*\"\\n    )\\n    task_complete_regex = r\"^Task (complete|completed|finished|done|over|success).*\"\\n    do_nothing_regex = r\"^(\\\\s*|Do nothing(\\\\s.*)?)$\"\\n\\n    return (\\n        not re.search(no_task_regex, input_str, re.IGNORECASE)\\n        and not re.search(task_complete_regex, input_str, re.IGNORECASE)\\n        and not re.search(do_nothing_regex, input_str, re.IGNORECASE)\\n    )\\n\\ndef parse_with_handling(parser: BaseOutputParser[T], completion: str) -> T:\\n    try:\\n        return parser.parse(completion)\\n    except OutputParserException as e:\\n        raise e\\n    \\n\\ntask_output_parser = TaskOutputParser(completed_tasks=[])', 'ast': <module 'ast' from '/Users/k.abhishek/anaconda3/envs/agentgpt/lib/python3.11/ast.py'>, 're': <module 're' from '/Users/k.abhishek/anaconda3/envs/agentgpt/lib/python3.11/re/__init__.py'>, 'List': typing.List, 'TypeVar': <class 'typing.TypeVar'>, 'BaseOutputParser': <class 'langchain_core.output_parsers.base.BaseOutputParser'>, 'OutputParserException': <class 'langchain_core.exceptions.OutputParserException'>, 'T': ~T, 'TaskOutputParser': <class '__main__.TaskOutputParser'>, 'handle_multiline_string': <function handle_multiline_string at 0x13a9d36a0>, 'extract_array': <function extract_array at 0x13ab31800>, 'remove_prefix': <function remove_prefix at 0x13ab32980>, 'real_tasks_filter': <function real_tasks_filter at 0x13ab32200>, 'parse_with_handling': <function parse_with_handling at 0x13ab32b60>, 'task_output_parser': TaskOutputParser(), '_i32': 'objectives = parse_with_handling(task_output_parser, response.content)\\nprint(objectives)', 'objectives': ['- understand_metrics: Clarify what the \"vessel name\" column signifies in the dataset.'], '_i33': 'analyze_task_prompt = PromptTemplate(\\n    template=\"\"\"\\n    High level objective: \"{goal}\"\\n    Current task: \"{task}\"\\n\\n    Based on this information, use the best expert to make progress or accomplish the task entirely. Each expert has a name and description of their expertise. \\n    Select the correct expert by being smart and efficient. Ensure \"reasoning\" and only \"reasoning\" is in the english language.\\n    Following are the list of experts {experts}\\n\\n    Note you MUST select a expert and return the name of the expert.\\n    \"\"\",\\n    input_variables=[\"goal\", \"task\", \"experts\"],\\n)', 'analyze_task_prompt': PromptTemplate(input_variables=['experts', 'goal', 'task'], template='\\n    High level objective: \"{goal}\"\\n    Current task: \"{task}\"\\n\\n    Based on this information, use the best expert to make progress or accomplish the task entirely. Each expert has a name and description of their expertise. \\n    Select the correct expert by being smart and efficient. Ensure \"reasoning\" and only \"reasoning\" is in the english language.\\n    Following are the list of experts {experts}\\n\\n    Note you MUST select a expert and return the name and reasoning of the expert in form of dictionary.\\n    '), '_i34': 'for objective in objectives:\\n    analyze_prompt = analyze_task_prompt.format(goal=query, task=objective, experts=expert_descriptions)\\n    expert_name = llm_gpt.invoke(analyze_prompt)\\n    print(expert_name)', 'objective': '- understand_metrics: Clarify what the \"vessel name\" column signifies in the dataset.', '_i35': 'import ast\\nimport re\\nfrom typing import List, TypeVar\\nfrom langchain.schema import BaseOutputParser, OutputParserException\\nT = TypeVar(\"T\")\\n\\nclass TaskOutputParser(BaseOutputParser[List[str]]):\\n    \"\"\"\\n    Extension of LangChain\\'s BaseOutputParser\\n    Responsible for parsing task creation output into a list of task strings\\n    \"\"\"\\n\\n    completed_tasks: List[str] = []\\n\\n    def __init__(self, *, completed_tasks: List[str]):\\n        super().__init__()\\n        self.completed_tasks = completed_tasks\\n\\n    def parse(self, text: str) -> List[str]:\\n        try:\\n            array_str = extract_array(text)\\n            all_tasks = [\\n                remove_prefix(task) for task in array_str if real_tasks_filter(task)\\n            ]\\n            return [task for task in all_tasks if task not in self.completed_tasks]\\n        except Exception as e:\\n            msg = f\"Failed to parse tasks from completion \\'{text}\\'. Exception: {e}\"\\n            raise OutputParserException(msg)\\n\\n    def get_format_instructions(self) -> str:\\n        return \"\"\"\\n        The response should be a JSON array of strings. Example:\\n\\n        [\"Search the web for NBA news\", \"Write some code to build a web scraper\"]\\n\\n        This should be parsable by json.loads()\\n        \"\"\"\\n\\ndef handle_multiline_string(input_str: str) -> List[str]:\\n    # Handle multiline string as a list\\n    processed_lines = [\\n        re.sub(r\".*?(\\\\d+\\\\..+)\", r\"\\\\1\", line).strip()\\n        for line in input_str.split(\"\\\\n\")\\n        if line.strip() != \"\"\\n    ]\\n\\n    # Check if there is at least one line that starts with a digit and a period\\n    if any(re.match(r\"\\\\d+\\\\..+\", line) for line in processed_lines):\\n        return processed_lines\\n    else:\\n        # raise RuntimeError(f\"Failed to extract array from {input_str}\")\\n        print(f\"Failed to extract array from {input_str}\")\\n        return [input_str]\\n\\ndef extract_array(input_str: str) -> List[str]:\\n    regex = (\\n        r\"\\\\[\\\\s*\\\\]|\"  # Empty array check\\n        r\"(\\\\[(?:\\\\s*(?:\\\\\"(?:[^\\\\\"\\\\\\\\]|\\\\\\\\.)*\\\\\"|\\\\\\'(?:[^\\\\\\'\\\\\\\\]|\\\\\\\\.)*\\\\\\')\\\\s*,?)*\\\\s*\\\\])\"\\n    )\\n    match = re.search(regex, input_str)\\n    if match is not None:\\n        return ast.literal_eval(match[0])\\n    else:\\n        return handle_multiline_string(input_str)\\n    \\ndef remove_prefix(input_str: str) -> str:\\n    prefix_pattern = (\\n        r\"^(Task\\\\s*\\\\d*\\\\.\\\\s*|Task\\\\s*\\\\d*[-:]?\\\\s*|Step\\\\s*\\\\d*[\"\\n        r\"-:]?\\\\s*|Step\\\\s*[-:]?\\\\s*|\\\\d+\\\\.\\\\s*|\\\\d+\\\\s*[-:]?\\\\s*|^\\\\.\\\\s*|^\\\\.*)\"\\n    )\\n    return re.sub(prefix_pattern, \"\", input_str, flags=re.IGNORECASE)\\n\\n\\ndef real_tasks_filter(input_str: str) -> bool:\\n    no_task_regex = (\\n        r\"^No( (new|further|additional|extra|other))? tasks? (is )?(\"\\n        r\"required|needed|added|created|inputted).*\"\\n    )\\n    task_complete_regex = r\"^Task (complete|completed|finished|done|over|success).*\"\\n    do_nothing_regex = r\"^(\\\\s*|Do nothing(\\\\s.*)?)$\"\\n\\n    return (\\n        not re.search(no_task_regex, input_str, re.IGNORECASE)\\n        and not re.search(task_complete_regex, input_str, re.IGNORECASE)\\n        and not re.search(do_nothing_regex, input_str, re.IGNORECASE)\\n    )\\n\\ndef parse_with_handling(parser: BaseOutputParser[T], completion: str) -> T:\\n    try:\\n        return parser.parse(completion)\\n    except OutputParserException as e:\\n        raise e\\n    \\n\\ntask_output_parser = TaskOutputParser(completed_tasks=[])', '_i36': 'objectives = parse_with_handling(task_output_parser, response.content)\\nprint(objectives)', '_i37': '#Available experts\\nfrom typing import Any, Dict, List, Optional, Union\\nfrom typing import Type, TypedDict\\n\\nclass ExpertDescription(TypedDict):\\n    \"\"\"Representation of a callable expert\"\"\"\\n    name: str\\n    \"\"\"The name of the expert.\"\"\"\\n    description: str\\n    \"\"\"A description of the expert.\"\"\"\\n    parameters: dict[str, object]\\n    \"\"\"The parameters of the expert.\"\"\"\\n\\ndef get_expert_function(expert: Type[Expert]) -> ExpertDescription:\\n    \"\"\"A function that will return the tool\\'s function specification\"\"\"\\n    name = get_expert_name(expert)\\n    return {\\n        \"name\": name,\\n        \"description\": expert.description,\\n        \"parameters\": {\\n            \"type\": \"object\",\\n            \"properties\": {\\n                \"reasoning\": {\\n                    \"type\": \"string\",\\n                    \"description\": (\\n                        f\"Reasoning is how the task will be accomplished with the current expert. \"\\n                        \"Detail your overall plan along with any concerns you have.\"\\n                        \"Ensure this reasoning value is in the user defined langauge \"\\n                    ),\\n                },\\n                \"arg\": {\\n                    \"type\": \"string\",\\n                    \"description\": expert.arg_description,\\n                },\\n            },\\n            \"required\": [\"reasoning\", \"arg\"],\\n        },\\n    }\\n\\ndef get_expert_name(expert: Type[Expert]) -> str:\\n    return expert.name\\n\\n# def format_expert_name(expert_name: str) -> str:\\n#     return expert_name.lower()\\n\\ndef get_available_experts() -> List[Type[Expert]]:\\n    return [\\n        MetricDiscoveryInputCrew\\n    ]', 'Dict': typing.Dict, 'Union': typing.Union, 'TypedDict': <function TypedDict at 0x106ca0ae0>, 'ExpertDescription': <class '__main__.ExpertDescription'>, 'get_expert_function': <function get_expert_function at 0x13a9d2b60>, 'get_expert_name': <function get_expert_name at 0x13a9d14e0>, 'get_available_experts': <function get_available_experts at 0x13a9d19e0>, '_i38': \"available_experts = get_available_experts()\\nexperts = list(map(get_expert_function, available_experts))\\nexpert_descriptions = {expert['name'] : expert['description'] for expert in experts}\", 'available_experts': [<class '__main__.MetricDiscoveryInputCrew'>], 'experts': [{'name': 'MetricDiscovery', 'description': 'Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.', 'parameters': {'type': 'object', 'properties': {'reasoning': {'type': 'string', 'description': 'Reasoning is how the task will be accomplished with the current expert. Detail your overall plan along with any concerns you have.Ensure this reasoning value is in the user defined langauge '}, 'arg': {'type': 'string', 'description': 'Query related to metrics.'}}, 'required': ['reasoning', 'arg']}}], 'expert_descriptions': {'MetricDiscovery': 'Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.'}, '_i39': 'expert_descriptions', '_39': {'MetricDiscovery': 'Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.'}, '_i40': 'experts', '_40': [{'name': 'MetricDiscovery', 'description': 'Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.', 'parameters': {'type': 'object', 'properties': {'reasoning': {'type': 'string', 'description': 'Reasoning is how the task will be accomplished with the current expert. Detail your overall plan along with any concerns you have.Ensure this reasoning value is in the user defined langauge '}, 'arg': {'type': 'string', 'description': 'Query related to metrics.'}}, 'required': ['reasoning', 'arg']}}], '_i41': 'analyze_task_prompt = PromptTemplate(\\n    template=\"\"\"\\n    High level objective: \"{goal}\"\\n    Current task: \"{task}\"\\n\\n    Based on this information, use the best expert to make progress or accomplish the task entirely. Each expert has a name and description of their expertise. \\n    Select the correct expert by being smart and efficient. Ensure \"reasoning\" and only \"reasoning\" is in the english language.\\n    Following are the list of experts {experts}\\n\\n    Note you MUST select a expert and return the name of the expert.\\n    \"\"\",\\n    input_variables=[\"goal\", \"task\", \"experts\"],\\n)', '_i42': 'for objective in objectives:\\n    analyze_prompt = analyze_task_prompt.format(goal=query, task=objective, experts=expert_descriptions)\\n    expert_name = llm_gpt.invoke(analyze_prompt)\\n    print(expert_name)', 'analyze_prompt': '\\n    High level objective: \"What dose the vessel name column represents?\"\\n    Current task: \"- understand_metrics: Clarify what the \"vessel name\" column signifies in the dataset.\"\\n\\n    Based on this information, use the best expert to make progress or accomplish the task entirely. Each expert has a name and description of their expertise. \\n    Select the correct expert by being smart and efficient. Ensure \"reasoning\" and only \"reasoning\" is in the english language.\\n    Following are the list of experts {\\'MetricDiscovery\\': \\'Use this to answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\\'}\\n\\n    Note you MUST select a expert and return the name and reasoning of the expert in form of dictionary.\\n    ', 'expert_name': AIMessage(content='{\\n    \"name\": \"MetricDiscovery\",\\n    \"reasoning\": \"The \\'vessel name\\' column in a dataset likely refers to the names of ships or boats that are part of the data being analyzed. The MetricDiscovery expert is suitable for explaining, describing, and interpreting what this column signifies within the context of the dataset, as it falls under the expertise of understanding metrics, measures, and the contents of columns in a dataset.\"\\n}', response_metadata={'token_usage': {'completion_tokens': 89, 'prompt_tokens': 169, 'total_tokens': 258}, 'model_name': 'gpt-4', 'system_fingerprint': 'fp_811936bd4f', 'finish_reason': 'stop', 'logprobs': None}, id='run-6361f59a-b256-438f-a79d-fc34f7babc0a-0'), '_i43': 'type(expert_name)', '_43': <class 'langchain_core.messages.ai.AIMessage'>, '_i44': 'type(dir(expert_name))', '_44': <class 'list'>, '_i45': 'type(expert_name.content)', '_45': <class 'str'>, '_i46': 'dir(expert_name)', '_46': ['Config', '__abstractmethods__', '__add__', '__annotations__', '__class__', '__class_vars__', '__config__', '__custom_root_type__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__exclude_fields__', '__fields__', '__fields_set__', '__format__', '__ge__', '__get_validators__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__include_fields__', '__init__', '__init_subclass__', '__iter__', '__json_encoder__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__post_root_validators__', '__pre_root_validators__', '__pretty__', '__private_attributes__', '__reduce__', '__reduce_ex__', '__repr__', '__repr_args__', '__repr_name__', '__repr_str__', '__rich_repr__', '__schema_cache__', '__setattr__', '__setstate__', '__signature__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__try_update_forward_refs__', '__validators__', '_abc_impl', '_backwards_compat_tool_calls', '_calculate_keys', '_copy_and_set_values', '_decompose_class', '_enforce_dict_if_root', '_get_value', '_init_private_attributes', '_iter', 'additional_kwargs', 'construct', 'content', 'copy', 'dict', 'example', 'from_orm', 'get_lc_namespace', 'id', 'invalid_tool_calls', 'is_lc_serializable', 'json', 'lc_attributes', 'lc_id', 'lc_secrets', 'name', 'parse_file', 'parse_obj', 'parse_raw', 'pretty_print', 'pretty_repr', 'response_metadata', 'schema', 'schema_json', 'to_json', 'to_json_not_implemented', 'tool_calls', 'type', 'update_forward_refs', 'validate'], '_i47': 'dir(expert_name.content)', '_47': ['__add__', '__class__', '__contains__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getnewargs__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mod__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__rmod__', '__rmul__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'capitalize', 'casefold', 'center', 'count', 'encode', 'endswith', 'expandtabs', 'find', 'format', 'format_map', 'index', 'isalnum', 'isalpha', 'isascii', 'isdecimal', 'isdigit', 'isidentifier', 'islower', 'isnumeric', 'isprintable', 'isspace', 'istitle', 'isupper', 'join', 'ljust', 'lower', 'lstrip', 'maketrans', 'partition', 'removeprefix', 'removesuffix', 'replace', 'rfind', 'rindex', 'rjust', 'rpartition', 'rsplit', 'rstrip', 'split', 'splitlines', 'startswith', 'strip', 'swapcase', 'title', 'translate', 'upper', 'zfill'], '_i48': 'expert_name.content', '_48': 'Expert: MetricDiscovery\\n\\nReasoning: The task at hand is to clarify the significance of the \"vessel name\" column in a dataset, which falls under the explanation and interpretation of a specific column within a table. The MetricDiscovery expert is described as being used to answer questions related to the explanation, description, and interpretation of metrics, measures, KPIs, tables, or columns. Therefore, this expert is best suited to provide clarity on what the \"vessel name\" column represents.', '_i49': 'type(expert_name.content)', '_49': <class 'str'>, '_i50': 'dict(expert_name.content)', '_i51': 'analyze_task_prompt = PromptTemplate(\\n    template=\"\"\"\\n    High level objective: \"{goal}\"\\n    Current task: \"{task}\"\\n\\n    Based on this information, use the best expert to make progress or accomplish the task entirely. Each expert has a name and description of their expertise. \\n    Select the correct expert by being smart and efficient. Ensure \"reasoning\" and only \"reasoning\" is in the english language.\\n    Following are the list of experts {experts}\\n\\n    Note you MUST select a expert and return the name and reasoning of the expert in form of dictionary.\\n    \"\"\",\\n    input_variables=[\"goal\", \"task\", \"experts\"],\\n)', '_i52': 'for objective in objectives:\\n    analyze_prompt = analyze_task_prompt.format(goal=query, task=objective, experts=expert_descriptions)\\n    expert_name = llm_gpt.invoke(analyze_prompt)\\n    print(expert_name)', '_i53': 'dict(expert_name.content)', '_i54': 'type(expert_name.content)', '_54': <class 'str'>, '_i55': 'type(expert_name..name)', '_i56': 'type(expert_name.name)', '_56': <class 'NoneType'>, '_i57': \"type(expert_name['name'])\", '_i58': 'import json \\ndictionary_data = json.loads(expert_name.content)', 'dictionary_data': {'name': 'MetricDiscovery', 'reasoning': \"The 'vessel name' column in a dataset likely refers to the names of ships or boats that are part of the data being analyzed. The MetricDiscovery expert is suitable for explaining, describing, and interpreting what this column signifies within the context of the dataset, as it falls under the expertise of understanding metrics, measures, and the contents of columns in a dataset.\"}, '_i59': 'dictionary_data', '_59': {'name': 'MetricDiscovery', 'reasoning': \"The 'vessel name' column in a dataset likely refers to the names of ships or boats that are part of the data being analyzed. The MetricDiscovery expert is suitable for explaining, describing, and interpreting what this column signifies within the context of the dataset, as it falls under the expertise of understanding metrics, measures, and the contents of columns in a dataset.\"}, '_i60': 'experts_info = {\"Metric\" : MetricDiscoveryInputCrew()}', 'experts_info': {'MetricDiscovery': <__main__.MetricDiscoveryInputCrew object at 0x13a869190>}, '_i61': 'experts_info = {\"MetricDiscovery\" : MetricDiscoveryInputCrew()}', '_i62': \"expert = experts_info.get(dictionary_data['name'])\", 'expert': <__main__.MetricDiscoveryInputCrew object at 0x13a869190>, '_i63': 'type(expert)', '_63': <class '__main__.MetricDiscoveryInputCrew'>, '_i64': \"import json \\nfor objective in objectives:\\n    analyze_prompt = analyze_task_prompt.format(goal=query, task=objective, experts=expert_descriptions)\\n    response = llm_service.invoke(analyze_prompt)\\n    selected_expert = json.loads(response.content)\\n    expert_object = experts_info.get(selected_expert['name'])\\n    output = expert_object.run(objective)\", '_i65': \"import json \\nfor objective in objectives:\\n    analyze_prompt = analyze_task_prompt.format(goal=query, task=objective, experts=expert_descriptions)\\n    response = llm_gpt.invoke(analyze_prompt)\\n    selected_expert = json.loads(response.content)\\n    expert_object = experts_info.get(selected_expert['name'])\\n    output = expert_object.run(objective)\", 'selected_expert': {'name': 'MetricDiscovery', 'reasoning': \"The 'vessel name' column in a dataset likely refers to the names of ships or maritime vessels that are relevant to the data being analyzed. The MetricDiscovery expert is suitable for explaining, interpreting, and providing a description of what this column signifies within the context of the dataset, as it falls under the expertise of understanding metrics, measures, and the interpretation of table columns.\"}, 'expert_object': <__main__.MetricDiscoveryInputCrew object at 0x13a869190>}\n",
      "Built-in variables: ['ArithmeticError', 'AssertionError', 'AttributeError', 'BaseException', 'BaseExceptionGroup', 'BlockingIOError', 'BrokenPipeError', 'BufferError', 'BytesWarning', 'ChildProcessError', 'ConnectionAbortedError', 'ConnectionError', 'ConnectionRefusedError', 'ConnectionResetError', 'DeprecationWarning', 'EOFError', 'Ellipsis', 'EncodingWarning', 'EnvironmentError', 'Exception', 'ExceptionGroup', 'False', 'FileExistsError', 'FileNotFoundError', 'FloatingPointError', 'FutureWarning', 'GeneratorExit', 'IOError', 'ImportError', 'ImportWarning', 'IndentationError', 'IndexError', 'InterruptedError', 'IsADirectoryError', 'KeyError', 'KeyboardInterrupt', 'LookupError', 'MemoryError', 'ModuleNotFoundError', 'NameError', 'None', 'NotADirectoryError', 'NotImplemented', 'NotImplementedError', 'OSError', 'OverflowError', 'PendingDeprecationWarning', 'PermissionError', 'ProcessLookupError', 'RecursionError', 'ReferenceError', 'ResourceWarning', 'RuntimeError', 'RuntimeWarning', 'StopAsyncIteration', 'StopIteration', 'SyntaxError', 'SyntaxWarning', 'SystemError', 'SystemExit', 'TabError', 'TimeoutError', 'True', 'TypeError', 'UnboundLocalError', 'UnicodeDecodeError', 'UnicodeEncodeError', 'UnicodeError', 'UnicodeTranslateError', 'UnicodeWarning', 'UserWarning', 'ValueError', 'Warning', 'ZeroDivisionError', '__IPYTHON__', '__build_class__', '__debug__', '__doc__', '__import__', '__loader__', '__name__', '__package__', '__pybind11_internals_v4_clang_libcpp_cxxabi1002__', '__spec__', 'abs', 'aiter', 'all', 'anext', 'any', 'ascii', 'bin', 'bool', 'breakpoint', 'bytearray', 'bytes', 'callable', 'chr', 'classmethod', 'compile', 'complex', 'copyright', 'credits', 'delattr', 'dict', 'dir', 'display', 'divmod', 'enumerate', 'eval', 'exec', 'execfile', 'filter', 'float', 'format', 'frozenset', 'get_ipython', 'getattr', 'globals', 'hasattr', 'hash', 'help', 'hex', 'id', 'input', 'int', 'isinstance', 'issubclass', 'iter', 'len', 'license', 'list', 'locals', 'map', 'max', 'memoryview', 'min', 'next', 'object', 'oct', 'open', 'ord', 'pow', 'print', 'property', 'range', 'repr', 'reversed', 'round', 'runfile', 'set', 'setattr', 'slice', 'sorted', 'staticmethod', 'str', 'sum', 'super', 'tuple', 'type', 'vars', 'zip']\n",
      "Agent completed task with result: output\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: The user wants to understand the meaning of the \"vessel name\" column in a dataset. I need to rephrase this query to focus specifically on the metric information aspect of the \"vessel name\" column.\n",
      "\n",
      "Action: rephrase_input_query\n",
      "\n",
      "Action Input: {\"query\": \"Clarify what the 'vessel name' column signifies in the dataset.\"}\n",
      "\u001b[0m\u001b[95m \n",
      "\n",
      "The 'vessel name' column in the dataset represents the unique identifier or title assigned to each ship or maritime vehicle included in the information set.\n",
      "\u001b[00m\n",
      "\u001b[32;1m\u001b[1;3mThought: I now know the final answer\n",
      "\n",
      "Final Answer: The 'vessel name' column in the dataset represents the unique identifier or title assigned to each ship or maritime vehicle included in the information set.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: To provide the user with the necessary information, I need to use the metric_discovery tool to find out if there is a relevant metric or description related to the 'vessel name' column in the dataset.\n",
      "\n",
      "Action: metric_discovery\n",
      "\n",
      "Action Input: {\"query\": \"vessel name\"}\n",
      "\u001b[0m\u001b[95m \n",
      "\n",
      "Sorry, the query is out of scope.\n",
      "\u001b[00m\n",
      "\u001b[32;1m\u001b[1;3mThought: Since the metric discovery tool returned a response indicating that the query is out of scope, it means there is no relevant metric or description available in the metadata for the 'vessel name' column in the dataset.\n",
      "\n",
      "Final Answer: Sorry, the query is out of scope.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "for objective in objectives:\n",
    "    analyze_prompt = analyze_task_prompt.format(goal=query, task=objective, experts=expert_descriptions)\n",
    "    response = llm_service.invoke(analyze_prompt)\n",
    "    selected_expert = json.loads(response.content)\n",
    "    expert_object = experts_info.get(selected_expert['name'])\n",
    "    output = expert_object.run(objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorry, the query is out of scope.\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
