{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/k.abhishek/anaconda3/envs/agentgpt/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `AzureOpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import AzureOpenAIEmbeddings`.\n",
      "  warn_deprecated(\n",
      "/Users/k.abhishek/anaconda3/envs/agentgpt/lib/python3.11/site-packages/langchain_community/embeddings/azure_openai.py:113: UserWarning: As of openai>=1.0.0, Azure endpoints should be specified via the `azure_endpoint` param not `openai_api_base` (or alias `base_url`). Updating `openai_api_base` from https://polarisopenai.openai.azure.com/ to https://polarisopenai.openai.azure.com//openai.\n",
      "  warnings.warn(\n",
      "/Users/k.abhishek/anaconda3/envs/agentgpt/lib/python3.11/site-packages/langchain_community/embeddings/azure_openai.py:120: UserWarning: As of openai>=1.0.0, if `deployment` (or alias `azure_deployment`) is specified then `openai_api_base` (or alias `base_url`) should not be. Instead use `deployment` (or alias `azure_deployment`) and `azure_endpoint`.\n",
      "  warnings.warn(\n",
      "/Users/k.abhishek/anaconda3/envs/agentgpt/lib/python3.11/site-packages/langchain_community/embeddings/azure_openai.py:128: UserWarning: As of openai>=1.0.0, if `openai_api_base` (or alias `base_url`) is specified it is expected to be of the form https://example-resource.azure.openai.com/openai/deployments/example-deployment. Updating https://polarisopenai.openai.azure.com/ to https://polarisopenai.openai.azure.com//openai.\n",
      "  warnings.warn(\n",
      "/Users/k.abhishek/anaconda3/envs/agentgpt/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `AzureChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import AzureChatOpenAI`.\n",
      "  warn_deprecated(\n",
      "/Users/k.abhishek/anaconda3/envs/agentgpt/lib/python3.11/site-packages/langchain_community/chat_models/azure_openai.py:167: UserWarning: As of openai>=1.0.0, Azure endpoints should be specified via the `azure_endpoint` param not `openai_api_base` (or alias `base_url`). Updating `openai_api_base` from https://polariseastus2.openai.azure.com/ to https://polariseastus2.openai.azure.com/openai.\n",
      "  warnings.warn(\n",
      "/Users/k.abhishek/anaconda3/envs/agentgpt/lib/python3.11/site-packages/langchain_community/chat_models/azure_openai.py:174: UserWarning: As of openai>=1.0.0, if `deployment_name` (or alias `azure_deployment`) is specified then `openai_api_base` (or alias `base_url`) should not be. Instead use `deployment_name` (or alias `azure_deployment`) and `azure_endpoint`.\n",
      "  warnings.warn(\n",
      "/Users/k.abhishek/anaconda3/envs/agentgpt/lib/python3.11/site-packages/langchain_community/chat_models/azure_openai.py:182: UserWarning: As of openai>=1.0.0, if `openai_api_base` (or alias `base_url`) is specified it is expected to be of the form https://example-resource.azure.openai.com/openai/deployments/example-deployment. Updating https://polariseastus2.openai.azure.com/ to https://polariseastus2.openai.azure.com/openai.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#initialize\n",
    "#     model\n",
    "#     environment variables\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.utils.llamaindex_retriever import LlamaIndexRetriever\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.azure_openai import AzureOpenAIEmbeddings\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "\n",
    "def load_env_variables(file_path):\n",
    "    load_dotenv(file_path)\n",
    "    print(\"Environment variables loaded successfully!\")\n",
    "\n",
    "env_file_path = \"../.env\"\n",
    "load_env_variables = load_env_variables(env_file_path)\n",
    "max_tokens = 3500\n",
    "temperature = 0.1\n",
    "\n",
    "# embeddings = AzureOpenAIEmbeddings(azure_deployment=azure_deployment, openai_api_version=openai_api_version)\n",
    "embeddings =  AzureOpenAIEmbeddings(\n",
    "        deployment=os.getenv(\"EMB_DEPLOYMENT\"),\n",
    "        openai_api_version=os.getenv(\"EMB_OPENAI_API_VERSION\"),\n",
    "        model=os.getenv(\"EMB_MODEL\"),\n",
    "        openai_api_key=os.getenv(\"EMB_OPENAI_API_KEY\"),\n",
    "        openai_api_base=os.getenv(\"EMB_OPENAI_ENDPOINT\"),\n",
    "        openai_api_type=os.getenv(\"EMB_API_TYPE\"),\n",
    "    )\n",
    "\n",
    "llm_gpt = AzureChatOpenAI(deployment_name=os.getenv('AZURE_OPENAI_DEPLOYMENT_NAME'), openai_api_version=os.getenv(\"OPENAI_API_VERSION\"),\n",
    "                        openai_api_base=os.getenv(\"OPENAI_API_BASE\"), \n",
    "                        openai_api_type= os.getenv(\"OPENAI_API_TYPE\"),\n",
    "                        openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "                        max_tokens=max_tokens,\n",
    "                        temperature=temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define utils\n",
    "from src.utils.cube_semantic_custom import CubeSemanticLoader\n",
    "def fetch_cube_metadata(*args, **kwargs):\n",
    "    try:\n",
    "        # # Load document from Cube meta api\n",
    "        loader = CubeSemanticLoader(os.getenv(\"CUBE_API_URL\"), os.getenv(\"CUBE_TOKEN\"), False)\n",
    "        documents = loader.load()\n",
    "        # to_json()\n",
    "        return documents\n",
    "    except Exception as e:\n",
    "        # Handle exceptions gracefully and return an error response\n",
    "        print(\"Error in fetching metadata from cube: \" + str(e))\n",
    "        return 0\n",
    "\n",
    "def create_vector_store(documents, local_vector_store_path, *args, **kwargs):\n",
    "    print(\"Loaded documents: \" + str(documents))\n",
    "    vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "    vectorstore.save_local(local_vector_store_path)\n",
    "    print(\"Vector store created and saved successfully!\")\n",
    "\n",
    "def load_vector_store(vector_store_path, embeddings, *args, **kwargs):\n",
    "    # Load the vector store from the local file system\n",
    "    vectorstore = FAISS.load_local(vector_store_path, embeddings, allow_dangerous_deserialization=True)\n",
    "    print(\"Vector store loaded successfully!\")\n",
    "    \n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "#load existing vector store\n",
    "vector_store_path = \"/Users/k.abhishek/Documents/experiments/metric_store/metric_store_gen_ai/data/vector_store/cube_meta_faiss_index\"\n",
    "vectorstore = load_vector_store(vector_store_path, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tools "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from crewai import Agent, Task, Crew\n",
    "from langchain.tools import tool\n",
    "from src.utils.llamaindex_retriever import LlamaIndexRetriever\n",
    "from typing import Optional, Type\n",
    "from langchain.callbacks.manager import (\n",
    "    AsyncCallbackManagerForToolRun,\n",
    "    CallbackManagerForToolRun,\n",
    ")\n",
    "# Import things that are needed generically\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "# from langchain.tools import BaseTool, StructuredTool, tool\n",
    "from crewai_tools import BaseTool\n",
    "\n",
    "\n",
    "def get_similar_documents_faiss(query, max_number_documents=3):\n",
    "  vectorstore = FAISS.load_local(vector_store_path, embeddings, allow_dangerous_deserialization=True)\n",
    "  docs = vectorstore.similarity_search_with_relevance_scores(query, max_number_documents)\n",
    "  relevant_documents = []\n",
    "  for doc in docs:\n",
    "      doc = doc[0]\n",
    "      meta = {'text':doc.page_content, 'table_metadata': doc.metadata}\n",
    "      relevant_documents.append(meta)\n",
    "  return relevant_documents\n",
    "\n",
    "def get_similar_documents(query, max_number_documents=3):\n",
    "    return get_similar_documents_faiss(query, max_number_documents)\n",
    "\n",
    "\n",
    "class QueryInput(BaseModel):\n",
    "    query: str = Field(description=\"should be enquiry query\")\n",
    "\n",
    "\n",
    "class RephraseInputQuery(BaseTool):\n",
    "    name:str = \"rephrase_input_query\"\n",
    "    description :str = \"Useful to rephrase the query to capture the intent of the user regarding metric information\"\n",
    "    args_schema: Type[BaseModel] = QueryInput\n",
    "\n",
    "    def _run(\n",
    "        self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool.\"\"\"\n",
    "        metric_description = self.rephrase_input_query(query)\n",
    "        return metric_description\n",
    "\n",
    "    async def _arun(\n",
    "        self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"custom_search does not support async\")\n",
    "    \n",
    "    \n",
    "    def rephrase_input_query(self, query, *args, **kwargs):\n",
    "        agent = Agent(\n",
    "                role='Intent Capturer',\n",
    "                goal=\n",
    "                'Rephrasing the query to capture the intent of the user regarding metric information',\n",
    "                backstory=\n",
    "                \"You are an expert to understand the user's intent and rephrase the query to capture the intent of the user accurately.\",\n",
    "                llm = llm_gpt,\n",
    "                allow_delegation=False)\n",
    "        task = Task(\n",
    "                agent=agent,\n",
    "                description=\n",
    "                f'Rephrase the query to capture the intent of the user regarding metric information. The query is {query}. Donot add any noise to the response',\n",
    "                expected_output=\"some string\",\n",
    "        \n",
    "            )\n",
    "        extracted_metrics = task.execute()\n",
    "\n",
    "        return extracted_metrics\n",
    "    \n",
    "\n",
    "    \n",
    "class MetricDiscovery(BaseTool):\n",
    "    name :str = \"metric_discovery\"\n",
    "    description:str = \"\"\"Useful for general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\"\"\n",
    "    args_schema: Type[BaseModel] = QueryInput\n",
    "\n",
    "    def _run(\n",
    "        self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool.\"\"\"\n",
    "        metric_description = self.metric_discovery(query)\n",
    "        return metric_description\n",
    "\n",
    "    async def _arun(\n",
    "        self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"custom_search does not support async\")\n",
    "    \n",
    "    \n",
    "    def metric_discovery(self, query, *args, **kwargs):\n",
    "        \"\"\"Useful for general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\"\"\n",
    "        relevant_documents = get_similar_documents(query)\n",
    "        agent = Agent(\n",
    "                role='Data Analyst Assistant',\n",
    "                goal=\n",
    "                'Empower users to understand and utilize data effectively. This includes helping them discover relevant metrics, interpreting their meaning',\n",
    "                backstory=\n",
    "                \"The primary purpose is to bridge the gap between raw data and user comprehension, fostering a data-driven culture within the organization.\",\n",
    "                llm = llm_gpt,\n",
    "                allow_delegation=False)  \n",
    "        \n",
    "        task = Task(\n",
    "                agent=agent,\n",
    "                description=\n",
    "                \"\"\" You are responding to  question {metric_description} with answer from the Metadata provided to you as {relevant_documents}}.\n",
    "                    Strictly answer the question with the information present in metadata only.\n",
    "                    Respond with \"Sorry, the query is out of scope.\" if the answer is not present in metadata and terminate further reasoning and prcoess.\n",
    "                    \"\"\",\n",
    "                expected_output=\"some string\",\n",
    "        \n",
    "            )\n",
    "        output = task.execute()\n",
    "\n",
    "        return output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_termination(task_output):\n",
    "    agent = Agent(\n",
    "                role='Determine query completion',\n",
    "                goal=\n",
    "                'Given task output, determine termination of crew workflow',\n",
    "                backstory=\n",
    "                \"Given user query request from user determine if no more new task is needed to be executed\",\n",
    "                llm = llm_gpt,\n",
    "                allow_delegation=False)\n",
    "    task = Task(\n",
    "                agent=agent,\n",
    "                description=\n",
    "                f'Given task output, if the query is completed and the task result determines that the query is out of scope then terminate the workflow or else the required query is satisfied. Following is the task result {task_output}',\n",
    "                expected_output=\"some string\",\n",
    "        \n",
    "            )\n",
    "    termination_status = task.execute()\n",
    "    return termination_status\n",
    "class MetricDiscoveryTasks():\n",
    "  def metric_isolation(self, agent, query):\n",
    "    return Task(description=(f\"\"\"\n",
    "        Rephrase the query to capture the intent of the user regarding metric information. The query is {query}. Donot add any noise to the response.\n",
    "        {self.__tip_section()}\"\"\"),\n",
    "      agent=agent,\n",
    "      expected_output=\"Reformatted query to capture the intent of the user regarding metric information.\",\n",
    "    )\n",
    "  \n",
    "  def metric_discovery(self, agent):\n",
    "    return Task(description=(f\"\"\"\n",
    "        Answer the general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\n",
    "        {self.__tip_section()}\"\"\"),\n",
    "      agent=agent,\n",
    "      expected_output=\"If relevant metric exists in metadata, provide the answer. Else, respond with 'Sorry, the query is out of scope.' and terminate process.\",\n",
    "    )\n",
    "  def __tip_section(self):\n",
    "    return \"If you do your BEST WORK, I'll give you a $10,000 commission!\"\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricDiscoveryAgent():\n",
    "  def user_intent_capture(self):\n",
    "    return Agent(\n",
    "      role='Intent Capturer',\n",
    "      goal=\n",
    "      'Rephrasing the query to capture the intent of the user regarding metric information',\n",
    "      backstory=\n",
    "      \"You are an expert to understand the user's intent and rephrase the query to capture the intent of the user accurately.\",\n",
    "      verbose=True,\n",
    "      tools=[\n",
    "        RephraseInputQuery()\n",
    "      ],\n",
    "      llm = llm_gpt,\n",
    "    )\n",
    "  def discover_metric_info(self):\n",
    "    return Agent(\n",
    "     role='Data Analyst Assistant',\n",
    "      goal=\n",
    "      'Empower users to understand and utilize data effectively. This includes helping them discover relevant metrics, interpreting their meaning',\n",
    "      backstory=\n",
    "      \"The primary purpose is to bridge the gap between raw data and user comprehension, fostering a data-driven culture within the organization.\",\n",
    "      llm = llm_gpt,\n",
    "      verbose=True,\n",
    "      tools=[\n",
    "        MetricDiscovery()\n",
    "      ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def after_task_callback(output):\n",
    "  # Perform actions after the task, \n",
    "  # for example, logging or updating agent state\n",
    "  \n",
    "  print(f\"Agent completed task with result: {output}\")\n",
    "\n",
    "# Assigning the function to task_callback\n",
    "task_callback = after_task_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai.process import Process\n",
    "class MetricDiscoveryInputCrew:\n",
    "  def __init__(self, query):\n",
    "    self.query = query\n",
    "    # self.llm = llm_gpt\n",
    "\n",
    "  def run(self):\n",
    "    agents = MetricDiscoveryAgent()\n",
    "    tasks = MetricDiscoveryTasks()\n",
    "    # print(agents)\n",
    "    print(tasks)\n",
    "    user_intent_capture_agent = agents.user_intent_capture()\n",
    "    discover_metric_info_agent = agents.discover_metric_info()\n",
    "    # print(metric_isolator_agent)\n",
    "    # metric_isolator_task = tasks.metric_isolation(metric_isolator_agent, self.query)\n",
    "    metric_isolator_task = tasks.metric_isolation(user_intent_capture_agent, self.query)\n",
    "    metric_discover_task = tasks.metric_discovery(discover_metric_info_agent)\n",
    "    \n",
    "    # print(\"Metric_isolator_task\", metric_isolator_task)\n",
    "    crew = Crew(\n",
    "      agents=[\n",
    "        user_intent_capture_agent,\n",
    "        discover_metric_info_agent,\n",
    "      ],\n",
    "      tasks=[\n",
    "        metric_isolator_task,\n",
    "        metric_discover_task\n",
    "      ],\n",
    "      verbose=False,\n",
    "      process=Process.sequential,\n",
    "      step_callback=after_task_callback(metric_discover_task.output)\n",
    "    )\n",
    "\n",
    "    result = crew.kickoff()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-01 10:26:32,139 - 140704506453952 - __init__.py-__init__:518 - WARNING: Overriding of current TracerProvider is not allowed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.MetricDiscoveryTasks object at 0x14832af50>\n",
      "Agent completed task with result: None\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: To capture the user's intent regarding metric information accurately, I need to rephrase the query to focus on the metric aspect of the feature usage by paid subscribers.\n",
      "\n",
      "Action: rephrase_input_query\n",
      "\n",
      "Action Input: {\"query\": \"What is the most popular feature used by our paid subscribers\"}\n",
      "\u001b[0m\u001b[95m \n",
      "\n",
      "Please provide the feature among our paid subscription offerings that has the highest usage statistics.\n",
      "\u001b[00m\n",
      "\u001b[32;1m\u001b[1;3mFinal Answer: Please provide the feature among our paid subscription offerings that has the highest usage statistics.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: To provide the user with the information they're asking for, I need to discover the metric that represents the \"highest usage statistics\" among our paid subscription features. I will use the metric_discovery tool to find the relevant metric.\n",
      "\n",
      "Action: metric_discovery\n",
      "\n",
      "Action Input: {\"query\": \"highest usage statistics among paid subscription features\"}\n",
      "\u001b[0m\u001b[95m \n",
      "\n",
      "Sorry, the query is out of scope.\n",
      "\u001b[00m\n",
      "\u001b[32;1m\u001b[1;3mThought: Since the metric discovery tool indicated that the query is out of scope, it means that there is no relevant metric available in the metadata that I can access. Therefore, I must respond accordingly to the user.\n",
      "\n",
      "Final Answer: Sorry, the query is out of scope.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the most popular feature used by our paid subscribers\"\n",
    "# formatted_query = input(\n",
    "#     dedent(\"\"\"\n",
    "#       {What is the most popular feature used by our paid subscribers}\n",
    "#     \"\"\"))\n",
    "# print(formatted_query)\n",
    "crew = MetricDiscoveryInputCrew(query)\n",
    "result = crew.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.MetricDiscoveryInputCrew object at 0x1478f7f10>\n"
     ]
    }
   ],
   "source": [
    "print(crew.__repr__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
