{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.utils.llamaindex_retriever import LlamaIndexRetriever\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.azure_openai import AzureOpenAIEmbeddings\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "\n",
    "def load_env_variables(file_path):\n",
    "    load_dotenv(file_path)\n",
    "    print(\"Environment variables loaded successfully!\")\n",
    "\n",
    "env_file_path = \"../.env\"\n",
    "load_env_variables = load_env_variables(env_file_path)\n",
    "\n",
    "\n",
    "# embeddings = AzureOpenAIEmbeddings(azure_deployment=azure_deployment, openai_api_version=openai_api_version)\n",
    "embeddings =  AzureOpenAIEmbeddings(\n",
    "        deployment=os.getenv(\"EMB_DEPLOYMENT\"),\n",
    "        openai_api_version=os.getenv(\"EMB_OPENAI_API_VERSION\"),\n",
    "        model=os.getenv(\"EMB_MODEL\"),\n",
    "        openai_api_key=os.getenv(\"EMB_OPENAI_API_KEY\"),\n",
    "        openai_api_base=os.getenv(\"EMB_OPENAI_ENDPOINT\"),\n",
    "        openai_api_type=os.getenv(\"EMB_API_TYPE\"),\n",
    "    )\n",
    "\n",
    "llm_gpt = AzureChatOpenAI(deployment_name=os.getenv('AZURE_OPENAI_DEPLOYMENT_NAME'), openai_api_version=os.getenv(\"OPENAI_API_VERSION\"),\n",
    "                        openai_api_base=os.getenv(\"OPENAI_API_BASE\"), \n",
    "                        openai_api_type= os.getenv(\"OPENAI_API_TYPE\"),\n",
    "                        openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "                        max_tokens=3500,\n",
    "                        temperature=0.0)\n",
    "# for key, value in os.environ.items():\n",
    "#   print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.cube_semantic_custom import CubeSemanticLoader\n",
    "def fetch_cube_metadata(*args, **kwargs):\n",
    "    try:\n",
    "        # # Load document from Cube meta api\n",
    "        loader = CubeSemanticLoader(os.getenv(\"CUBE_API_URL\"), os.getenv(\"CUBE_TOKEN\"), False)\n",
    "        documents = loader.load()\n",
    "        # to_json()\n",
    "        return documents\n",
    "    except Exception as e:\n",
    "        # Handle exceptions gracefully and return an error response\n",
    "        print(\"Error in fetching metadata from cube: \" + str(e))\n",
    "        return 0\n",
    "\n",
    "def create_vector_store(documents, local_vector_store_path, *args, **kwargs):\n",
    "    print(\"Loaded documents: \" + str(documents))\n",
    "    vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "    vectorstore.save_local(local_vector_store_path)\n",
    "    print(\"Vector store created and saved successfully!\")\n",
    "\n",
    "def load_vector_store(vector_store_path, embeddings, *args, **kwargs):\n",
    "    # Load the vector store from the local file system\n",
    "    vectorstore = FAISS.load_local(vector_store_path, embeddings, allow_dangerous_deserialization=True)\n",
    "    print(\"Vector store loaded successfully!\")\n",
    "    \n",
    "    return vectorstore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store_path = \"/Users/k.abhishek/Documents/experiments/metric_store/metric_store_gen_ai/data/vector_store/cube_meta_faiss_index\"\n",
    "# cube_metadata = fetch_cube_metadata()\n",
    "loader = CubeSemanticLoader(os.getenv(\"CUBE_API_URL\"), os.getenv(\"CUBE_TOKEN\"), False)\n",
    "cube_metadata = loader.fetch_raw_cube_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "filepath = \"/Users/k.abhishek/Documents/experiments/metric_store/metric_store_gen_ai/data/preloaded_cube_metadata/cube_metadata.json\"\n",
    "#save the cube metadata to a file\n",
    "with open(filepath, \"w\") as file:\n",
    "    json.dump(cube_metadata, file)\n",
    "\n",
    "print(\"Cube metadata saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the cube metadata from the file and format the data into list[Document] for further processing while using \n",
    "import json\n",
    "\n",
    "filepath = \"/Users/k.abhishek/Documents/experiments/metric_store/metric_store_gen_ai/data/preloaded_cube_metadata/cube_metadata.json\"\n",
    "\n",
    "# Load the JSON data from the file\n",
    "with open(filepath, \"r\") as file:\n",
    "    data = json.load(file)\n",
    "documents = loader.format_raw_cube_metadata(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = load_vector_store(vector_store_path, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Controller\n",
    "from langchain import PromptTemplate\n",
    "start_goal_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    You are an very experienced and expert manager. You are given following query \"{goal}\".\n",
    "    The query may contain different objectives which needs an expertise to solve. Your job is to provide a list of objectives that is easier for the experts to serve the query.\n",
    "    Ensure objectives are streamlined to minimize the overall number of tasks while addressing the objective effectively. \n",
    "    Some part of the query may not be relevant to the objectives. You can ignore those parts.\n",
    "    The number of tasks should be strictly less than 10.\n",
    "    \"\"\",\n",
    "    input_variables=[\"goal\", \"language\", \"tools\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tools\n",
    "\n",
    "Metric Discovery: Assuming we are trying to 3 metrics \n",
    "Agent: Get relevant \n",
    "Get 3 top documents \n",
    "\n",
    "Tasks: Metric Discovery \n",
    "1. Rewrite the and Extract specifics of metric information for better retrieval\n",
    "2. Extract top 3 documents related to metric information. (Basic RAG)\n",
    "3. get information about metrics and compile the results and return \n",
    "\n",
    "Tasks: Information regarding the metric\n",
    "1. Check if metric exists\n",
    "2. Query vector database to descrive about the metric (RAG)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from crewai import Agent, Task\n",
    "from langchain.tools import tool\n",
    "from src.utils.llamaindex_retriever import LlamaIndexRetriever\n",
    "#Will create below functions once the input is setup properly\n",
    "# def create_vector_store\n",
    "\n",
    "# def ingest_cube_meta():\n",
    "\n",
    "\n",
    "\n",
    "@tool(\"Extract metric queried.\")\n",
    "def extract_metric_description(query, *args, **kwargs):\n",
    "  \"\"\"Useful to isolate metric information to be further used in the its discovery\"\"\"\n",
    "  agent = Agent(\n",
    "        role='Metric Isolator',\n",
    "        goal=\n",
    "        'Accurate Extraction of Metric name or description',\n",
    "        backstory=\n",
    "        \"You're a Metric isolator which is responsible for extracting the metrics name from the given content.\",\n",
    "        llm = llm_gpt,\n",
    "        allow_delegation=False)\n",
    "  task = Task(\n",
    "        agent=agent,\n",
    "        description=\n",
    "        f' The primary objective is to ensure that all the metrics are correctly isolated and extracted from the query {query}. This extracted information should be organized in a form of list.',\n",
    "        expected_output=\"some string\",\n",
    "  \n",
    "    )\n",
    "  extracted_metrics = task.execute()\n",
    "\n",
    "  return extracted_metrics\n",
    "\n",
    "faiss_index_path = \"/Users/k.abhishek/Documents/experiments/metric_store/metric_store_gen_ai/data/vector_store/cube_meta_faiss_index\"\n",
    "vectorstore = FAISS.load_local(faiss_index_path, embeddings, allow_dangerous_deserialization=True)\n",
    "\n",
    "def get_similar_documents(query, max_number_documents=3):\n",
    "  faiss_index_path = \"/Users/k.abhishek/Documents/experiments/metric_store/metric_store_gen_ai/data/vector_store/cube_meta_faiss_index\"\n",
    "  vectorstore = FAISS.load_local(faiss_index_path, embeddings, allow_dangerous_deserialization=True)\n",
    "  docs = vectorstore.similarity_search_with_relevance_scores(query, max_number_documents)\n",
    "  conversational_metadata = []\n",
    "  for doc in docs:\n",
    "      doc = doc[0]\n",
    "      meta = {'text':doc.page_content, 'table_metadata': doc.metadata}\n",
    "      conversational_metadata.append(meta)\n",
    "  return conversational_metadata\n",
    "\n",
    "# @tool(\"Metric Discovery.\")\n",
    "def metric_discovery_faiss(metric_description, vectorstore, *args, **kwargs):\n",
    "  \"\"\"Useful for general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\"\"\n",
    "  # documents = fetch_cube_metadata()\n",
    "  # retriever = LlamaIndexRetriever('metric discovery')\n",
    "  # retriever.index_document(documents)\n",
    "\n",
    "  # docs = vectorstore.similarity_search_with_relevance_scores(metric_description, max_number_documents)\n",
    "  # conversational_metadata = []\n",
    "  # for doc in docs:\n",
    "  #   meta = {'text':doc.text, 'table_metadata': doc.metadata}\n",
    "  #   conversational_metadata.append(meta)\n",
    "  conversational_metadata = get_similar_documents(metric_description)\n",
    "  agent = Agent(\n",
    "        role='Data Analyst Assistant',\n",
    "        goal=\n",
    "        'Empower users to understand and utilize data effectively. This includes helping them discover relevant metrics, interpreting their meaning',\n",
    "        backstory=\n",
    "        \"The primary purpose is to bridge the gap between raw data and user comprehension, fostering a data-driven culture within the organization.\",\n",
    "        llm = llm_gpt,\n",
    "        allow_delegation=False)  \n",
    "  \n",
    "  task = Task(\n",
    "        agent=agent,\n",
    "        description=\n",
    "        \"\"\" You are responding to  question {metric_description} with answer from the Metadata provided to you as {conversational_metadata}}.\n",
    "            Strictly answer the question with the information present in metadata only.\n",
    "            Respond with \"Sorry, the query is out of scope.\" if the answer is not present in metadata.\n",
    "            \"\"\",\n",
    "        expected_output=\"some string\",\n",
    "  \n",
    "    )\n",
    "  output = task.execute()\n",
    "\n",
    "  return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prompt_metric_discovery = f\"You are given a metric description as input {metric_description}. Your task is to determine whether this specific metric exists within the context provided. Thoroughly analyze the metric description and provide a definitive answer on the existence of the metric, along with any relevant details or insights that support your conclusion.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_index_path = \"/Users/k.abhishek/Documents/experiments/metric_store/metric_store_gen_ai/data/vector_store/cube_meta_faiss_index\"\n",
    "vectorstore = FAISS.load_local(faiss_index_path, embeddings, allow_dangerous_deserialization=True)\n",
    "query = \"What is the most popular feature used by our paid subscribers\"\n",
    "response = metric_discovery_faiss(query, vectorstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sorry, the query is out of scope.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectorstore.similarity_search(\"What is the most popular feature used by our paid subscribers\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Users Count, None', metadata={'table_name': 'users', 'column_name': 'users.count', 'column_data_type': 'number', 'column_title': 'Users Count', 'column_description': 'None', 'column_member_type': 'measure', 'column_values': [], 'cube_data_obj_type': 'cube'}),\n",
       " Document(page_content='Users Company, None', metadata={'table_name': 'users', 'column_name': 'users.company', 'column_data_type': 'string', 'column_title': 'Users Company', 'column_description': 'None', 'column_member_type': 'dimension', 'column_values': [], 'cube_data_obj_type': 'cube'}),\n",
       " Document(page_content='Users Created at, None', metadata={'table_name': 'users', 'column_name': 'users.created_at', 'column_data_type': 'time', 'column_title': 'Users Created at', 'column_description': 'None', 'column_member_type': 'dimension', 'column_values': [], 'cube_data_obj_type': 'cube'})]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content='Users Count, None', metadata={'table_name': 'users', 'column_name': 'users.count', 'column_data_type': 'number', 'column_title': 'Users Count', 'column_description': 'None', 'column_member_type': 'measure', 'column_values': [], 'cube_data_obj_type': 'cube'}),\n",
       "  0.6682709429886676),\n",
       " (Document(page_content='Users Company, None', metadata={'table_name': 'users', 'column_name': 'users.company', 'column_data_type': 'string', 'column_title': 'Users Company', 'column_description': 'None', 'column_member_type': 'dimension', 'column_values': [], 'cube_data_obj_type': 'cube'}),\n",
       "  0.6650152464551708),\n",
       " (Document(page_content='Users Created at, None', metadata={'table_name': 'users', 'column_name': 'users.created_at', 'column_data_type': 'time', 'column_title': 'Users Created at', 'column_description': 'None', 'column_member_type': 'dimension', 'column_values': [], 'cube_data_obj_type': 'cube'}),\n",
       "  0.6643387473897224),\n",
       " (Document(page_content='Users City, None', metadata={'table_name': 'users', 'column_name': 'users.city', 'column_data_type': 'string', 'column_title': 'Users City', 'column_description': 'None', 'column_member_type': 'dimension', 'column_values': [], 'cube_data_obj_type': 'cube'}),\n",
       "  0.6586392290655942)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(\"Metric Discovery.\")\n",
    "def metric_discovery_faiss(metric_description, *args, **kwargs):\n",
    "  \"\"\"Useful for general user questions related to discovery, explaination, description, interpretation of metrics/measures/KPIs, tables or columns.\"\"\"\n",
    "  documents = fetch_cube_metadata()\n",
    "  retriever = LlamaIndexRetriever('metric discovery')\n",
    "  retriever.index_document(documents)\n",
    "\n",
    "  # rephrased_query = f\"Find the metric {metric_description}\"\n",
    "\n",
    "  response_doc = retriever.query_util(metric_description, documents)\n",
    "  conversational_metadata = []\n",
    "  for doc in response_doc:\n",
    "    meta = {'text':doc.text, 'table_metadata': doc.metadata}\n",
    "    conversational_metadata.append(meta)\n",
    "  agent = Agent(\n",
    "        role='Data Analyst Assistant',\n",
    "        goal=\n",
    "        'Empower users to understand and utilize data effectively. This includes helping them discover relevant metrics, interpreting their meaning',\n",
    "        backstory=\n",
    "        \"The primary purpose is to bridge the gap between raw data and user comprehension, fostering a data-driven culture within the organization.\",\n",
    "        llm = llm_gpt,\n",
    "        allow_delegation=False)  \n",
    "  \n",
    "  task = Task(\n",
    "        agent=agent,\n",
    "        description=\n",
    "        \"\"\" You are responding to  question {metric_description} with answer from the Metadata provided to you as {conversational_metadata}}.\n",
    "            Strictly answer the question with the information present in metadata only.\n",
    "            Respond with \"Sorry, the query is out of scope.\" if the answer is not present in metadata.\n",
    "            \"\"\",\n",
    "        expected_output=\"some string\",\n",
    "  \n",
    "    )\n",
    "  output = task.execute()\n",
    "\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the most popular feature used by our paid subscribers\"\n",
    "extracted_metrics = extract_metric_description(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_documents(query, vector_store):\n",
    "  docs = vector_store.similarity_search(query)\n",
    "  # take the first document as the best guess\n",
    "  table_name = docs[0].metadata[\"table_name\"]\n",
    "  # Columns\n",
    "  columns_question = \"All available columns\"\n",
    "  column_docs = vector_store.similarity_search(\n",
    "      columns_question,\n",
    "      filter=dict(table_name=table_name),\n",
    "      k=20\n",
    "  )\n",
    "  lines = []\n",
    "  for column_doc in column_docs:\n",
    "      column_title = column_doc.metadata[\"column_title\"]\n",
    "      column_name = column_doc.metadata[\"column_name\"]\n",
    "      column_data_type = column_doc.metadata[\"column_data_type\"]\n",
    "      lines.append(\n",
    "          f\"title: {column_title}, column name: {column_name}, datatype: {column_data_type}, member type: {column_doc.metadata['column_member_type']}\"\n",
    "      )\n",
    "  columns = \"\\n\".join(lines)\n",
    "  print(\"columns :\", columns)\n",
    "\n",
    "  FAISS.similarity_search_with_relevance_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre process of input to make it more relevant\n",
    "import nltk\n",
    "\n",
    "# Download NLTK tokenizer data (one-time setup)\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def preprocess_text(text):\n",
    "  # Tokenization\n",
    "  tokens = nltk.word_tokenize(text.lower())\n",
    "  # Stop word removal\n",
    "  stopwords = nltk.corpus.stopwords.words('english')\n",
    "  tokens = [token for token in tokens if token not in stopwords]\n",
    "  return tokens\n",
    "\n",
    "def reformat_question(question):\n",
    "  # Define synonyms and related terms\n",
    "  metrics = [\"metric\", \"KPI\", \"measure\"]\n",
    "  sales_terms = [\"sales\", \"revenue\", \"turnover\"]\n",
    "  central_tendency = [\"average\", \"mean\", \"median\"]\n",
    "  \n",
    "  # Preprocess the question\n",
    "  preprocessed_question = preprocess_text(question)\n",
    "  \n",
    "  # Build the reformulated query string using question tokens\n",
    "  query_string = \"(\" + \" OR \".join(metrics) + \")\"\n",
    "  query_string += \" AND (\" + \" OR \".join(sales_terms) + \")\"\n",
    "  query_string += \" AND (\" + \" OR \".join(central_tendency) + \")\"\n",
    "  \n",
    "  # Include question tokens for broader coverage\n",
    "  query_string += \" AND (\" + \" OR \".join(preprocessed_question) + \")\"\n",
    "  \n",
    "  return query_string\n",
    "\n",
    "# Example usage\n",
    "question = \"Get the metric for sales on avg\"\n",
    "reformulated_question = reformat_question(question)\n",
    "print(f\"Original question: {question}\")\n",
    "print(f\"Reformatted question for FAISS search: {reformulated_question}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.langchain_retriever import LangchainRetriever\n",
    "langchain_retriever = LangchainRetriever(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = fetch_cube_metadata()\n",
    "langchain_retriever.index_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdocs = langchain_retriever.retrieve_sub_document()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loaders = [\n",
    "    TextLoader(\"/Users/k.abhishek/Documents/experiments/metric_store/metric_store_gen_ai/data/dummy_txt_files/file1.txt\"),\n",
    "    TextLoader(\"/Users/k.abhishek/Documents/experiments/metric_store/metric_store_gen_ai/data/dummy_txt_files/file2.txt\"),\n",
    "]\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain_retriever.index_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdocs = langchain_retriever.retrieve_sub_document(\"vectorstore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
